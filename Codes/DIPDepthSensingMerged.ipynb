{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coz5J_cIjs-3"
      },
      "source": [
        "## Digital Image Processing Project (Group IV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLxvbIvOCcvR"
      },
      "source": [
        "Given two images (left and right view) and camera calibration details, the goal is to find the \n",
        "relative depth of various objects in the image using stereo vision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ussZZ-mhUP"
      },
      "source": [
        "### DataSet used : https://drivingstereo-dataset.github.io/\n",
        "10 Images are taken at random from the left-right vision folders as well as from the rainy / foggy folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pRMfCK9UrSb"
      },
      "outputs": [],
      "source": [
        "# Import third party libs.\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.util import random_noise\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math\n",
        "\n",
        "import re\n",
        "numbers = re.compile(r'(\\d+)')\n",
        "def numericalSort(value):\n",
        "    parts = numbers.split(value)\n",
        "    parts[1::2] = map(int, parts[1::2])\n",
        "    return parts\n",
        "\n",
        "def blur_images(images):\n",
        "  blurred_images = [] * len(images) \n",
        "\n",
        "  for img in images:\n",
        "      # kernel is of size 9x9\n",
        "      blur_kernel = np.ones((9, 9), np.float32) / (9.0 * 9.0)\n",
        "      gaussian_blur = cv2.GaussianBlur(img, (9, 9), 0)\n",
        "      blurred_images.append(gaussian_blur)\n",
        "\n",
        "  return blurred_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e62HKukYLRrf"
      },
      "source": [
        "### Bit plane slicing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmMAEW2iLUWp"
      },
      "outputs": [],
      "source": [
        "def bit_plane_slicing(images):\n",
        "  for img in images:\n",
        "    cv2_imshow(img)\n",
        "    lst=[]\n",
        "    for j in range(img.shape[0]):\n",
        "      for k in range(img.shape[1]):\n",
        "        lst.append(str(format((img[j][k]),'08b')))\n",
        "    eight_bit_img = (np.array([int(i[0]) for i in lst],dtype = np.uint8) * 128).reshape(img.shape[0],img.shape[1])\n",
        "    seven_bit_img = (np.array([int(i[1]) for i in lst],dtype = np.uint8) * 64).reshape(img.shape[0],img.shape[1])\n",
        "    six_bit_img = (np.array([int(i[2]) for i in lst],dtype = np.uint8) * 32).reshape(img.shape[0],img.shape[1])\n",
        "    five_bit_img = (np.array([int(i[3]) for i in lst],dtype = np.uint8) * 16).reshape(img.shape[0],img.shape[1])\n",
        "    four_bit_img = (np.array([int(i[4]) for i in lst],dtype = np.uint8) * 8).reshape(img.shape[0],img.shape[1])\n",
        "    three_bit_img = (np.array([int(i[5]) for i in lst],dtype = np.uint8) * 4).reshape(img.shape[0],img.shape[1])\n",
        "    two_bit_img = (np.array([int(i[6]) for i in lst],dtype = np.uint8) * 2).reshape(img.shape[0],img.shape[1])\n",
        "    one_bit_img = (np.array([int(i[7]) for i in lst],dtype = np.uint8) * 1).reshape(img.shape[0],img.shape[1])\n",
        "    final1=cv2.hconcat([eight_bit_img,seven_bit_img,six_bit_img,five_bit_img])\n",
        "    final2=cv2.hconcat([four_bit_img,three_bit_img,two_bit_img,one_bit_img])\n",
        "    final=cv2.hconcat([final1,final2])\n",
        "    print(\"The 8 bit planes: \")\n",
        "    cv2_imshow(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8V00j2rTcEc"
      },
      "source": [
        "## Histogram Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U95qpZ5Tbqb"
      },
      "outputs": [],
      "source": [
        "def histogram_eq(images):\n",
        "  for img in images:\n",
        "    print(\"Original image: \")\n",
        "    cv2_imshow(img)\n",
        "    #flatten image array and calculate histogram via binning\n",
        "    histogram_array=np.bincount(img.flatten(),minlength=256)\n",
        "    #normalize\n",
        "    num_pixels = np.sum(histogram_array)\n",
        "    histogram_array = histogram_array/num_pixels\n",
        "    #normalized cumulative histogram\n",
        "    chistogram_array = np.cumsum(histogram_array) #cumsum returns cumulative sum of array elements over a given axis\n",
        "    transform_map = np.floor(255 * chistogram_array).astype(np.uint8) #pixel mapping lookup table\n",
        "    #flattening image into 1D array\n",
        "    img_list = list(img.flatten())\n",
        "    eq_img_list = [transform_map[p] for p in img_list]#transform pixel values to equalize\n",
        "    eq_img_array = np.reshape(np.asarray(eq_img_list), img.shape)#reshape and write back into an image array\n",
        "    print(\"Histogram Equalized Image: \")\n",
        "    cv2_imshow(eq_img_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS7vUgQDVyhs"
      },
      "source": [
        "## Smoothing + Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCHtRLUYVvw6"
      },
      "outputs": [],
      "source": [
        "def smoothing_segmentation(images):\n",
        "  print(\"Smoothing + segmented images\")\n",
        "  for img in images:\n",
        "    dims=img.shape\n",
        "    mean_fil=np.zeros([dims[0],dims[1]])\n",
        "    for i in range(1,dims[0]-1):\n",
        "      for j in range(1,dims[1]-1):\n",
        "        neighbours = [img[i-1,j-1],\n",
        "                    img[i-1,j],\n",
        "                    img[i-1,j+1],\n",
        "                    img[i,j-1],\n",
        "                    img[i,j],\n",
        "                    img[i,j+1],\n",
        "                    img[i+1,j-1],\n",
        "                    img[i+1,j],\n",
        "                    img[i+1,j+1],]\n",
        "        mean_fil[i,j]=sum(neighbours)/9\n",
        "        mean_fil=mean_fil.astype(np.uint8)\n",
        "    \n",
        "    img_shape = mean_fil.shape\n",
        "    height = img_shape[0]\n",
        "    width = img_shape[1]\n",
        "  \n",
        "    for row in range(width):\n",
        "      for column in range(height):\n",
        "        if mean_fil[column, row] > 127:\n",
        "          mean_fil[column, row] = 255\n",
        "        else:\n",
        "          mean_fil[column, row] = 0\n",
        "    cv2_imshow(mean_fil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHumPOV59Nks",
        "outputId": "9d5209cb-21f6-4d13-d5a1-109293c0ff62"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Shankar0x/DepthSensingDatasets.git images\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrRSXtwY-fYI",
        "outputId": "15a0c9ba-2b71-47c7-df8e-cafc3aa00b4d"
      },
      "outputs": [],
      "source": [
        "a = np.asarray(Image.open('images/DrivingStereo_dataset/001.jpg'))\n",
        "print(\"The shape of the images are: \",a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctnLm-KE9Rqa"
      },
      "outputs": [],
      "source": [
        "path = 'images/DrivingStereo_dataset/'\n",
        "imgs = np.zeros((10,400,879), dtype=np.uint8)\n",
        "for i in range(1,10):\n",
        "    if i<=9:\n",
        "        image = cv2.imread(path+'00'+str(i)+'.jpg', 0)\n",
        "    else:\n",
        "        image = cv2.imread(path+'0'+str(i)+'.jpg',0)\n",
        "    data = np.asarray(image, np.uint8)\n",
        "    imgs[i-1] = data.astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RkCVnXN4MLWW",
        "outputId": "bb715817-f79c-462f-d1bf-ed50c8286805"
      },
      "outputs": [],
      "source": [
        "# Driver code for bitplane slicing and histogram eq\n",
        "bit_plane_slicing(imgs.copy())\n",
        "histogram_eq(imgs.copy())\n",
        "smoothing_segmentation(imgs.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFb04TZ9WisC"
      },
      "source": [
        "## Nearest neighbour interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7dOVLToWdcb"
      },
      "outputs": [],
      "source": [
        "def nearestneighbor(image,scale):\n",
        "  width, height = orig.shape[:2]\n",
        "  xNew = int(width*scale)\n",
        "  yNew = int(height*scale)\n",
        "  newimage = np.zeros([xNew,yNew])\n",
        "\n",
        "  for i in range(xNew-1):\n",
        "    for j in range(yNew-1):\n",
        "      newimage[i,j]=orig[int(i/scale),int(j/scale)]\n",
        "  return newimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jdNtQqR9Wsp4",
        "outputId": "a3233caa-33eb-4422-9a7c-1514562cb3e0"
      },
      "outputs": [],
      "source": [
        "# Driver code for nearest neighbour\n",
        "path = 'images/DrivingStereo_dataset/RainyAndFoggy/'\n",
        "image_one = cv2.imread(path+'001.jpg', 0)\n",
        "rainy = np.zeros((10,image_one.shape[0], image_one.shape[1]), dtype=np.uint8)\n",
        "for i in range(1,11):\n",
        "    if i<=9:\n",
        "        image = cv2.imread(path+'00'+str(i)+'.jpg', 0)\n",
        "    else:\n",
        "        image = cv2.imread(path+'0'+str(i)+'.jpg',0)\n",
        "\n",
        "    image = cv2.resize(image, (image_one.shape[1], image_one.shape[0]))\n",
        "    data = np.asarray(image, np.uint8)\n",
        "    rainy[i-1] = data\n",
        "\n",
        "\n",
        "for orig in rainy:\n",
        "  retimg = nearestneighbor(orig,1/2)\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  print(\"Scaled image using nearest neighbour interpolation:\")\n",
        "  cv2_imshow(retimg)\n",
        "  print()\n",
        "  print(\"\\n----------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kx3h_hRMW7s-",
        "outputId": "28002c07-cb8d-4738-e133-cd95eb015b1e"
      },
      "outputs": [],
      "source": [
        "for orig in rainy:\n",
        "  nn_img = cv2.resize(orig,None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  print(\"Scaled image using nearest neighbor interpolation:\")\n",
        "  cv2_imshow(nn_img)\n",
        "  print()\n",
        "  print(\"\\n----------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y48Ad1m2XEXn"
      },
      "source": [
        "## Bilinear interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n5l42JcYXHAC",
        "outputId": "453f449c-106b-4da2-f1ac-b61d60830de3"
      },
      "outputs": [],
      "source": [
        "def GetBilinearPixel(imArr, posX, posY):\n",
        "        out = []\n",
        " \n",
        "      \n",
        "        modXi = int(posX)\n",
        "        modYi = int(posY)\n",
        "        modXf = posX - modXi\n",
        "        modYf = posY - modYi\n",
        "        modXiPlusOneLim = min(modXi+1,imArr.shape[1]-1)\n",
        "        modYiPlusOneLim = min(modYi+1,imArr.shape[0]-1)\n",
        " \n",
        "      \n",
        "        for chan in range(3):\n",
        "                bl = imArr[modYi, modXi]\n",
        "                br = imArr[modYi, modXiPlusOneLim]\n",
        "                tl = imArr[modYiPlusOneLim, modXi]\n",
        "                tr = imArr[modYiPlusOneLim, modXiPlusOneLim]\n",
        " \n",
        "               \n",
        "                b = modXf * br + (1. - modXf) * bl\n",
        "                t = modXf * tr + (1. - modXf) * tl\n",
        "                pxf = modYf * t + (1. - modYf) * b\n",
        "                out.append(int(pxf+0.5))\n",
        "       \n",
        "        return out\n",
        "\n",
        "for orig in rainy:\n",
        "  width,height = orig.shape\n",
        "  chan = 3\n",
        "\n",
        "  scale_x=0.5\n",
        "  scale_y=0.5\n",
        "\n",
        "  w1=width\n",
        "  h1=height\n",
        "  w2=int(math.floor(w1*scale_x))\n",
        "  h2=int(math.floor(h1*scale_y))\n",
        "  img_bl = np.empty((w2,h2,3), dtype=np.uint8)\n",
        "  x_ratio=float(1/float(scale_x))\n",
        "  y_ratio=float(1/float(scale_y))\n",
        "\n",
        "  for i in range(0,w2):\n",
        "      for j in range(0,h2):\n",
        "          orir = i * x_ratio #Find position in original image\n",
        "          oric = j * y_ratio\n",
        "          \n",
        "          img_bl[i, j]= GetBilinearPixel(orig, oric, orir)\n",
        "\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  print(\"Scaled image using bilinear interpolation:\")\n",
        "  cv2_imshow(img_bl)\n",
        "  print()\n",
        "  print(\"\\n----------------------------------------\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GmrJNFA6XMgH",
        "outputId": "0d27413d-4c5b-4c2d-c786-a85c9b4e47af"
      },
      "outputs": [],
      "source": [
        "for orig in rainy:\n",
        "  bilinear_img = cv2.resize(orig,None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  print(\"Scaled image using bilinear interpolation:\")\n",
        "  cv2_imshow(bilinear_img)\n",
        "  print()\n",
        "  print(\"\\n----------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUCqv5CcXS7m"
      },
      "source": [
        "## Bicubic interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_xDrz18FXUgO",
        "outputId": "49fd54f3-6953-4ffd-f03a-42910a84384f"
      },
      "outputs": [],
      "source": [
        "for orig in rainy:\n",
        "  bicubic_img = cv2.resize(orig,None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_CUBIC)\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  print(\"Scaled image using bicubic interpolation:\")\n",
        "  cv2_imshow(bicubic_img)\n",
        "  print()\n",
        "  print(\"\\n----------------------------------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWzLiTLYXgjb"
      },
      "source": [
        "# Basic image transformations\n",
        "### 1. Image negatives\n",
        "### 2. Log transformation\n",
        "### 3. Gamma correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_TOLYPXkhj"
      },
      "source": [
        "# Image negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zq90MYj0XjjL",
        "outputId": "00985706-559d-4774-d368-361740938d60"
      },
      "outputs": [],
      "source": [
        "def imgnegative(image):\n",
        "  imgneg = 255 - image\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(image)\n",
        "  print()\n",
        "\n",
        "  print(\"Negative of the image:\")\n",
        "  cv2_imshow(imgneg)\n",
        "  print()\n",
        "\n",
        "  print(\"\\n----------------------------------------\\n\")\n",
        "  \n",
        "foggy=rainy.copy()\n",
        "\n",
        "for orig in foggy:\n",
        "  imgnegative(orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfSKvA3PXp8E"
      },
      "source": [
        "## Log transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soAyTiABXr29"
      },
      "outputs": [],
      "source": [
        "def logtransform(image):\n",
        "  # Apply log transformation method\n",
        "  temp = 255 / np.log(1 + np.max(image))\n",
        "  log_image = temp * (np.log(image + 1))\n",
        "    \n",
        "  # Specify the data type so that\n",
        "  # float value will be converted to int\n",
        "  log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "  print(\"Original image:\")\n",
        "  cv2_imshow(image)\n",
        "  print()\n",
        "\n",
        "  print(\"After log transformation:\")\n",
        "  cv2_imshow(log_image)\n",
        "  print()\n",
        "\n",
        "  print(\"\\n----------------------------------------\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2hzamufWYCKE",
        "outputId": "09d9a966-89ab-4212-cfc5-3194f99bc690"
      },
      "outputs": [],
      "source": [
        "images=rainy.copy()\n",
        "for orig in images:\n",
        "  logtransform(orig / 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4CjrViWYGh_"
      },
      "source": [
        "## Gamma Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QaM6gLxeYIie",
        "outputId": "b56a4581-546b-4d52-b68f-576d12d7ddae"
      },
      "outputs": [],
      "source": [
        "#function to apply gamma correction on an image\n",
        "\n",
        "def gammaadjust(image, gamma=1.0):\n",
        "  inverse = 1.0/gamma\n",
        "  table = np.array([((i/255)**inverse)*255 for i in np.arange(0,256)]).astype(\"uint8\")\n",
        "  return cv2.LUT(image,table)\n",
        "\n",
        "for orig in images:\n",
        "  print(\"Original Image:\")\n",
        "  cv2_imshow(orig)\n",
        "  print()\n",
        "  values=[]\n",
        "  for gamma in np.arange(0.0,3.5,0.5):\n",
        "    if gamma==1:\n",
        "      continue\n",
        "    if gamma > 0:\n",
        "      gamma = gamma\n",
        "    else:\n",
        "      gamma = 0.1\n",
        "    values.append(gammaadjust(orig,gamma=gamma))\n",
        "\n",
        "  print(\"After gamma correction with gamma 0.1, 0.5, 1.5, 2.0, 2.5 and 3.0 respectively\")\n",
        "  x = np.concatenate((values[0],values[1]),axis=1)\n",
        "  for i in range(2,len(values)):\n",
        "    x = np.concatenate((x,values[i]),axis=1)\n",
        "  cv2_imshow(x)\n",
        "  print()\n",
        "  print(\"\\n-----------------------------------------------\\n\")\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGXtFW5oJ8rT"
      },
      "source": [
        "# Spatial Resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nr7bs_rKA7H"
      },
      "source": [
        "Spatial resolution can determine the quality of an image and describe how detailed an object can be represented by the image. If its quality is reduced, then the size of the image is automatically decreased. This will result in less data storage and less processing power. \n",
        "\n",
        "\n",
        "For depth sensing, there is a requirement for low-size images which will result in optimized use of resources. Spatial Resolutions helps in reducing the size. But it may result in less queality image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nf3IIgY2KEV3",
        "outputId": "5fe6e885-b3e0-4ae6-b065-84cd1566f1db"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "#Read the image\n",
        "imgs = imgs.copy()\n",
        "\n",
        "\n",
        "for x in range(len(imgs)):\n",
        "  img1 = imgs[x].copy()    \n",
        "\n",
        "# Obtain the size\n",
        "  [m, n] = img1.shape\n",
        "\n",
        "  \n",
        "# Assigning a down sampling rate\n",
        "  f = 4\n",
        " \n",
        "# Create a matrix of all zeros for\n",
        "# downsampled values\n",
        "  img2 = np.zeros((m//f, n//f), int)\n",
        " \n",
        "# Assign the down sampled values from the original\n",
        "# image according to the down sampling frequency.\n",
        "\n",
        "  for i in range(0, m, f):\n",
        "      for j in range(0, n, f):\n",
        "          try:\n",
        "              img2[i//f][j//f] = img1[i][j]\n",
        "          except IndexError:\n",
        "              pass\n",
        " \n",
        " \n",
        "#UpÂ sampling\n",
        "\n",
        "# Create matrix of zeros to store the upsampled image\n",
        "  img3 = np.zeros((m, n), int)\n",
        "# new size\n",
        "  for i in range(0, m-1, f):\n",
        "    for j in range(0, n-1, f):\n",
        "      try:\n",
        "        img3[i, j] = img2[i//f][j//f]\n",
        "      except IndexError:\n",
        "        pass\n",
        "        \n",
        "#Replicating rows\n",
        " \n",
        "  for i in range(1, m-(f-1), f):\n",
        "    for j in range(0, n-(f-1)):\n",
        "        try:\n",
        "            img3[i:i+(f-1), j] = img3[i-1, j]\n",
        "        except IndexError:\n",
        "            pass\n",
        "        \n",
        "#Replicating columns\n",
        "  for i in range(0, m-1):\n",
        "    for j in range(1, n-1, f):\n",
        "      try:\n",
        "        img3[i, j:j+(f-1)] = img3[i, j-1]\n",
        "      except IndexError:\n",
        "        pass\n",
        "# # Show original image\n",
        "  plt.figure(figsize=(30,3))\n",
        "  \n",
        "  plt.subplot(1,3,1)\n",
        "  plt.imshow(img1, cmap=\"gray\")\n",
        "  plt.title('Original image')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1, 3,2)\n",
        "  plt.imshow(img2, cmap='gray')\n",
        "  plt.title('down sampled image') \n",
        "  plt.axis() \n",
        "\n",
        "  plt.subplot(1, 3,3)\n",
        "  plt.imshow(img3, cmap='gray')\n",
        "  plt.title('up sampled image') \n",
        "  plt.axis() \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "Ox57fCnbKXbt",
        "outputId": "302d3c3e-8ae2-41a5-b784-7909aa0ee67a"
      },
      "outputs": [],
      "source": [
        "# # Print down sampled image\n",
        "print('Down Sampled Image:')\n",
        "\n",
        "plt.imshow(img2, cmap=\"gray\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "_7TO3Mq_KYyF",
        "outputId": "7967be33-7dbd-475b-a49e-6348b824f833"
      },
      "outputs": [],
      "source": [
        "# #Plot the up sampled image\n",
        "print('Up Sampled Image:')\n",
        "plt.imshow(img3, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dLPHoiqKbDR"
      },
      "source": [
        "###Intensity Resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3pXflYKcgP"
      },
      "source": [
        "It refers to the number of intensity levels used to represent an image. The more intensity levels used, the finer the level of detail discernible in an image. Intensity level resolution is usually given in terms of the number of bits used to store each intensity level.\n",
        "\n",
        "For Depth sensing below we used three different intensity levels:- [ 32 bit, 64, 128 ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p9PQ8bOJUwQJ",
        "outputId": "82640f15-349d-434e-c43e-128e97b6b27e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def intensity_resolution(img,min_r,max_r):\n",
        "\n",
        "  # Find width and height of image\n",
        "  row, column = img.shape\n",
        "\n",
        "  # Create an zeros array to store the sliced image\n",
        "  img1 = np.zeros((row,column),dtype = 'uint8')\n",
        "\n",
        "  # Specify the min and max range\n",
        "  min_range = min_r\n",
        "  max_range = max_r\n",
        "\n",
        "  # Loop over the input image \n",
        "  for i in range(row):\n",
        "      for j in range(column):\n",
        "  # if pixel value lies in desired range set it to 255 otherwise set it to 0.\n",
        "          if img[i,j]>min_range and img[i,j]<max_range:\n",
        "              img1[i,j] = 255\n",
        "          else:\n",
        "              img1[i,j] = 0\n",
        "  # Display the image\n",
        "  return img1\n",
        "\n",
        "#Read the image\n",
        "images = []\n",
        "filelist_imgs = sorted(glob.glob('images/DrivingStereo_dataset/*.jpg'), key=numericalSort)\n",
        "for fname in filelist_imgs:\n",
        "  img = cv2.imread(fname)\n",
        "  images.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "img32 = np.zeros((10,400,879))\n",
        "for i in range(10):\n",
        "  img32[i] = intensity_resolution(images[i],0,32)\n",
        "\n",
        "for i in range(len(img32)):\n",
        "  plt.figure(figsize=(100,9))\n",
        "  plt.subplot(1,9,1)\n",
        "  plt.imshow(img32[i],cmap=\"gray\")\n",
        "  plt.title('32 bit Intensity image '+str(i+1))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TxHhyZ3DVm-j",
        "outputId": "12a886a4-bf2e-466a-d243-5883c232ee74"
      },
      "outputs": [],
      "source": [
        "img64 = np.zeros((10,400,879))\n",
        "for i in range(10):\n",
        "  img64[i] = intensity_resolution(images[i],0,64)\n",
        "\n",
        "for i in range(len(img64)):\n",
        "  plt.figure(figsize=(100,9))\n",
        "  plt.subplot(1,9,1)\n",
        "  plt.imshow(img64[i],cmap=\"gray\")\n",
        "  plt.title('64 bit Intensity image '+str(i+1))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fNC5astKRgdg",
        "outputId": "950c96bd-1ad1-4f69-8a0e-318fb3321df4"
      },
      "outputs": [],
      "source": [
        "img128 = np.zeros((10,400,879))\n",
        "for i in range(10):\n",
        "  img128[i] = intensity_resolution(images[i],0,128)\n",
        "for i in range(len(img128)):\n",
        "  plt.figure(figsize=(100,9))\n",
        "  plt.subplot(1,9,1)\n",
        "  plt.imshow(img128[i],cmap=\"gray\")\n",
        "  plt.title('128 bit Intensity image '+str(i+1))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j9LHSHzSVyu0",
        "outputId": "1fb64846-ba8e-4ba5-edcc-70bfd9b0f825"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the image\n",
        "\n",
        "def thresholding(img,s):\n",
        "    img_shape = img.shape\n",
        "    height = img_shape[0]\n",
        "    width = img_shape[1]\n",
        "    # img1 = np.empty((10,400,879))\n",
        "    img1 = img.copy()\n",
        "    for row in range(width):\n",
        "        for column in range(height):\n",
        "            if img1[column, row] >= s:\n",
        "                img1[column, row] = 255\n",
        "            else:\n",
        "                img1[column, row] = 0\n",
        "    return img1\n",
        "\n",
        "images = imgs.copy()\n",
        "\n",
        "img_low = np.empty((10,400,879))\n",
        "for i in range(10):\n",
        "  img_low[i] = thresholding(images[i],60)\n",
        "\n",
        "img_high = np.empty((10,400,879))\n",
        "for i in range(10):\n",
        "  img_high[i] = thresholding(images[i],100)\n",
        "\n",
        "for i in range(len(img_low)):\n",
        "  plt.figure(figsize=(100,9))\n",
        "  plt.subplot(1,9,1)\n",
        "  plt.imshow(img_low[i],cmap=\"gray\")\n",
        "  plt.title('Low Threshold image '+str(i+1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "  plt.imshow(img_high[i],cmap=\"gray\")\n",
        "  plt.title('High Threshold image '+str(i+1))\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "X7GTioazKeOq",
        "outputId": "cf820048-d0bf-4329-a8a7-9d2af7c9cb21"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the image\n",
        "imgs = imgs.copy()\n",
        "\n",
        "img = imgs[0]\n",
        "# Find width and height of image\n",
        "row, column = img.shape\n",
        "# Create an zeros array to store the sliced image\n",
        "img1 = np.zeros((row,column),dtype = 'uint8')\n",
        "\n",
        "# Specify the min and max range\n",
        "\n",
        "min_range = 0\n",
        "max_range = 128\n",
        "# while(1):\n",
        "#     x = input()\n",
        "#     y = input()\n",
        "\n",
        "# Loop over the input image \n",
        "\n",
        "for i in range(row):\n",
        "    for j in range(column):\n",
        "# if pixel value lies in desired range set it to 255 otherwise set it to 0.\n",
        "        if img[i,j]>min_range and img[i,j]<max_range:\n",
        "            img1[i,j] = 255\n",
        "        else:\n",
        "            img1[i,j] = 0\n",
        "# Display the image\n",
        "plt.imshow(img1, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "FUg6il7UKhFx",
        "outputId": "1db1efd9-dd64-411b-ba02-673c19e41e1a"
      },
      "outputs": [],
      "source": [
        "min_range = 0\n",
        "max_range = 64\n",
        "\n",
        "for i in range(row):\n",
        "    for j in range(column):\n",
        "        if img[i,j]>min_range and img[i,j]<max_range:\n",
        "            img1[i,j] = 255\n",
        "        else:\n",
        "            img1[i,j] = 0\n",
        "\n",
        "plt.imshow(img1, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "c5SrZfRKKmOJ",
        "outputId": "c6234ea2-6259-49a6-e5a9-d7caa9baa4f6"
      },
      "outputs": [],
      "source": [
        "min_range = 0\n",
        "max_range = 32\n",
        "\n",
        "for i in range(row):\n",
        "    for j in range(column):\n",
        "        if img[i,j]>min_range and img[i,j]<max_range:\n",
        "            img1[i,j] = 255\n",
        "        else:\n",
        "            img1[i,j] = 0\n",
        "\n",
        "plt.imshow(img1, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHIbJS3FKog1"
      },
      "source": [
        "# Smooth and Hard Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "C5LkZsbxKp66",
        "outputId": "5859f2c7-6de0-404b-ee68-54bff60547d3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the image\n",
        "\n",
        "def thresholdimg(img,s):\n",
        "    img_shape = img.shape\n",
        "    height = img_shape[0]\n",
        "    width = img_shape[1]\n",
        "    for row in range(width):\n",
        "        for column in range(height):\n",
        "            if img[column, row] > s:\n",
        "                img[column, row] = 255\n",
        "            elif img[column, row] != 0:\n",
        "                img[column, row] = 0\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    return\n",
        "\n",
        "imgs = imgs.copy()\n",
        "\n",
        "thresholdimg(imgs[7],140)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nQXuToApKrqh",
        "outputId": "dfbbff77-2296-4137-f6a0-c7df6a55f6a6"
      },
      "outputs": [],
      "source": [
        "thresholdimg(imgs[7],160)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T2bTxEfSw8L"
      },
      "source": [
        "## **Salt and pepper noise removal**\n",
        "\n",
        "###<u>Relevance to our project</u>\n",
        "###Salt-and-pepper noise is also called impulse noise. It can be caused by several reasons like dead pixels, analog-to-digital conversion error, bit transmission error, etc. The dataset can be cleaned from images containing salt and pepper noise using the following method.\n",
        "\n",
        "###A **median filter** is used to clean the images from salt and pepper noise as it is the most efficient among non linear filters. The implementation of both median and average filter is done and plotted side by side for comparision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxT1KWj2ZBPo"
      },
      "outputs": [],
      "source": [
        "def denoise_imgs(salt_imgs):\n",
        "  dims = salt_imgs.shape\n",
        "  img_new = np.zeros([dims[0], dims[1]])\n",
        "  avg_new = np.zeros([dims[0],dims[1]])\n",
        "  for i in range(1,dims[0]-1):\n",
        "    for j in range(1, dims[1]-1):\n",
        "      neighbours = [salt_imgs[i-1,j-1],\n",
        "                    salt_imgs[i-1,j],\n",
        "                    salt_imgs[i-1,j+1],\n",
        "                    salt_imgs[i,j-1],\n",
        "                    salt_imgs[i,j],\n",
        "                    salt_imgs[i,j+1],\n",
        "                    salt_imgs[i+1,j-1],\n",
        "                    salt_imgs[i+1,j],\n",
        "                    salt_imgs[i+1,j+1],]\n",
        "      neighbours = sorted(neighbours)\n",
        "      img_new[i,j]=neighbours[4]\n",
        "      avg_new[i,j]=sum(neighbours)/9\n",
        "  img_new = img_new.astype(np.uint8)\n",
        "  avg_new = avg_new.astype(np.uint8)\n",
        "  return img_new,avg_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C34JqJAQZCUa"
      },
      "outputs": [],
      "source": [
        "salt_pepper_imgs = np.full_like(imgs,0)\n",
        "for i in range(10):\n",
        "  noisy = random_noise(imgs[i],mode='s&p',amount=0.3)\n",
        "  salt_pepper_imgs[i]=np.array(255*noisy, dtype = 'uint8')\n",
        "\n",
        "cleaned_imgs = np.full_like(imgs,0)\n",
        "avg_cleaned_imgs = np.full_like(imgs,0)\n",
        "for i in range(10):\n",
        "  clean_img,avg_clean_img = denoise_imgs(salt_pepper_imgs[i])\n",
        "  cleaned_imgs[i]=clean_img\n",
        "  avg_cleaned_imgs[i]=avg_clean_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tvLp2V6vZDLJ",
        "outputId": "869144e3-e235-476b-f797-06323c935689"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[0],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[0],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[0],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[1],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[1],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[1],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[1],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[1],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[1],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[2],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[2],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[2],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[3],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[3],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[3],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[3],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[4],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[4],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[4],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[4],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[5],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[5],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[5],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[5],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[6],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[6],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[6],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[6],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[7],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[7],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[7],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[7],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[8],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[8],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[8],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[8],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[9],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[9],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(avg_cleaned_imgs[9],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(cleaned_imgs[9],cmap='gray')\n",
        "plt.title('Median filter')\n",
        "plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x088ho4cYunL"
      },
      "source": [
        "## **Gaussian noise and its removal using Wiener filter**\n",
        "\n",
        "###<u>Relevance to our project</u>\n",
        "###Gaussian noise is known as the most **natural** form of noise in images as normal function can be found anywhere in the world from height in a class room or grades in a university.\n",
        "\n",
        "###The removal of Gaussian noise can be done using any non-linear filters (average, median etc) but Wiener's filter is a type of filter that can do both filtering of Gaussian noise and also fix the motion blur in an image. In the project, there is a high possibility of having images with both Gaussian blur and most importantly motion blur hence correcting them becomes a crucial step towards finding the depth of objects in the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfJsex_aBhB"
      },
      "outputs": [],
      "source": [
        "from numpy.fft import fft2, ifft2\n",
        "from scipy.signal import gaussian, convolve2d\n",
        "def add_gaussian_noise(img, sigma):\n",
        "\tgauss = np.random.normal(0, sigma, np.shape(img))\n",
        "\tnoisy_img = img + gauss\n",
        "\tnoisy_img[noisy_img < 0] = 0\n",
        "\tnoisy_img[noisy_img > 255] = 255\n",
        "\treturn noisy_img\n",
        "\n",
        "def wiener_filter(img, kernel, K):\n",
        "\tkernel /= np.sum(kernel)\n",
        "\tdummy = np.copy(img)\n",
        "\tdummy = fft2(dummy)\n",
        "\tkernel = fft2(kernel, s = img.shape)\n",
        "\tkernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K)\n",
        "\tdummy = dummy * kernel\n",
        "\tdummy = np.abs(ifft2(dummy))\n",
        "\treturn dummy\n",
        "\n",
        "def gaussian_kernel(kernel_size = 3):\n",
        "\th = gaussian(kernel_size, kernel_size / 3).reshape(kernel_size, 1)\n",
        "\th = np.dot(h, h.transpose())\n",
        "\th /= np.sum(h)\n",
        "\treturn h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpsxqVE0aC55"
      },
      "outputs": [],
      "source": [
        "# inducing motion blur and deblurring it\n",
        "gaussian_noise_imgs = np.full_like(imgs,0)\n",
        "for i in range(10):\n",
        "  gaussian_noise_imgs[i] = add_gaussian_noise(imgs[i],30)\n",
        "\n",
        "kernel = gaussian_kernel()\n",
        "\n",
        "wiener_corrected = np.full_like(imgs,0)\n",
        "for i in range(10):\n",
        "  wiener_corrected[i] = wiener_filter(imgs[i],kernel,K=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nihW8XSYaD5a",
        "outputId": "2c212817-0ff0-487e-fd63-d13161ff14cd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[0],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[0],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[1],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[1],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[2],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[2],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[2],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[3],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[3],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[3],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[4],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[4],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[4],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[5],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[5],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[5],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[6],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[6],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[6],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[7],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[7],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[7],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[8],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[8],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[8],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[9],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(gaussian_noise_imgs[9],cmap='gray')\n",
        "plt.title('Gaussian Noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(wiener_corrected[9],cmap='gray')\n",
        "plt.title('Noise Removed image')\n",
        "plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysoq-vEcaGQq"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bawssaz0Zz5K"
      },
      "source": [
        "## **Inducing motion blur and de-blurring the image**\n",
        "\n",
        "###<u>Relevance to our project</u>\n",
        "\n",
        "###For the project choosen, the most ubiquitous of all noise is the motion blur due to the moving nature of host camera. To mimic that, we use the blur function where an identity mask is used to convolve the image to bring about a blurry look.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "###The noise is cleaned using the Wiener filtering method. A gaussian kernel is created (default 3x3 filter) using normal random numbers. That kernel is passed into the Wiener filter method. The constant K is the ratio of Spectral Power Density of the noisy image and the Spectral Power Density of the filter kernel used. We pass it as 10 instead of calculating it manually in the code each time.\n",
        "\n",
        "###Finally after the Fast Fourier Transform function is used, the output must be inverted using Inverse Fast Fourier Transform Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk8FOJ_SaH7h"
      },
      "outputs": [],
      "source": [
        "# Blurring and de blurring\n",
        "def blur(img, kernel_size = 3):\n",
        "\tdummy = np.copy(img)\n",
        "\th = np.eye(kernel_size) / kernel_size\n",
        "\tdummy = convolve2d(dummy, h, mode = 'valid')\n",
        "\treturn dummy\n",
        "\n",
        "blur_imgs = np.zeros((10,391,870))\n",
        "\n",
        "clean_blur = np.full_like(imgs,0)\n",
        "\n",
        "for i in range(10):\n",
        "  blur_imgs[i] = blur(imgs[i],10)\n",
        "\n",
        "kernel = gaussian_kernel()\n",
        "\n",
        "for i in range(10):\n",
        "  clean_blur[i] = wiener_filter(imgs[i],kernel,K=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L-XHsqIWaJL4",
        "outputId": "d3c3fa9a-3060-412e-a587-b30837fc8af1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[0],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[0],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[1],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[1],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[2],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[2],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[2],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[3],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[3],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[3],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[4],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[4],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[4],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[5],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[5],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[5],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[6],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[6],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[6],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[7],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[7],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[7],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[8],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[8],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[8],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[9],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(blur_imgs[9],cmap='gray')\n",
        "plt.title('Motion blur image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(clean_blur[9],cmap='gray')\n",
        "plt.title('De-blurred image')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taFUF1cg3kqx"
      },
      "source": [
        "## Sharpening of Images\n",
        "\n",
        "### Sharpening basically means to highlight transitions in intensity of a image. Sharpening filters are high pass spatial filters.\n",
        "\n",
        "### Sharpening can be accomplised by spatial differentiation (i.e the rate of change of pixels intensities / colors in the spatial plane)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5910ogB64Mk8"
      },
      "source": [
        "### Method 1  : Laplacian\n",
        "\n",
        "#### The laplacian derivative (first degree) = Vf = df'/dx + df'/dy. <br>\n",
        "Here, df'/dx = f(x + 1, y) - f(x, y), and df'/dy = f(x, y + 1) - f(x, y).\n",
        "\n",
        "#### The laplacian derivative (second degree) = V^2f = d^2f'/dx^2 + d^2f'/dy^2. <br>\n",
        "Here, df'/dx = f(x + 1, y) + f(x - 1, y) - 2f(x, y), and d^2f'/dy = f(x, y + 1) + f(x, y - 1) - 2f(x, y).\n",
        "\n",
        "Used for removing blurring + enhancing (highlighting) the edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9McsSfdq6D2l"
      },
      "outputs": [],
      "source": [
        "def laplacian_filter_4(images):\n",
        "  \n",
        "# As smoothing is achieved by smoothing in the neighbourhood, we can say that sharpening is done by\n",
        "# spatial differentiation, where the strenght of the derivative operation is directly proportional to the magnitude of \n",
        "# intensity discontinuity at that point.\n",
        "# Areas of edges (areas of high varying intensities) are emphasized while de emphasizes areas of slow varying intensities.\n",
        "\n",
        "  laplacian_filter = []\n",
        "  sharpened_images = []\n",
        "\n",
        "  for image in images:\n",
        "    # Image with padding for convineince (for use with a 3X3 filter).\n",
        "    padded_image = image.copy()\n",
        "    padded_image = cv2.copyMakeBorder(padded_image, 2, 2, 2, 2, cv2.BORDER_CONSTANT, None, 0)\n",
        "    img_width, img_height = padded_image.shape[0:2]\n",
        "\n",
        "    # Sharpening using first derivative (i.e Laplacian), non rotated no diagonal consideration.\n",
        "    # partial_derivative_on_x = f(x + 1, y) - f(x, y)\n",
        "    # partial_derivative_on_x_2 = f(x + 1, y) + f(x - 1, y) - 2f(x, y)\n",
        "\n",
        "    # partial_derivative_on_y = f(x, y + 1) - f(x, y)\n",
        "    # partial_derivative_on_y_2 = f(x, y + 1) + f(x, y - 1) - 2f(x, y)\n",
        "\n",
        "    # combining, laplacian = f(x + 1, y) + f(x - 1, y) + f(x, y + 1) + f(x, y -1) - 4f(x, y)\n",
        "    # For convinience, as the center coeff is -ve, negating the full filter so it can be added directly with base / original image.\n",
        "\n",
        "    # in filter form, we have for n4 : \n",
        "    laplacian_filter_4 = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n",
        "    laplacian_filtered_image_4 = cv2.filter2D(image, -1, laplacian_filter_4)\n",
        "    laplacian_filter.append(laplacian_filtered_image_4)\n",
        "    sharpened_image = cv2.addWeighted(image, 1, laplacian_filtered_image_4, 2, gamma=0)\n",
        "    sharpened_images.append(sharpened_image)\n",
        "\n",
        "  return laplacian_filter, sharpened_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doCoplYw8Hcw"
      },
      "outputs": [],
      "source": [
        "def laplacian_filter_8(images):\n",
        "  laplacian_filter = []\n",
        "  sharpened_images = []\n",
        "\n",
        "  for image in images:\n",
        "    # Image with padding for convineince (for use with a 3X3 filter).\n",
        "    padded_image = image.copy()\n",
        "    padded_image = cv2.copyMakeBorder(padded_image, 2, 2, 2, 2, cv2.BORDER_CONSTANT, None, 0)\n",
        "    img_width, img_height = padded_image.shape[0:2]\n",
        "\n",
        "    # Sharpening using second derivative (i.e Laplacian), with diagonal consideration.\n",
        "    # For convinience, as the center coeff is -ve, negating the full filter so it can be added directly with base / original image.\n",
        "\n",
        "    # in filter form, we have for n8 : \n",
        "    laplacian_filter_8 = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
        "    laplacian_filtered_image_8 = cv2.filter2D(image, -1, laplacian_filter_8)\n",
        "    laplacian_filter.append(laplacian_filtered_image_8)\n",
        "\n",
        "    sharpened_image_8 = cv2.addWeighted(image, 1, laplacian_filtered_image_8, 1.5, gamma=0)\n",
        "    sharpened_images.append(sharpened_image_8)\n",
        "\n",
        "  return laplacian_filter, sharpened_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9l8Dr8G_pwQ"
      },
      "source": [
        "\n",
        "### Method 2. Unsharp masking method for sharpening (primarily used by publishing industry.)\n",
        "### First, the image is to be blurred. Subtract said blurred image from the original. This becomes the 'mask'.\n",
        "### Then, add the mask to hte original image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtZlNzTj_5dY"
      },
      "outputs": [],
      "source": [
        "def unsharp_masking(images, blurred_images):\n",
        "  unsharp_mask = [] * len(images)\n",
        "  sharpened_images = [] * len(images)\n",
        "\n",
        "  for i in range(0, len(images)):\n",
        "    mask = cv2.addWeighted(images[i], 1, blurred_images[i], -1, gamma=0)\n",
        "    sharpened_image = cv2.addWeighted(images[i], 1, mask, 3, gamma=0) \n",
        "    unsharp_mask.append(mask)\n",
        "    sharpened_images.append(sharpened_image)\n",
        "\n",
        "  return unsharp_mask, sharpened_images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc77YQ6MIJHr"
      },
      "source": [
        "## Method 3 : Sorbel edge detector (Approximation of Roberts Cross Gradient)\n",
        "### Here, image is processed in the X and Y axis one after another. The new image is the sum of X and Y results (i.e the edges highlighted) of the image.\n",
        "### Calculation is based on gradient of images intensity. Here, gradient = Vf = [df'/dx    df'/dy].\n",
        "### This vector points in the direction of the greatest rate of change of intensity at some location(x, y). The magnitude of this vector is the value of\n",
        "### rate of change in direction of said gradiant vector. Rather than finding magnitude via sqrt(Vf.x^2 + Vf.y^2), we can do : \n",
        "### mag(x, y) = |Vf.x| + |Vf.y|\n",
        "\n",
        "### The x derivate is : [1, 0, -1] and the 1D gaussian filter is [1, 2, 1]. Here, the values (1, 2) are important as we give more importance to the center compared to the rest.\n",
        "### The gaussian filter * x derivative = [[1, 0, -1], [2, 0, -2], [1, 0, -1]] (gx or sorbel x)\n",
        "### Similarly, for y derivative we have [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brr2bZ4CFSKK"
      },
      "outputs": [],
      "source": [
        "def sorbel(images):\n",
        "    sorbel_filter = []\n",
        "    sharpened_images = []\n",
        "\n",
        "    for image in images:\n",
        "      # Image with padding for convineince (for use with a 3X3 filter).\n",
        "      padded_image = image.copy()\n",
        "      padded_image = cv2.copyMakeBorder(padded_image, 2, 2, 2, 2, cv2.BORDER_CONSTANT, None, 0)\n",
        "      img_width, img_height = padded_image.shape[0:2]\n",
        " \n",
        "      gx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n",
        "      sorbel_x_filtered = cv2.filter2D(image, -1, gx)\n",
        "\n",
        "      gy = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "      sorbel_y_filtered = cv2.filter2D(image, -1, gy)\n",
        "\n",
        "      sorbel_filtered = cv2.addWeighted(sorbel_x_filtered, 1, sorbel_y_filtered, 1, gamma=0)\n",
        "      sorbel_filter.append(sorbel_filtered)\n",
        "      sharpened_image = cv2.addWeighted(image, 1, sorbel_filtered, 2, gamma=0)\n",
        "      sharpened_images.append(sharpened_image)\n",
        "\n",
        "    return sorbel_filter, sharpened_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "bLIGaMl2UtxV",
        "outputId": "33ba37e2-2267-4466-e256-e23de0fbaa08"
      },
      "outputs": [],
      "source": [
        "# Driver code for sharpening\n",
        "imgs = imgs.copy()\n",
        "\n",
        "org_images = [] \n",
        "\n",
        "# plt.imshow does not accept BGR, so converting images to RGB.\n",
        "for i in range(0, len(imgs)):\n",
        "  org_images.append(cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB))\n",
        "\n",
        "imgs = org_images\n",
        "\n",
        "# blur the images (using Gaussian blur)\n",
        "gaussian_blurred_images = blur_images(imgs)\n",
        "\n",
        "# laplacian filter and the sharpened image (n4)\n",
        "laplacian_filter_n4, sharpened_images_laplacian_4 = laplacian_filter_4(imgs)\n",
        "\n",
        "# laplacian filter and the sharpened image (n8)\n",
        "laplacian_filter_n8, sharpened_images_laplacian_8 = laplacian_filter_8(imgs)\n",
        "\n",
        "# Unsharp mask and sharpened images\n",
        "unsharp_mask, sharpened_images_unsharp = unsharp_masking(imgs, gaussian_blurred_images)\n",
        "\n",
        "# sorbel mask and sharpened_images\n",
        "sorbel_filter, sharpened_images_sorbel = sorbel(imgs)\n",
        "\n",
        "for i in range(len(imgs)):\n",
        "  plt.figure(figsize=(100,9))\n",
        "  \n",
        "  plt.subplot(1,9,1)\n",
        "  plt.imshow(imgs[i])\n",
        "  plt.title('Original image')\n",
        "  plt.axis('off')\n",
        "  \n",
        "  plt.subplot(1,9,2)\n",
        "  plt.imshow(sharpened_images_laplacian_4[i])\n",
        "  plt.title('Sharpened image laplacian n4')\n",
        "  plt.axis('off')\n",
        "  \n",
        "  plt.subplot(1,9,3)\n",
        "  plt.imshow(sharpened_images_laplacian_8[i])\n",
        "  plt.title('Sharpened image laplacian n8')\n",
        "  plt.axis('off')\n",
        "  \n",
        "  plt.subplot(1,9,4)\n",
        "  plt.imshow(sharpened_images_unsharp[i])\n",
        "  plt.title('Sharpened image unsharp masking')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1, 9, 5)\n",
        "  plt.imshow(sharpened_images_sorbel[i])\n",
        "  plt.title('Sharpened image using sorbel')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,6)\n",
        "  plt.imshow(laplacian_filter_n4[i])\n",
        "  plt.title('Laplacian n4 filter')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,7)\n",
        "  plt.imshow(laplacian_filter_n8[i])\n",
        "  plt.title('Laplacian n8 filter')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,8)\n",
        "  plt.imshow(unsharp_mask[i])\n",
        "  plt.title('unsharp mask')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,9)\n",
        "  plt.imshow(sorbel_filter[i])\n",
        "  plt.title('sorbel mask')\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07V0VUnaI1Vp"
      },
      "source": [
        "## Affine Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9KPjgDcH2ly"
      },
      "source": [
        "#### Relavance to project : Camera calibration (i.e converting 3D point in world space to a 2D pixel) parameters include Rotation and Translation matrices, when going from world coordinates to camera coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PloMwc9kI5-p"
      },
      "outputs": [],
      "source": [
        "def translate(images):\n",
        "\n",
        "  translated_images = []\n",
        "\n",
        "  for i in range(len(images)):\n",
        "    shape = images[i].shape\n",
        "\n",
        "    # Using homogeneous coordinates to represent 2D point (x, y) as 3D point(x', y', z')\n",
        "    # so that to go from 3D to 2D point we must do (x' / z', y' / z')\n",
        "\n",
        "    # Translation.\n",
        "    # Matrix requires so that (x, y, 1) -> (x + t2, y + t1, 1) is : \n",
        "    t1 = i * 10\n",
        "    t2 = i * 10\n",
        "\n",
        "    # Note, matrix is premultiplied (i.e lies on the left of vector, so vector is column vector here.)\n",
        "    # It is negated here because the (x, y) of translated image = source_image(x + t2, y + t1), so for visual appeal negating t2 and t1 (will be changed in future)\n",
        "    translation_matrix = np.array([[1, 0, -t2], [0, 1, -t1], [0, 0, 1]])\n",
        "\n",
        "    image = images[i]\n",
        "    \n",
        "    translated_image = image.copy()\n",
        "    for i in range(0, shape[0]):\n",
        "      for j in range(0, shape[1]):\n",
        "          homogeneous_coord = [i, j, 1]\n",
        "          coord = translation_matrix.dot(homogeneous_coord)\n",
        "          coord = coord[0:2]\n",
        "          if coord[0] < 0 or coord[0] >= translated_image.shape[0] or coord[1] < 0 or coord[1] >= translated_image.shape[1]:\n",
        "              translated_image[i, j, 0] = 0\n",
        "              translated_image[i, j, 1] = 0\n",
        "              translated_image[i, j, 2] = 0\n",
        "              continue\n",
        "\n",
        "\n",
        "          translated_image[i, j, 0] = image[int(coord[0]), int(coord[1]), 0]\n",
        "          translated_image[i, j, 1] = image[int(coord[0]), int(coord[1]), 1]\n",
        "          translated_image[i, j, 2] = image[int(coord[0]), int(coord[1]), 2]\n",
        "\n",
        "    translated_images.append(translated_image)\n",
        "\n",
        "  return translated_images\n",
        "\n",
        "def rotate(images):\n",
        "  rotated_images = [] * len(images)\n",
        "  for i in range(len(images)):\n",
        "    # Rotation around z axis by theta degree CCW\n",
        "    theta = np.deg2rad(i * 2)\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [0, 0, 1]])\n",
        "    image = images[i].copy()\n",
        "    shape = image.shape\n",
        "\n",
        "    rotated_image = image.copy()\n",
        "    for i in range(0, shape[0]):\n",
        "        for j in range(0, shape[1]):\n",
        "            homogeneous_coord = [i, j, 1]\n",
        "            coord = rotation_matrix.dot(homogeneous_coord)\n",
        "            coord = coord[0:2]\n",
        "            if coord[0] < 0 or coord[0] >= shape[0] or coord[1] < 0 or coord[1] >= shape[1]:\n",
        "                rotated_image[i, j, 0] = 0\n",
        "                rotated_image[i, j, 1] = 0\n",
        "                rotated_image[i, j, 2] = 0\n",
        "                continue\n",
        "\n",
        "\n",
        "            rotated_image[i, j, 0] = image[int(coord[0]), int(coord[1]), 0]\n",
        "            rotated_image[i, j, 1] = image[int(coord[0]), int(coord[1]), 1]\n",
        "            rotated_image[i, j, 2] = image[int(coord[0]), int(coord[1]), 2]\n",
        "\n",
        "\n",
        "    rotated_images.append(rotated_image)\n",
        "\n",
        "  return rotated_images\n",
        "\n",
        "def scale(images):\n",
        "  \n",
        "  scaled_images = [] * len(images)\n",
        "\n",
        "  for i in range(len(images)):\n",
        "        # Scaling\n",
        "    s1 = float(i + 0.1) / 6\n",
        "    s2 = float(i + 0.1) / 6\n",
        "\n",
        "    shape = images[i].shape\n",
        "    image = images[i].copy()\n",
        "\n",
        "    # Scaling matrix is required so it takes (x, y, 1) to (xs1, ys2, 1). Matrix for this is : \n",
        "    scaling_matrix = np.array([[s1, 0, 0], [0, s2, 0], [0, 0, 1]]) # Column vector required.\n",
        "\n",
        "    scaled_image = image.copy()\n",
        "    scaled_image = cv2.resize(scaled_image, (int(shape[1] * s1), int(shape[0] *  s2)))\n",
        "\n",
        "    for i in range(0, shape[0]):\n",
        "      for j in range(0, shape[1]):\n",
        "          homogeneous_coord = [i, j, 1]\n",
        "          coord = scaling_matrix.dot(homogeneous_coord)\n",
        "          coord = coord[0:2]\n",
        "          if coord[0] < 0 or coord[0] >= scaled_image.shape[0] or coord[1] < 0 or coord[1] >= scaled_image.shape[1]:\n",
        "              continue\n",
        "\n",
        "\n",
        "          scaled_image[int(coord[0]), int(coord[1]), 0] = image[i, j, 0]\n",
        "          scaled_image[int(coord[0]), int(coord[1]), 1] = image[i, j, 1]\n",
        "          scaled_image[int(coord[0]), int(coord[1]), 2] = image[i, j, 2]\n",
        "\n",
        "    scaled_images.append(scaled_image)\n",
        "\n",
        "  return scaled_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qNvnva8QZnB"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BHwo6SFZlG-c",
        "outputId": "27432b56-608d-476e-9672-88a59198d619"
      },
      "outputs": [],
      "source": [
        "# Visualize affine transformations\n",
        "\n",
        "imgs = imgs.copy()\n",
        "\n",
        "scaled = scale(imgs)\n",
        "for i in range(len(scaled)):\n",
        "  print(\"scaled by : \", (i + 0.1) / 6,', ', (i + 0.1) / 6)\n",
        "  cv2_imshow(scaled[i])\n",
        "\n",
        "translated = translate(imgs)\n",
        "\n",
        "for i in range(len(translated)):\n",
        "  print(\"translated by : \" ,i * 10 , \", \" ,i * 10)\n",
        "  cv2_imshow(translated[i])\n",
        "\n",
        "rotated = rotate(imgs)\n",
        "for i in range(len(translated)):\n",
        "  print('rotated by : ', np.deg2rad(i * 2))\n",
        "  cv2_imshow(rotated[i])\n",
        "\n",
        "imgs = imgs.copy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MHtiHlwGK2d"
      },
      "source": [
        "## Stereo Vision\n",
        "Process of reconstructing 3D geometry based on images from multiple viewpoints (2 viewpoints in our application). Works very similar as human vision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "LdLqvgfoFe6L",
        "outputId": "1091de81-06e4-4f24-b533-a9a80d3e3bb8"
      },
      "outputs": [],
      "source": [
        "exp = cv2.imread('images/DrivingStereo_dataset/Stereo/disparity_exp.png')\n",
        "cv2_imshow(exp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrIL6mErJFIi"
      },
      "source": [
        "## Disparity map generation : Map of difference in location of all points from both camera angles (left and right)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "LN0t_qZCJuCJ",
        "outputId": "e74a7cba-3ce5-4664-fd87-e25e2e194b30"
      },
      "outputs": [],
      "source": [
        "left = cv2.imread('images/DrivingStereo_dataset/Stereo/left.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "right = cv2.imread('images/DrivingStereo_dataset/Stereo/right.jpg'  ,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "left = cv2.resize(left,None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_LINEAR)\n",
        "right  = cv2.resize(right,None, fx = 0.5, fy = 0.5, interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "print(\"Left\")\n",
        "cv2_imshow(left)\n",
        "\n",
        "print(\"Right\")\n",
        "cv2_imshow(right)\n",
        "\n",
        "stereo = cv2.StereoBM_create(numDisparities=0, blockSize=21)\n",
        "disparity_raw = stereo.compute(left, right)\n",
        "print(\"Disparity Map\")\n",
        "cv2_imshow(disparity_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbqLN863_wu9",
        "outputId": "e70c6ca3-54be-40eb-a5b2-20e259e997f6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Shankar0x/DepthSensingDatasets.git images\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rqk8yTn_-A0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import scipy.ndimage as ndimage\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "import math\n",
        "import statistics\n",
        "import glob\n",
        "import random\n",
        "#from google.colab.patches import cv2_imshow\n",
        "from scipy import signal\n",
        "from math import log10, sqrt\n",
        "from skimage.util import random_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PE5ljUhAB42",
        "outputId": "e0cce148-904b-4c43-d3ce-c3c4f8d21fa5"
      },
      "outputs": [],
      "source": [
        "a = np.asarray(Image.open('images/Reduced_dataset/000001/left.png'))\n",
        "print(\"The shape of the images are: \",a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD37_k0wADsl",
        "outputId": "b2c31ef4-ff77-4cc8-9d7f-f3bae47d0fbb"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "left_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/left.png').convert('L')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/left.png').convert('L')\n",
        "    data = np.asarray(image)\n",
        "    left_imgs[i-1] = data\n",
        "left_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBTZyGQVAFkk",
        "outputId": "c974adce-116c-4bbc-e445-bade8b413fc4"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "right_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/right.png').convert('L')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/right.png').convert('L')\n",
        "    data = np.asarray(image)\n",
        "    right_imgs[i-1] = data\n",
        "right_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZYYlmpdAHYd",
        "outputId": "309b64e6-1375-4aa1-fbd2-e53c6c48db9e"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "right_disp_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/right_disp.png')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/right_disp.png')\n",
        "    data = np.asarray(image)\n",
        "    right_disp_imgs[i-1] = data\n",
        "right_disp_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuJZa9y-6zag",
        "outputId": "765b1dfb-345b-47da-a196-2e750b6cd211"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "left_disp_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/left_disp.png')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/left_disp.png')\n",
        "    data = np.asarray(image)\n",
        "    left_disp_imgs[i-1] = data\n",
        "left_disp_imgs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SteEeDs7GZY6"
      },
      "source": [
        "### Displaying left and right stereo images and their respective disparity maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "Qc2Mkzus6zah",
        "outputId": "4c01ca0d-9564-4dcf-da29-733da72ba11f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(3,4,figsize=(12,8))\n",
        "\n",
        "for i in range(3):\n",
        "        ax[i,0].title.set_text('Left stereo image')\n",
        "        ax[i,0].imshow(left_imgs[i], cmap='gray')\n",
        "        ax[i,0].axis('off')\n",
        "        ax[i,1].title.set_text('Left disparity map')\n",
        "        ax[i,1].imshow(left_disp_imgs[i],cmap='gray')\n",
        "        ax[i,1].axis('off')\n",
        "        ax[i,2].title.set_text('Right stereo image')\n",
        "        ax[i,2].imshow(right_imgs[i], cmap='gray')\n",
        "        ax[i,2].axis('off')\n",
        "        ax[i,3].title.set_text('Right disparity image')\n",
        "        ax[i,3].imshow(right_disp_imgs[i],cmap='gray')\n",
        "        ax[i,3].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiamGPhRGZY6"
      },
      "source": [
        "# Shankar's Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4MUL195GZY6"
      },
      "source": [
        "### Unsharp masking and highboost filtering\n",
        "<b> Unsharp masking </b>\n",
        "<br>\n",
        "<p> In unsharp masking, the blurred version of the image is taken as a mask which is then subtracted from the original image. This gives a clearer image as the inital blur is removed. </p>\n",
        "<b> Highboost filtering </b>\n",
        "<br>\n",
        "<p> In image processing, it is often desirable to emphasize high frequency components representing the image details without eliminating low frequency components (such as sharpening). The high-boost filter can be used to enhance high frequency component. </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gkp9Q3166zai"
      },
      "outputs": [],
      "source": [
        "def unsharp_highboost_filtering(k, img):\n",
        "    f = img\n",
        "    fig, ax = plt.subplots(3,3,figsize=(20,16))\n",
        "    ax[0,0].title.set_text('Original Image')\n",
        "    ax[0,0].imshow(f, cmap='gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    # input image in frequency domain, F(u,v)\n",
        "    F = np.fft.fftshift(np.fft.fft2(f))\n",
        "\n",
        "    ax[0,1].title.set_text('DFT centered')\n",
        "    ax[0,1].imshow(np.log1p(np.abs(F)), cmap='gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    # Gaussian Low Pass Filter\n",
        "    M,N = F.shape\n",
        "    H = np.zeros((M,N), dtype=np.float32)\n",
        "    D0 = 10\n",
        "    for u in range(M):\n",
        "        for v in range(N):\n",
        "            D = np.sqrt((u-M/2)**2 + (v-N/2)**2)\n",
        "            H[u,v] = np.exp(-D**2/(2*D0*D0))\n",
        "\n",
        "    ax[0,2].title.set_text('Gaussian Low Pass Filter')\n",
        "    ax[0,2].imshow(H, cmap='gray')\n",
        "    ax[0,2].axis('off')\n",
        "\n",
        "    # create fLP(x,y) (smoothed image)\n",
        "    FLP = H * F    \n",
        "    FLP = np.fft.ifftshift(FLP)\n",
        "    fLP = np.abs(np.fft.ifft2(FLP))\n",
        "\n",
        "    ax[1,0].title.set_text('DFT of image after GLPF centered')\n",
        "    ax[1,0].imshow(fLP, cmap='gray')\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    # create mask g(x,y)\n",
        "    gMask = f - fLP\n",
        "\n",
        "    ax[1,1].title.set_text('Mask (image - blurred image)')\n",
        "    ax[1,1].imshow(gMask, cmap='gray')\n",
        "    ax[1,1].axis('off')\n",
        "\n",
        "    # unsharp masking\n",
        "    g = f + 1*gMask\n",
        "\n",
        "    ax[1,2].title.set_text('Unsharp masking')\n",
        "    ax[1,2].imshow(g, cmap='gray')\n",
        "    ax[1,2].axis('off')\n",
        "\n",
        "    g = np.clip(g, 0, 255)\n",
        "    ax[2,0].title.set_text('Unsharp masking (clipped)')\n",
        "    ax[2,0].imshow(g, cmap='gray')\n",
        "    ax[2,0].axis('off')\n",
        "\n",
        "    # Highboost filtering\n",
        "    G = (1 + k*(1-H))*F\n",
        "    g = np.abs(np.fft.ifft2(np.fft.ifftshift(G)))\n",
        "    ax[2,1].title.set_text('Highboost filtering')\n",
        "    ax[2,1].imshow(g, cmap='gray')\n",
        "    ax[2,1].axis('off')\n",
        "\n",
        "    g = np.clip(g, 0, 255)\n",
        "    ax[2,2].title.set_text('Highboost filtering (clipped)')\n",
        "    ax[2,2].imshow(g, cmap='gray')\n",
        "    ax[2,2].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "5oKAvvBA6zai",
        "outputId": "5b852a37-c8b7-49bc-fbbd-3b66c491c82a"
      },
      "outputs": [],
      "source": [
        "unsharp_highboost_filtering(2, left_imgs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImDNDUvIGZY7"
      },
      "source": [
        "### Laplacian Filtering\n",
        "<p> Laplacian filtering is a technique used to make edge detection easier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDrEXf_y6zaj"
      },
      "outputs": [],
      "source": [
        "def laplacian_filtering(img):\n",
        "    f = img\n",
        "    # normalizing the image\n",
        "    f = f / 255\n",
        "\n",
        "    fig, ax = plt.subplots(2,2,figsize=(22,16))\n",
        "    ax[0,0].title.set_text('Original Image')\n",
        "    ax[0,0].imshow(f,cmap='gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    # transform into frequency domain\n",
        "    F = np.fft.fftshift(np.fft.fft2(f))\n",
        "\n",
        "    plt.figure(dpi=150)\n",
        "    ax[0,1].title.set_text('DFT of image (centered)')\n",
        "    ax[0,1].imshow(np.log1p(np.abs(F)),cmap='gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    # Laplacian Filter\n",
        "    P,Q = F.shape\n",
        "    H = np.zeros((P,Q), dtype=np.float32)\n",
        "    for u in range(P):\n",
        "        for v in range(Q):\n",
        "            H[u,v] = -4*np.pi*np.pi*((u-P/2)**2 + (v-Q/2)**2)\n",
        "\n",
        "    # Laplacian image\n",
        "    Lap = H * F\n",
        "    Lap = np.fft.ifftshift(Lap)\n",
        "    Lap = np.real(np.fft.ifft2(Lap))\n",
        "\n",
        "    # convert the Laplacian Image value into range [-1,1]\n",
        "    OldRange = np.max(Lap) - np.min(Lap)\n",
        "    NewRange = 1 - -1\n",
        "    LapScaled = (((Lap - np.min(Lap)) * NewRange) / OldRange) + -1\n",
        "\n",
        "    ax[1,0].title.set_text('Laplacian of the image')\n",
        "    ax[1,0].imshow(LapScaled,cmap='gray')\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    # image ehancement\n",
        "    c = -1\n",
        "    g = f + c*LapScaled\n",
        "    g = np.clip(g, 0, 1)\n",
        "\n",
        "    ax[1,1].title.set_text('Laplacian Filtered')\n",
        "    ax[1,1].imshow(g,cmap='gray')\n",
        "    ax[1,1].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "QX8SCpRC6zaj",
        "outputId": "d1e21e36-8467-4efa-ddc4-d8820e3fd1b5"
      },
      "outputs": [],
      "source": [
        "laplacian_filtering(left_imgs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odwZuwd8GZY8"
      },
      "source": [
        "### Inducing periodic noise and removing using Band Reject filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQkNB3VU6zak"
      },
      "outputs": [],
      "source": [
        "def ideal_low_pass_filter(image, d0):\n",
        "  m, n = image.shape\n",
        "  \n",
        "  H = np.zeros((m, n), dtype=np.float32)\n",
        "  for u in range(m):\n",
        "    for v in range(n):\n",
        "      d = np.sqrt((u - m / 2)**2 + (v - n / 2) ** 2)\n",
        "      if d <= d0:\n",
        "        # Inside the allowed - frequency range\n",
        "        H[u, v] = 1\n",
        "      else:\n",
        "        H[u, v] = 0\n",
        "  \n",
        "  return H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6BFubdGGZY8"
      },
      "outputs": [],
      "source": [
        "def periodic_noise(img):\n",
        "    f = img\n",
        "    F = np.fft.fftshift(np.fft.fft2(f))\n",
        "    x = np.linspace(1,1080,1080)\n",
        "    y = np.linspace(1, 860, 860)\n",
        "    x_1, y_1 = np.meshgrid(x, y)\n",
        "    mysinusoidal = 15*np.sin(2*np.pi/14*x_1+2*np.pi/14*y_1)\n",
        "    noisy_img = left_imgs[0]+mysinusoidal\n",
        "    return noisy_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgpD60oJ6zak"
      },
      "outputs": [],
      "source": [
        "def band_reject(img):\n",
        "\n",
        "    f = img\n",
        "    F = np.fft.fftshift(np.fft.fft2(f))\n",
        "    \n",
        "    fig, ax = plt.subplots(3,2,figsize=(26,34))\n",
        "\n",
        "    ax[0,0].title.set_text('Original Image')\n",
        "    ax[0,0].imshow(f,cmap='gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    ax[0,1].title.set_text('DFT of the image (centered)')\n",
        "    ax[0,1].imshow(np.log1p(np.abs(F)), cmap='gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    noisy_img = periodic_noise(img)\n",
        "\n",
        "    ax[1,0].title.set_text('Noisy image')\n",
        "    ax[1,0].imshow(noisy_img, cmap='gray')\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    F_new = np.fft.fftshift(np.fft.fft2(noisy_img))\n",
        "\n",
        "    ax[1,1].title.set_text('DFT of noisy image')\n",
        "    ax[1,1].imshow(np.log1p(np.abs(F_new)), cmap='gray')    \n",
        "    ax[1,1].axis('off')\n",
        "\n",
        "    H1 = ideal_low_pass_filter(left_imgs[0], 130)\n",
        "    H2 = ideal_low_pass_filter(left_imgs[0], 90)\n",
        "    H3 = H1 - H2\n",
        "    H3 = 1 - H3\n",
        "\n",
        "    cleaned_dft = F_new*H3 \n",
        "    ax[2,1].title.set_text('DFT after band reject filter')\n",
        "    ax[2,1].imshow(np.log1p(np.abs(cleaned_dft)),cmap='gray')\n",
        "    ax[2,1].axis('off')\n",
        "\n",
        "    ift_cleaned = np.fft.ifftshift(cleaned_dft)\n",
        "    ift_cleaned = np.fft.ifft2(ift_cleaned)\n",
        "    ax[2,0].title.set_text('Cleaned using Band Reject')\n",
        "    ax[2,0].imshow((np.abs(ift_cleaned)),cmap='gray')\n",
        "    ax[2,0].axis('off')\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1-cVGujc6zak",
        "outputId": "2370a6f3-238d-4178-c0ce-5c682f4ddd96"
      },
      "outputs": [],
      "source": [
        "band_reject(left_imgs[0]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nzoeBlJGZY9"
      },
      "source": [
        "### Band pass filter\n",
        "<p> Band pass filter is a type of high pass filter. The output of bandpass filter essentially contains the edges of the image. Adding this image on the original image will result in a sharper image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iUR-foZGZY9"
      },
      "outputs": [],
      "source": [
        "def bandpass(img):\n",
        "    fig, ax = plt.subplots(1,4,figsize=(28,50))\n",
        "    H1 = ideal_low_pass_filter(img, 300)\n",
        "    H2 = ideal_low_pass_filter(img, 100)\n",
        "    H3 = H1 - H2\n",
        "    ax[3].title.set_text('Sharpened by band pass filtering')\n",
        "    ax[3].imshow(img,cmap='gray') \n",
        "    ax[3].axis('off')\n",
        "\n",
        "    ax[1].title.set_text('Band pass filter')\n",
        "    ax[1].imshow(H3, cmap='gray')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    F_new = np.fft.fftshift(np.fft.fft2(img))\n",
        "    inv_conv = F_new*H3 \n",
        "    ift_cleaned = np.fft.ifftshift(inv_conv)\n",
        "    ift_cleaned = np.fft.ifft2(ift_cleaned)\n",
        "\n",
        "    ax[2].title.set_text('Band pass filtered image')\n",
        "    ax[2].imshow((np.abs(ift_cleaned)),cmap='gray')\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    test_img = img+np.abs(ift_cleaned)\n",
        "    ax[0].title.set_text('Original image')\n",
        "    ax[0].imshow(test_img,cmap='gray')  \n",
        "    ax[0].axis('off')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "WeIaNwHjGZY9",
        "outputId": "546eb085-c673-4fa5-a813-4e2d9df4fa39"
      },
      "outputs": [],
      "source": [
        "bandpass(left_imgs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSnd3oZ4GZY-"
      },
      "source": [
        "### Notch filtering\n",
        "<p> This is a filtering technique used to remove periodic noise by adding notches on the DFT of the noisy image corresponding to the sinusoidal component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JMYcTqUGZY-"
      },
      "outputs": [],
      "source": [
        "def notch_filtering(img):\n",
        "    noisy_img = periodic_noise(img)\n",
        "    bg = np.zeros_like(img)\n",
        "    bg = bg + 255\n",
        "    c1_cords = (img.shape[1]//2-78, img.shape[0]//2-70)\n",
        "    c2_cords = (img.shape[0]//2+190, img.shape[1]//2-50)\n",
        "    radius = 15\n",
        "    color = (0,0,0)\n",
        "    thickness = -1\n",
        "    image1 = cv2.circle(bg, c1_cords, radius, color, thickness)\n",
        "    image2 = cv2.circle(bg, c2_cords, radius, color, thickness)\n",
        "    image = image1+image2\n",
        "    \n",
        "    F_orig = np.fft.fftshift(np.fft.fft2(img))\n",
        "\n",
        "    F = np.fft.fftshift(np.fft.fft2(noisy_img))\n",
        "    F_new = F*image \n",
        "    fig, ax = plt.subplots(3,2,figsize=(26,34))\n",
        "\n",
        "    ax[0,0].title.set_text('Original image')\n",
        "    ax[0,0].imshow(img,cmap='gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    ax[0,1].title.set_text('DFT of original image')\n",
        "    ax[0,1].imshow(np.abs(np.log1p(F_orig)),cmap='gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    ax[1,0].title.set_text('Periodic noisy image')\n",
        "    ax[1,0].imshow(noisy_img,cmap='gray')\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    ax[1,1].title.set_text('DFT of periodic image')\n",
        "    ax[1,1].imshow(np.abs(np.log1p(F)),cmap='gray')\n",
        "    ax[1,1].axis('off')\n",
        "\n",
        "    ift_cleaned = np.fft.ifftshift(F_new)\n",
        "    ift_cleaned = np.fft.ifft2(ift_cleaned)\n",
        "\n",
        "    ax[2,0].title.set_text('Notch filtered image')\n",
        "    ax[2,0].imshow(np.abs(ift_cleaned),cmap='gray')\n",
        "    ax[2,0].axis('off')\n",
        "\n",
        "    ax[2,1].title.set_text('DFT of notch filtered image')\n",
        "    ax[2,1].imshow(np.abs(np.log1p(F_new)),cmap='gray')\n",
        "    ax[2,1].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oijyt4ljGZY-",
        "outputId": "078b9619-5f8c-47d2-efdb-842c18e65824"
      },
      "outputs": [],
      "source": [
        "notch_filtering(left_imgs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdqjTZN-GZY-"
      },
      "source": [
        "# Sneha's Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwNQ9RKtGZY-"
      },
      "outputs": [],
      "source": [
        "def pxIsInImgRange(x, y, w, h):\n",
        "  if (0<=x) and (x < w): \n",
        "    if (0<=y) and (y < h):\n",
        "      return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXLJ6UAyGZY-"
      },
      "outputs": [],
      "source": [
        "def minfilter(img,radius):\n",
        "  h = img.shape[0]\n",
        "  w = img.shape[1]\n",
        "  img2 = np.zeros_like(img)\n",
        "  for x in range (-radius, w+radius):\n",
        "      for y in range (-radius, h+radius):\n",
        "          if pxIsInImgRange(x,y,w,h): \n",
        "                  px = []\n",
        "                  for vx2 in range (-radius, radius+1):\n",
        "                      for vy2 in range (-radius, radius+1):\n",
        "                          x2 = x + vx2\n",
        "                          y2 = y + vy2\n",
        "                          if pxIsInImgRange(x2,y2, w, h):\n",
        "                              px.append(img[y2][x2])\n",
        "\n",
        "                  minimum = min(px)\n",
        "                  img2[y][x] = minimum\n",
        "\n",
        "  return img2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIJUIi-jGZY-"
      },
      "outputs": [],
      "source": [
        "def maxfilter(img,radius):\n",
        "  h = img.shape[0]\n",
        "  w = img.shape[1]\n",
        "  img2 = np.zeros_like(img)\n",
        "  for x in range (-radius, w+radius):\n",
        "      for y in range (-radius, h+radius):\n",
        "          if pxIsInImgRange(x,y,w,h): \n",
        "                  px = []\n",
        "                  for vx2 in range (-radius, radius+1):\n",
        "                      for vy2 in range (-radius, radius+1):\n",
        "                          x2 = x + vx2\n",
        "                          y2 = y + vy2\n",
        "                          if pxIsInImgRange(x2,y2,w,h):\n",
        "                              px.append(img[y2][x2])\n",
        "\n",
        "                  maximum = max(px)\n",
        "                  img2[y][x] = maximum\n",
        "\n",
        "  return img2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACjWtYR-GZY-"
      },
      "outputs": [],
      "source": [
        "def medianfilter(img,radius):\n",
        "  h = img.shape[0]\n",
        "  w = img.shape[1]\n",
        "  img2 = np.zeros_like(img)\n",
        "  for x in range (-radius, w+radius):\n",
        "      for y in range (-radius, h+radius):\n",
        "          if pxIsInImgRange(x,y,w,h): \n",
        "                  px = []\n",
        "                  for vx2 in range (-radius, radius+1):\n",
        "                      for vy2 in range (-radius, radius+1):\n",
        "                          x2 = x + vx2\n",
        "                          y2 = y + vy2\n",
        "                          if pxIsInImgRange(x2,y2,w,h):\n",
        "                              px.append(img[y2][x2])\n",
        "                  median = statistics.median(px)\n",
        "                  img2[y][x] = median\n",
        "\n",
        "  return img2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfpe0fHWGZY_"
      },
      "outputs": [],
      "source": [
        "def mdptfilter(img,radius):\n",
        "  h = img.shape[0]\n",
        "  w = img.shape[1]\n",
        "  img2 = np.zeros_like(img)\n",
        "  for x in range (-radius, w+radius):\n",
        "      for y in range (-radius, h+radius):\n",
        "          if pxIsInImgRange(x,y,w,h): \n",
        "                  px = []\n",
        "                  for vx2 in range (-radius, radius+1):\n",
        "                      for vy2 in range (-radius, radius+1):\n",
        "                          x2 = x + vx2\n",
        "                          y2 = y + vy2\n",
        "                          if pxIsInImgRange(x2,y2,w,h):\n",
        "                              px.append(img[y2][x2])\n",
        "\n",
        "                  px.sort()\n",
        "                  maxi = max(px)\n",
        "                  mini = min(px)\n",
        "                  mdpt = int((int(mini)+int(maxi))/2)\n",
        "                  img2[y][x] = mdpt\n",
        "  return img2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2UqiDlTGZY_"
      },
      "outputs": [],
      "source": [
        "def noise_gen(img,typeofnoise):\n",
        "    row, col = img.shape\n",
        "    if typeofnoise == 'Gaussian':\n",
        "        gauss = np.random.normal(10,10,(row,col))\n",
        "        noisy = img + gauss\n",
        "    elif typeofnoise == 'SnP':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        pepper = 0.05\n",
        "        salt = 1-pepper\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn < pepper:\n",
        "                    noise[i][j]=0\n",
        "                elif rdn>salt:\n",
        "                    noise[i][j]=255\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    elif typeofnoise == 'Uniform':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                noise[i][j]= np.random.uniform(0,500)\n",
        "        noisy = img + noise\n",
        "    elif typeofnoise == 'Salt':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        salt = 0.6\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn>salt:\n",
        "                    noise[i][j]=255\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    elif typeofnoise == 'Pepper':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        pepper = 0.6\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn < pepper:\n",
        "                    noise[i][j]=0\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    return noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "R5_9aL5jGZY_",
        "outputId": "110cea62-0489-4a63-ea6b-7c41f2b8a08a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,3,figsize=(16,9))\n",
        "img = left_imgs[7]\n",
        "\n",
        "kernel = 3\n",
        "radius = int((kernel-1)/2)\n",
        "\n",
        "ax[0,0].title.set_text('Original Image')\n",
        "ax[0,0].imshow(img,cmap='gray')\n",
        "ax[0,0].axis('off')\n",
        "\n",
        "ax[0,1].title.set_text('Gaussian Noise')\n",
        "ax[0,1].imshow(noise_gen(img, 'Gaussian'),cmap='gray')\n",
        "ax[0,1].axis('off')\n",
        "\n",
        "ax[0,2].title.set_text('Midpoint filtering')\n",
        "ax[0,2].imshow(mdptfilter(img,radius),cmap='gray')\n",
        "ax[0,2].axis('off')\n",
        "\n",
        "ax[1,0].title.set_text('Original Image')\n",
        "ax[1,0].imshow(img,cmap='gray')\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "ax[1,1].title.set_text('Uniform Noise')\n",
        "ax[1,1].imshow(noise_gen(img, 'Uniform'),cmap='gray')\n",
        "ax[1,1].axis('off')\n",
        "\n",
        "ax[1,2].title.set_text('Midpoint Filtering')\n",
        "ax[1,2].imshow(mdptfilter(img,radius),cmap='gray')\n",
        "ax[1,2].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "yh2QZaqeGZY_",
        "outputId": "24f926b3-dc23-4705-8cfd-ccfbba231a7a"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,3,figsize=(16,9))\n",
        "img = left_imgs[17]\n",
        "\n",
        "kernel = 3\n",
        "radius = int((kernel-1)/2)\n",
        "\n",
        "ax[0,0].title.set_text('Original Image')\n",
        "ax[0,0].imshow(img,cmap='gray')\n",
        "ax[0,0].axis('off')\n",
        "\n",
        "ax[0,1].title.set_text('Salt Noise')\n",
        "ax[0,1].imshow(noise_gen(img, 'Salt'),cmap='gray')\n",
        "ax[0,1].axis('off')\n",
        "\n",
        "ax[0,2].title.set_text('Min filtering')\n",
        "ax[0,2].imshow(minfilter(img,radius),cmap='gray')\n",
        "ax[0,2].axis('off')\n",
        "\n",
        "ax[1,0].title.set_text('Original Image')\n",
        "ax[1,0].imshow(img,cmap='gray')\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "ax[1,1].title.set_text('Pepper Noise')\n",
        "ax[1,1].imshow(noise_gen(img, 'Pepper'),cmap='gray')\n",
        "ax[1,1].axis('off')\n",
        "\n",
        "ax[1,2].title.set_text('Max Filtering')\n",
        "ax[1,2].imshow(maxfilter(img,radius),cmap='gray')\n",
        "ax[1,2].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "cOHdoWcuGZY_",
        "outputId": "55a690f8-c9a2-4720-cca9-75538556edb7"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize=(16,4))\n",
        "img = left_imgs[8]\n",
        "\n",
        "kernel = 3\n",
        "radius = int((kernel-1)/2)\n",
        "\n",
        "ax[0].title.set_text('Original Image')\n",
        "ax[0].imshow(img,cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "ax[1].title.set_text('Salt and pepper noise')\n",
        "ax[1].imshow(noise_gen(img, 'SnP'),cmap='gray')\n",
        "ax[1].axis('off')\n",
        "\n",
        "ax[2].title.set_text('Median filtering')\n",
        "ax[2].imshow(minfilter(img,radius),cmap='gray')\n",
        "ax[2].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "776CXz_6GZY_"
      },
      "outputs": [],
      "source": [
        "def gauss_PDF(img):\n",
        "    row, col = img.shape\n",
        "    gauss = np.random.normal(10,10,(row,col))\n",
        "    noisy = img + gauss\n",
        "    smooth_part = noisy[:15, :15]\n",
        "\n",
        "    fig, ax = plt.subplots(2,2,figsize=(16,22))\n",
        "\n",
        "    ax[0,0].title.set_text('Noisy Image')\n",
        "    ax[0,0].imshow(noisy,cmap = 'gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    ax[0,1].title.set_text('Smooth Part')\n",
        "    ax[0,1].imshow(smooth_part,cmap = 'gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    ax[1,0].title.set_text('Noisy Image Histogram')\n",
        "    ax[1,0].hist(noisy.ravel(),256,[0,256])\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    ax[1,1].title.set_text('Estimated Noise Distribution')\n",
        "    ax[1,1].hist(smooth_part.ravel(),256,[0,256])\n",
        "    ax[1,1].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tYNQxnD7GZZA",
        "outputId": "d2228439-0067-41c9-879d-8869ea4a4401"
      },
      "outputs": [],
      "source": [
        "gauss_PDF(left_imgs[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6ukHdipGZZA"
      },
      "outputs": [],
      "source": [
        "def uniform_PDF(img):\n",
        "    row, col = img.shape\n",
        "    noise = np.zeros((row,col),dtype = np.float32)\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            noise[i][j]= np.random.uniform(0,500)\n",
        "    noisy = img + noise\n",
        "    smooth_part = noisy[:15, :15]\n",
        "\n",
        "    fig, ax = plt.subplots(2,2,figsize=(16,22))\n",
        "\n",
        "    ax[0,0].title.set_text('Noisy Image')\n",
        "    ax[0,0].imshow(noisy,cmap = 'gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    ax[0,1].title.set_text('Smooth Part')\n",
        "    ax[0,1].imshow(smooth_part,cmap = 'gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    ax[1,0].title.set_text('Noisy Image Histogram')\n",
        "    ax[1,0].hist(noisy.ravel(),256,[0,256])\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    ax[1,1].title.set_text('Estimated Noise Distribution')\n",
        "    ax[1,1].hist(smooth_part.ravel(),256,[0,256])\n",
        "    ax[1,1].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b-naMNdDGZZA",
        "outputId": "0688c26d-abb6-47b1-e9a5-58876bc65809"
      },
      "outputs": [],
      "source": [
        "uniform_PDF(left_imgs[13])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1NvdtCnGZZA"
      },
      "outputs": [],
      "source": [
        "def saltandpepper_PDF(img):\n",
        "    row, col = img.shape\n",
        "    noise = np.zeros((row,col),dtype = np.float32)\n",
        "    pepper = 0.05\n",
        "    salt = 1-pepper\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            rdn = np.random.random()\n",
        "            if rdn < pepper:\n",
        "                noise[i][j]=0\n",
        "            elif rdn>salt:\n",
        "                noise[i][j]=1\n",
        "            else:\n",
        "                noise[i][j]=img[i][j]\n",
        "    noisy = img + noise\n",
        "    smooth_part = noisy[:15, :15]\n",
        "\n",
        "    fig, ax = plt.subplots(2,2,figsize=(16,22))\n",
        "\n",
        "    ax[0,0].title.set_text('Noisy Image')\n",
        "    ax[0,0].imshow(noisy,cmap = 'gray')\n",
        "    ax[0,0].axis('off')\n",
        "\n",
        "    ax[0,1].title.set_text('Smooth Part')\n",
        "    ax[0,1].imshow(smooth_part,cmap = 'gray')\n",
        "    ax[0,1].axis('off')\n",
        "\n",
        "    ax[1,0].title.set_text('Noisy Image Histogram')\n",
        "    ax[1,0].hist(noisy.ravel(),256,[0,256])\n",
        "    ax[1,0].axis('off')\n",
        "\n",
        "    ax[1,1].title.set_text('Estimated Noise Distribution')\n",
        "    ax[1,1].hist(smooth_part.ravel(),256,[0,256])\n",
        "    ax[1,1].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_bwdPY2GZZA",
        "outputId": "a0df4ae1-e41b-4b05-da43-2aa08bcb4994"
      },
      "outputs": [],
      "source": [
        "saltandpepper_PDF(left_imgs[22])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hdDo8sHGZZA"
      },
      "source": [
        "## Tarun's Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-tIdSJkGZZA"
      },
      "outputs": [],
      "source": [
        "def fourier_transform(image):\n",
        "  ft = np.fft.fft2(image)\n",
        "  ft = np.fft.fftshift(ft)\n",
        "\n",
        "  return ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "82SqDRfJGZZA",
        "outputId": "4e0c7750-ea24-4eb8-d1d8-5ed65a97e127"
      },
      "outputs": [],
      "source": [
        "img = left_imgs[4]\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(16,5))\n",
        "\n",
        "ax[0].title.set_text(\"Original image\")\n",
        "ax[0].imshow(img, cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "ft_image = fourier_transform(img)\n",
        "enhanced_ft_image = np.log1p(np.abs(ft_image))\n",
        "ax[1].title.set_text(\"Shifted fourier transform of image\")\n",
        "ax[1].imshow(enhanced_ft_image, cmap='gray')\n",
        "ax[1].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohQZQOq_GZZB"
      },
      "source": [
        "Ideal Low Pass Filter\n",
        "\n",
        "A frequency domain low pass filter satisfiying the property : \n",
        "H(u, v) = {1 if D(u, v) >= D0, 0 if D(U, v) < D0) \\\n",
        "Here, D(u, v) is given by sqrt((u - M / 2) ** 2 + (v - N / 2) ** 2) \\\n",
        "D0 is the cutoff frequency of the image (or the radius of the circle encompassing the low frequency componenets of frequency domain image). \\\n",
        "Blurs image, but produces significant blurring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0tTEZGoGZZB"
      },
      "outputs": [],
      "source": [
        "img_shape = img.shape\n",
        "\n",
        "def ideal_low_pass_filter(image, d0):\n",
        "  m, n = image.shape\n",
        "  \n",
        "  H = np.zeros((m, n), dtype=np.float32)\n",
        "  for u in range(m):\n",
        "    for v in range(n):\n",
        "      d = np.sqrt((u - m / 2)**2 + (v - n / 2) ** 2)\n",
        "      if d <= d0:\n",
        "        # Inside the allowed - frequency range\n",
        "        H[u, v] = 1\n",
        "      else:\n",
        "        H[u, v] = 0\n",
        "  \n",
        "  return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOPKLa0uGZZB"
      },
      "source": [
        "Ideal High Pass Filter\n",
        "\n",
        "A frequency domain filter given by 1 - Ideal Low Pass Filter \\\n",
        "\n",
        "That is, H(u, v) = {0 if D(u, v) >= D0, 1 if D(u, v) < D0} \\\n",
        "Here, D0 is the cutoff frequency, or the frequencies we wish to attenutate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHhlDIhPGZZB"
      },
      "outputs": [],
      "source": [
        "def ideal_high_pass_filter(image, d0):\n",
        "  m, n = image.shape\n",
        "\n",
        "  H = np.zeros((m, n), dtype=np.float32)\n",
        "  for u in range(m):\n",
        "    for v in range(n):\n",
        "      d = np.sqrt((u - m / 2)**2 + (v - n / 2) ** 2)\n",
        "      if d <= d0:\n",
        "        # Inside not  allowed - frequency range\n",
        "        H[u, v] = 0\n",
        "      else:\n",
        "        H[u, v] = 1\n",
        "  \n",
        "  return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWknhP5zGZZB"
      },
      "source": [
        "Visualizing the Ideal Low Pass Filter and Ideal High Pass Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uBBQhmx3GZZB",
        "outputId": "670257c9-c2fd-465c-83ae-d29ad838a3a4"
      },
      "outputs": [],
      "source": [
        "ilp_filters = []\n",
        "for i in range(1, 10):\n",
        "  ilp_filters.append(ideal_low_pass_filter(img, i * 10))\n",
        "\n",
        "ihp_filters = []\n",
        "for i in range(1, 10):\n",
        "  ihp_filters.append(ideal_high_pass_filter(img, i * 10))\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(1, 9):\n",
        "  plt.subplot(1,10, i)\n",
        "  plt.imshow(ilp_filters[i],cmap='gray')\n",
        "  plt.title(('ILP D0->' + str(i * 10)))\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(1, 9):\n",
        "  plt.subplot(2,10, i)\n",
        "  plt.imshow(ihp_filters[i],cmap='gray')\n",
        "  plt.title(('IHP D0->' + str(i * 10)))\n",
        "  plt.axis('on')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CwTq9dTGZZB"
      },
      "source": [
        "Applying the low pass & high pass ideal pass filters : Multiply frequency domain of image by the filter, and de - center (i.e shift it), and perform inverse fourier transform of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu9QJVegGZZB"
      },
      "outputs": [],
      "source": [
        "# Assume iamge is in spatial domain\n",
        "def apply_low_pass_filter(ilp_filter, image):\n",
        "  ft = np.fft.fft2(image)\n",
        "  ft_shifted = np.fft.fftshift(ft)\n",
        "\n",
        "  g = ft_shifted * ilp_filter\n",
        "\n",
        "  g_spatial = np.fft.ifftshift(g)\n",
        "  g_spatial = np.fft.ifft2(g_spatial)\n",
        "\n",
        "  return g, g_spatial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lse0af4EGZZB",
        "outputId": "b0a5375d-b534-413c-f21a-835155717cd4"
      },
      "outputs": [],
      "source": [
        "ilpf, ilp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_low_pass_filter(ilp_filters[i], img)\n",
        "  ilpf.append(g)\n",
        "  ilp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(ilpf[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  plt.imshow(np.log1p(np.abs(ilp_applied[i])),cmap='gray')\n",
        "  plt.title('Spatial domain result')\n",
        "  plt.axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOQpPGQWGZZC"
      },
      "outputs": [],
      "source": [
        "# Assume image is in spatial domain\n",
        "def apply_high_pass_filter(ihp_filter, image):\n",
        "  ft = np.fft.fft2(image)\n",
        "  ft_shifted = np.fft.fftshift(ft)\n",
        "\n",
        "  g = ft_shifted * ihp_filter\n",
        "\n",
        "  g_spatial = np.fft.ifftshift(g)\n",
        "  g_spatial = np.fft.ifft2(g_spatial)\n",
        "\n",
        "  return g, g_spatial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "56eMX05QGZZC",
        "outputId": "b3c9962f-e5ff-4ed5-8cb8-58aab058e673"
      },
      "outputs": [],
      "source": [
        "ihpf, ihp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_high_pass_filter(ihp_filters[i], img)\n",
        "  ihpf.append(g)\n",
        "  ihp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(ihpf[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  plt.imshow((np.abs(ihp_applied[i])),cmap='gray')\n",
        "  plt.title('Ihpf mask ')\n",
        "  plt.axis('on')\n",
        "\n",
        "  \n",
        "  plt.subplot(1,9,3)\n",
        "\n",
        "  plt.imshow((np.abs(ihp_applied[i])) + img,cmap='gray')\n",
        "  plt.title('Ihpf applied')\n",
        "  plt.axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "migRrlGTGZZC"
      },
      "source": [
        "Why the ringing affect ? \n",
        "\n",
        "To visualize this, going from frequency -> spatial domain (just for the filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NrycAj4hGZZC",
        "outputId": "b285a3c7-6551-4c45-a38a-4a566cf4dd23"
      },
      "outputs": [],
      "source": [
        "white_image = np.ones((img.shape[0], img.shape[1]), dtype=np.float32)\n",
        "\n",
        "\n",
        "ilpf, ilp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_low_pass_filter(ilp_filters[i], white_image)\n",
        "  ihpf.append(g)\n",
        "  ihp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(ilp_filters[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  ilp_ift = np.fft.ifftshift(ilp_filters[8-i])\n",
        "  spatial_ilp = np.fft.fftshift(np.abs(np.fft.ifft2(ilp_ift)))\n",
        "  plt.imshow((np.log1p(np.abs(spatial_ilp[100:-100,300:-300]))), cmap='gray')\n",
        "\n",
        "  plt.title('Spatial ILP')\n",
        "  plt.axis('on')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "73rNhL2EGZZC",
        "outputId": "322b82de-1d95-4d2e-c433-f7e9f3b68e49"
      },
      "outputs": [],
      "source": [
        "white_image = np.ones((img.shape[0], img.shape[1]), dtype=np.float32)\n",
        "\n",
        "\n",
        "ihpf, ihp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_high_pass_filter(ihp_filters[i], white_image)\n",
        "  ihpf.append(g)\n",
        "  ihp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(ihp_filters[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  ilp_ift = np.fft.ifftshift(ilp_filters[8-i])\n",
        "  spatial_ilp = np.fft.fftshift(np.abs(np.fft.ifft2(ilp_ift)))\n",
        "  plt.imshow((np.log1p(1.0 - np.abs(spatial_ilp[100:-100,300:-300]))), cmap='gray')\n",
        "\n",
        "  plt.title('Spatial IHP')\n",
        "  plt.axis('on')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpgsGyh8GZZC"
      },
      "source": [
        "# The Butterworth Low Pass Filter\n",
        "\n",
        "A frequency domain given by :\n",
        "H(u, v) = 1 / (1 + (D / D0) ^ 2n) \\\n",
        "Where, \\\n",
        "D = sqrt((u - m / 2) ** 2 + (v - n / 2) ** 2) \\\n",
        "D0 = cut off frequency \\\n",
        "n = order of filter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoDe9_D7GZZC"
      },
      "outputs": [],
      "source": [
        "def butter_worth_low_pass(image, d0, order):\n",
        "  m, n = image.shape\n",
        "  H = np.zeros((m, n), dtype=np.float64)\n",
        "  for u in range(m):\n",
        "    for v in range(n):\n",
        "      d = np.sqrt((u - m / 2) ** 2 + (v - n / 2) ** 2)\n",
        "      H[u, v] = 1 / (1 + (d/d0) ** (2 * order))\n",
        "\n",
        "  return H\n",
        "\n",
        "def butter_worth_high_pass(image, d0, order):\n",
        "  m, n = image.shape\n",
        "  H = np.zeros((m, n), dtype=np.float64)\n",
        "  for u in range(m):\n",
        "    for v in range(n):\n",
        "      d = np.sqrt((u - m / 2) ** 2 + (v - n / 2) ** 2)\n",
        "      H[u, v] = 1 / (1 + (d0/d) ** (2 * order))\n",
        "\n",
        "  return H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1AZtwjbXGZZC",
        "outputId": "8d7c6729-be41-4bc0-ec41-89c8942c9523"
      },
      "outputs": [],
      "source": [
        "butter_worth_low_pass_filters = []\n",
        "for i in range(1, 10):\n",
        "  butter_worth_low_pass_filters.append(butter_worth_low_pass(img, i * 10, 2 ** (i/2)))\n",
        "\n",
        "butter_worth_high_pass_filters = []\n",
        "for i in range(1, 10):\n",
        "  butter_worth_high_pass_filters.append(butter_worth_high_pass(img, i * 10, 2 ** (i / 2)))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(200,5))\n",
        "\n",
        "for i in range(1, 9):\n",
        "  plt.subplot(1,10, i)\n",
        "  plt.imshow(butter_worth_low_pass_filters[i],cmap='gray')\n",
        "  plt.title(('Butter low pass (D0, n) ' + str(i * 10) + '|' + str(2 ** (i/2))))\n",
        "  plt.figure(figsize=(200,5))\n",
        "\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(200,5))\n",
        "\n",
        "for i in range(1, 9):\n",
        "  plt.subplot(2,10, i)\n",
        "  plt.imshow(butter_worth_high_pass_filters[i],cmap='gray')\n",
        "  plt.title(('Butter worth high pass (D0, n) ' + str(i * 10) + '|' + str(2 ** (i/2))))\n",
        "  plt.axis('on')\n",
        "  plt.figure(figsize=(200,5))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmlmagE1GZZD"
      },
      "source": [
        "Applying the butter worth high and low pass filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOArEQCRGZZD"
      },
      "outputs": [],
      "source": [
        "# Assume image is in spatial domain\n",
        "def apply_butter_worth_pass_filter(filter, image):\n",
        "  ft = np.fft.fft2(image)\n",
        "  ft_shifted = np.fft.fftshift(ft)\n",
        "\n",
        "  g = ft_shifted * filter\n",
        "\n",
        "  g_spatial = np.fft.ifftshift(g)\n",
        "  g_spatial = np.fft.ifft2(g_spatial)\n",
        "\n",
        "  return g, g_spatial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzBsOXaGZZD"
      },
      "source": [
        "Visualize the butter worth filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s3zMfVi6GZZD",
        "outputId": "286736e7-be57-449f-cd94-12b2c3adf977"
      },
      "outputs": [],
      "source": [
        "blpf, blp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_butter_worth_pass_filter(butter_worth_low_pass_filters[i], img)\n",
        "  blpf.append(g)\n",
        "  blp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(blpf[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  plt.imshow(np.log1p(np.abs(blp_applied[i])),cmap='gray')\n",
        "  plt.title('Spatial domain result' + str('(D0, n) ') + str(i * 10) + '|' + str(2 ** (i/2)))\n",
        "\n",
        "  plt.axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "98DtxaNKGZZD",
        "outputId": "5dbc23e9-572c-40ad-d265-df1fcabe5927"
      },
      "outputs": [],
      "source": [
        "butter_worth_low_pass_filters.append(butter_worth_low_pass(img, 50, 1000))\n",
        "\n",
        "g, g_spatial = apply_butter_worth_pass_filter(butter_worth_low_pass_filters[-1], img)\n",
        "\n",
        "plt.figure(figsize=(100,5))\n",
        "\n",
        "plt.subplot(1,9, 1)\n",
        "plt.imshow(np.log1p(np.abs(g)),cmap='gray')\n",
        "plt.title('Convolution in FT')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,9,2)\n",
        "\n",
        "plt.imshow(np.log1p(np.abs(g_spatial)),cmap='gray')\n",
        "plt.title('Spatial domain result' + str('(D0, n) ') + str(50) + '|' + str(1000))\n",
        "plt.axis('on')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-ybxtR9LGZZD",
        "outputId": "ecbac831-a7fc-4952-fad9-5cbfe35451ec"
      },
      "outputs": [],
      "source": [
        "bhpf, bhp_applied = [], []\n",
        "for i in range(0,9):\n",
        "  g, g_spatial = apply_butter_worth_pass_filter(butter_worth_high_pass_filters[i], img)\n",
        "  bhpf.append(g)\n",
        "  bhp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 8):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(bhpf[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  plt.imshow((np.abs(bhp_applied[i])),cmap='gray')\n",
        "  plt.title('Spatial domain result' + str('(D0, n) ') + str(i * 10) + '|' + str(2 ** (i/2)))\n",
        "  plt.axis('on')\n",
        "\n",
        "  plt.subplot(1,9,3)\n",
        "\n",
        "  plt.imshow((np.abs(bhp_applied[i])) + img,cmap='gray')\n",
        "  plt.title('Butter worth applied')\n",
        "  plt.axis('on')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec80cmHWGZZD"
      },
      "source": [
        "Homomorphic Filtering \\\n",
        "\n",
        "Image enhancement technique (in frequency domain). \\\n",
        "Involves non linear mapping to different domain in which linear filtering techniques are applied. \\\n",
        "Then, it is followed by mapping back to the original domain. \\\n",
        "Simultaneously normalizes brightness, and increases contrast of image. \\\n",
        "Correct non uniform illumination in images & improving appearance (subjective) of gray scale image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yArLTXA-GZZE"
      },
      "source": [
        "Illumination Reflectance Model : I(x, y) = L(x, y) * R(x, y) \\\n",
        "reflactance is associated with object edges and varies rapidly in space. \\\n",
        "illumination contributes to the dynamic range and various much slower compared to reflectance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GBBCZt2GZZE"
      },
      "source": [
        "I(x, y) = ln() -> DFT -> H(u  v) -> DFT^-1, EXP -> G(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYHEvwbHGZZE"
      },
      "source": [
        "Demo : Homomorphic filtering with butter worth high pass filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkQJU07cGZZE"
      },
      "outputs": [],
      "source": [
        "# h is the filter we want to apply.\n",
        "def homomorphic_filter(img, h):\n",
        "  # Step 1 -> Natural log of image (to separate illumination and reflectance from image).\n",
        "  image_nl = np.log1p(img)\n",
        "\n",
        "  # Step 2 -> Transform image to the fourier domain.\n",
        "  dft = np.fft.fftshift(np.fft.fft2(image_nl))\n",
        "\n",
        "  # Step 3 -> Apply filter to DFT\n",
        "  filtered_image = (dft *  h)\n",
        "\n",
        "  # Step 4 -> Back to spatial domain\n",
        "  spatial_img = np.real(np.fft.ifft2(np.fft.ifftshift(filtered_image)))\n",
        "\n",
        "  # Step 5 -> Apply exponential to cancel affect of log.\n",
        "  homomorphic_img = np.expm1(spatial_img, dtype=np.float64)\n",
        "\n",
        "  # Step 6 -> Normalization\n",
        "  img_homomorphic = cv2.normalize(homomorphic_img, None, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "  \n",
        "  return homomorphic_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "PouytR-kGZZE",
        "outputId": "bdb2437b-a82d-44d8-d57a-b76f3b2a337c"
      },
      "outputs": [],
      "source": [
        "rainy_image = right_imgs[12]\n",
        "rainy_image = cv2.normalize(rainy_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "plt.xlabel('Original image')\n",
        "plt.imshow(rainy_image, cmap='gray')\n",
        "plt.plot()\n",
        "plt.show()\n",
        "img_height, img_width = rainy_image.shape[:2]\n",
        "\n",
        "butter_worth_high_pass_filters = []\n",
        "for i in range(1, 3):\n",
        "  butter_worth_high_pass_filters.append(butter_worth_high_pass(rainy_image, i * 10, 2 ** (i+1)))\n",
        "\n",
        "blpf, blp_applied = [], []\n",
        "for i in range(0,2):\n",
        "  g, g_spatial = apply_butter_worth_pass_filter(butter_worth_high_pass_filters[i], rainy_image)\n",
        "  blpf.append(g)\n",
        "  blp_applied.append(g_spatial)\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 2):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  plt.imshow(np.log1p(np.abs(blpf[i])),cmap='gray')\n",
        "  plt.title('Convolution in FT')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9,2)\n",
        "\n",
        "  plt.imshow(np.log1p(np.abs(blp_applied[i])),cmap='gray')\n",
        "  plt.title('Spatial domain butter worth result' + str('(D0, n) ') + str(i * 10) + '|' + str(2 ** (i/2)))\n",
        "  plt.axis('on')\n",
        "\n",
        "  plt.subplot(1,9,3)\n",
        "\n",
        "  homomorphic_image = homomorphic_filter(rainy_image, butter_worth_high_pass_filters[i])\n",
        "  plt.imshow(((homomorphic_image)),cmap='gray')\n",
        "  plt.title('Spatial domain butter worth + homomorphic' + str('(D0, n) ') + str(i * 10) + '|' + str(2 ** (i/2)))\n",
        "  plt.axis('on')\n",
        "  \n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmFQU6lcGZZE"
      },
      "source": [
        "Morphological Transformations\n",
        "\n",
        "Broad set of image processing operations that processes binary images based on SE (Structuring elements) which dictates the nature of the operation.\n",
        "\n",
        "Each pixel in image is adjusted based on value of pixels in its neighbourhood.\n",
        "\n",
        "It is not subjective. Used for getting the ground truth of the description of region shapes, boundaries, and for extracting the various componenets from the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkxK73yCGZZE"
      },
      "source": [
        "Erosion\n",
        "\n",
        "Pixel will be considered 255 or 0 only if ALL pixels under the kernel is 255 or 0. OTherwise it is eroded (i.e color changes to 0 or 255)\\\n",
        "\n",
        "Mathematically, \\\n",
        "If A is the set and B is the kernel / structural element, then, the erosion of A by B is denoted by A (-) B, where ð°\n",
        "A (-) B = {z | (B)z is contained in A}. \\\n",
        "For the SE to erode the image at any point, the ENTIRE strucuting element must be contained by the binary image at said point. \\\n",
        "\n",
        "It shrinks or thins objects in a given binary image, as it removes pixels on object boundaries. Enlarges foreground holes, remove irrelavant small details from the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6za9dPnbGZZE"
      },
      "source": [
        "Useful for removing isolated pixels, removes outer layer of objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWpbDwy_GZZF"
      },
      "outputs": [],
      "source": [
        "def erode(image, se):\n",
        "  # Create the padded image.\n",
        "  # Image with padding for convineince (for use with a 3X3 filter).\n",
        "  padded_image = image.copy()\n",
        "\n",
        "  padded_image = cv2.copyMakeBorder(padded_image, 3, 3, 3, 3, cv2.BORDER_CONSTANT, None, 0)\n",
        "  img_height, img_width = padded_image.shape[0:2]\n",
        "\n",
        "  res = padded_image.copy()\n",
        "  def map_se_255(x):\n",
        "    if x == 1:\n",
        "      return 255\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  for v in range(img_height-se.shape[0]):\n",
        "    for u in range(img_width-se.shape[1]):\n",
        "      covering = True\n",
        "      for i in range(se.shape[0]):\n",
        "        for j in range(se.shape[1]):\n",
        "          if res[v+i, u+j] != map_se_255(se[i, j]):\n",
        "            covering = False\n",
        "\n",
        "      if covering:\n",
        "        for i in range(se.shape[0]):\n",
        "          for j in range(se.shape[1]):\n",
        "            res[v+i, u+j] = 1\n",
        "      \n",
        "      else:\n",
        "        for i in range(se.shape[0]):\n",
        "          for j in range(se.shape[1]):\n",
        "            res[v+i, u+j] = 0\n",
        "      \n",
        "  \n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zMWN7bizGZZF",
        "outputId": "30e401b4-c451-4b32-e08e-561a7c8d3901"
      },
      "outputs": [],
      "source": [
        "img = right_imgs[8]\n",
        "noised_img = img\n",
        "\n",
        "for x in range(noised_img.shape[0]):\n",
        "  for y in range(noised_img.shape[1]):\n",
        "    t = np.random.randint(0,20)\n",
        "    if t == 3:\n",
        "      noised_img[x, y] = 255\n",
        "\n",
        "plt.imshow(noised_img, cmap = 'gray') \n",
        "\n",
        "binary_image = noised_img\n",
        "\n",
        "se = np.ones((3, 3), dtype=np.uint8)\n",
        "print(\"The structuring element used.\")\n",
        "print(se)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 20):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  erosion = cv2.erode(binary_image, se, iterations=i+1)\n",
        "  plt.imshow(erosion,cmap='gray')\n",
        "  plt.title('Erosion iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9, 2)\n",
        "  erosion = 255 - cv2.erode(binary_image, se, iterations=i+1)\n",
        "  plt.imshow(erosion,cmap='gray')\n",
        "  plt.title('Erosion iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOUy2b-kHvdR"
      },
      "source": [
        "Dilation in image processing \\\n",
        "\n",
        "Used for 'expanding an element A by some structural element B'. Adds pixels to object boundaries.\n",
        "Even if a single pixel of the iamge is covered by the structural element, we set the entire area covered by teh structural element to 1, else 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X_Ki34aXGZZF",
        "outputId": "db5f0c1b-4a8f-4043-baa5-30b731cdd507"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ret, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "img = left_imgs[9]\n",
        "img = cv2.resize(img, (300,300))\n",
        "noised_img = img\n",
        "\n",
        "for x in range(noised_img.shape[0]):\n",
        "  for y in range(noised_img.shape[1]):\n",
        "    t = np.random.randint(0,30)\n",
        "    if t == 3:\n",
        "      noised_img[x, y] = 0\n",
        "\n",
        "plt.imshow(noised_img) \n",
        "\n",
        "binary_image = noised_img\n",
        "\n",
        "print(\"Opening image\")\n",
        "plt.imshow(img, cmap='gray')\n",
        "\n",
        "plt.figure(figsize=(90,5))\n",
        "\n",
        "for i in range(0, 18):\n",
        "\n",
        "  plt.figure(figsize=(90,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  dilation = cv2.dilate(binary_image, se, iterations=i+1)\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('Dilation iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9, 2)\n",
        "  dilation = 255 - cv2.dilate(binary_image, se, iterations=i+1)\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('dilation iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.axis('on')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIWY9jrmIoou"
      },
      "source": [
        "Opening and Closing\n",
        "\n",
        "Closing -> Erosion followed by Dilation.\\\n",
        "Opening -> Dilation folled by Erosion. \\\n",
        "\n",
        "Same properties for erosion and dilation, but the object size REMAINS THE SAME."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4K3L2gpmIG4c",
        "outputId": "739531bd-9a2f-4c2f-bd4a-6715bced28c9"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ret, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "img = left_imgs[10]\n",
        "noised_img = img\n",
        "for x in range(noised_img.shape[0]):\n",
        "  for y in range(noised_img.shape[1]):\n",
        "    t = np.random.randint(0,10)\n",
        "    if t == 3:\n",
        "      noised_img[x, y] = 255\n",
        "\n",
        "binary_image = noised_img\n",
        "plt.imshow(binary_image,cmap='gray')\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 18):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  erosion = cv2.erode(binary_image, se, iterations=i+1)\n",
        "  dilation = cv2.dilate(erosion, se, iterations=i+1)\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('Closing iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9, 2)\n",
        "  dilation = 255 - cv2.dilate(dilation, se, iterations=i+1)\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('Closing iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FEQQPFRaIxBu",
        "outputId": "68f95c47-2303-44d4-f14f-8358a028443a"
      },
      "outputs": [],
      "source": [
        "\n",
        "#ret, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "img = right_imgs[20]\n",
        "binary_image = img\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "for i in range(0, 18):\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.figure(figsize=(100,5))\n",
        "\n",
        "  plt.subplot(1,9, 1)\n",
        "  dilation = cv2.dilate(binary_image, se, iterations=i+1)\n",
        "  erosion = cv2.erode(dilation, se, iterations=i+1)\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('Opening iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1,9, 2)\n",
        "  dilation = 255 - erosion\n",
        "  plt.imshow(dilation,cmap='gray')\n",
        "  plt.title('Opening iterations : ' + str(i + 1))\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.axis('on')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWcq-FXsKJEV"
      },
      "source": [
        "## Ashfaq's Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1QSGxSA_I84F",
        "outputId": "eca1ece0-bf79-4388-d886-ba410e578b0c"
      },
      "outputs": [],
      "source": [
        "left_images=left_imgs[:4]\n",
        "\n",
        "# def dft(x):\n",
        "#     x = np.asarray(x, dtype=float)\n",
        "#     N = x.shape[0]\n",
        "#     n = np.arange(N)\n",
        "#     k = n.reshape((N, 1))\n",
        "#     M = np.exp(-2j * np.pi * k * n / N)\n",
        "#     return np.dot(M, x)\n",
        "for f in left_images:\n",
        "  # my_dft=dft(f)\n",
        "  # print(my_dft)\n",
        "  # print(my_dft.shape)\n",
        "  # p,q=my_dft.shape\n",
        "  dft = cv2.dft(np.float32(f),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
        "\n",
        "  # shift zero-frequency component to the center of the spectrum\n",
        "  dft_shift = np.fft.fftshift(dft)\n",
        "  magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],\n",
        "        dft_shift[:,:,1])\n",
        "    )\n",
        "  dft_spectrum = 20*np.log(cv2.magnitude(dft[:,:,0],\n",
        "        dft[:,:,1])\n",
        "    )\n",
        "\n",
        "  # visualize input image and the magnitude spectrum\n",
        "  # plt.subplot(131),plt.imshow(f, cmap = 'gray')\n",
        "  # plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
        "  # plt.subplot(132),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
        "  # plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
        "  # plt.subplot(133),plt.imshow(dft_spectrum, cmap = 'gray')\n",
        "  # plt.title('DFT Spectrum'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(f, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Fourier Transform')\n",
        "  plt.imshow(dft_spectrum, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Fourier Transforming after centering')\n",
        "  plt.imshow(magnitude_spectrum, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  # cv2_imshow(my_dft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H8jY6PDfLO0d",
        "outputId": "e02e5f1b-4fec-4e21-a35e-78c2f317e92b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for f in left_images:\n",
        "  dft = cv2.dft(np.float32(f),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
        "  F = np.fft.fft2(f)\n",
        "  Fshift = np.fft.fftshift(F)\n",
        "  # shift zero-frequency component to the center of the spectrum\n",
        "  dft_shift = np.fft.fftshift(dft)\n",
        "  magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],\n",
        "        dft_shift[:,:,1])\n",
        "    )\n",
        "  dft_spectrum = 20*np.log(cv2.magnitude(dft[:,:,0],\n",
        "        dft[:,:,1])\n",
        "    )\n",
        "\n",
        "  # visualize input image and the magnitude spectrum\n",
        "  # plt.subplot(131),plt.imshow(f, cmap = 'gray')\n",
        "  # plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
        "  # plt.subplot(132),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
        "  # plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
        "  # plt.subplot(133),plt.imshow(dft_spectrum, cmap = 'gray')\n",
        "  # plt.title('DFT Spectrum'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(f, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Fourier Transform')\n",
        "  plt.imshow(dft_spectrum, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  phi=np.angle(F)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Phase Angle of Image')\n",
        "  plt.imshow(phi, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Fourier Transforming after centering')\n",
        "  plt.imshow(magnitude_spectrum, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  phi=np.angle(Fshift)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Phase Angle of Fourier Transform after centering')\n",
        "  plt.imshow(phi, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTjBJsWB-gtM"
      },
      "source": [
        "# Gaussian Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f4hA4eSY-gtM",
        "outputId": "80a8a3be-0473-4062-9154-ade5a380a809"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# open the image f\n",
        "for f in left_images:\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(f, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # transform the image into frequency domain, f --> F\n",
        "  F = np.fft.fft2(f)\n",
        "  Fshift = np.fft.fftshift(F)\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Discrete Fourier Transform')\n",
        "  plt.imshow(np.log1p(np.abs(F)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Discrete Fourier Transform after centering')\n",
        "  plt.imshow(np.log1p(np.abs(Fshift)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  phi=np.angle(F)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Phase Angle')\n",
        "  plt.imshow(phi, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # Create Gaussin Filter: Low Pass Filter\n",
        "  M,N = f.shape\n",
        "  H = np.zeros((M,N), dtype=np.float32)\n",
        "  D0 = 10\n",
        "  for u in range(M):\n",
        "      for v in range(N):\n",
        "          D = np.sqrt((u-M/2)**2 + (v-N/2)**2)\n",
        "          H[u,v] = np.exp(-D**2/(2*D0*D0))\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Gaussian Low Pass Filter')\n",
        "  plt.imshow(H, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # Image Filters\n",
        "  Gshift = Fshift * H\n",
        "  G = np.fft.ifftshift(Gshift)\n",
        "  g = np.abs(np.fft.ifft2(G))\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Gaussian low pass filter in spatial domain')\n",
        "  plt.imshow(g, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Guassian low pass filtering in frequency domain')\n",
        "  plt.imshow(np.log1p(np.abs(Gshift)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Guassian low pass filtering in frequency domain without centering')\n",
        "  plt.imshow(np.log1p(np.abs(G)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  phi=np.angle(G)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Phase Angle of gaussian low pass')\n",
        "  plt.imshow(phi, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # Gaussian: High pass filter\n",
        "  HPF = 1 - H\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Gaussian High Pass Filter')\n",
        "  plt.imshow(HPF, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  # Image Filters\n",
        "  Gshift = Fshift * HPF\n",
        "  G = np.fft.ifftshift(Gshift)\n",
        "  g = np.abs(np.fft.ifft2(G))\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Gaussian high pass filter in spatial domain')\n",
        "  plt.imshow(g, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Guassian high pass filtering in frequency domain')\n",
        "  plt.imshow(np.log1p(np.abs(Gshift)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Input Image after applying Guassian high pass filtering in frequency domain without centering')\n",
        "  plt.imshow(np.log1p(np.abs(G)), cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  phi=np.angle(G)\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title('Phase Angle of gaussian high pass')\n",
        "  plt.imshow(phi, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gQl_lU-gtM"
      },
      "source": [
        "# Adaptive Median Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gquhliIB-gtN",
        "outputId": "427d88a6-5300-4737-d92e-ab306bf03048"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def sp_noise(image,prob):\n",
        "    '''\n",
        "    Add salt and pepper noise to image\n",
        "    prob: Probability of the noise\n",
        "    '''\n",
        "    output = np.zeros(image.shape,np.uint8)\n",
        "    thres = 1 - prob \n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            rdn = random.random()\n",
        "            if rdn < prob:\n",
        "                output[i][j] = 0\n",
        "            elif rdn > thres:\n",
        "                output[i][j] = 255\n",
        "            else:\n",
        "                output[i][j] = image[i][j]\n",
        "    return output\n",
        "\n",
        "#o@njit\n",
        "def padding(img,pad):\n",
        "    padded_img = np.zeros((img.shape[0]+2*pad,img.shape[1]+2*pad))\n",
        "    padded_img[pad:-pad,pad:-pad] = img\n",
        "    return padded_img\n",
        "\n",
        "#0@njit(parallel=True)\n",
        "def AdaptiveMedianFilter(img,s=3,sMax=7):\n",
        "    if len(img.shape) == 3:\n",
        "        raise Exception (\"Single channel image only\")\n",
        "\n",
        "    H,W = img.shape\n",
        "    a = sMax//2\n",
        "    padded_img = padding(img,a)\n",
        "\n",
        "    f_img = np.zeros(padded_img.shape)\n",
        "\n",
        "    for i in range(a,H+a+1):\n",
        "        for j in range(a,W+a+1):\n",
        "            value = Lvl_A(padded_img,i,j,s,sMax)\n",
        "            f_img[i,j] = value\n",
        "\n",
        "    return f_img[a:-a,a:-a] \n",
        "\n",
        "#0@njit\n",
        "def Lvl_A(mat,x,y,s,sMax):\n",
        "    window = mat[x-(s//2):x+(s//2)+1,y-(s//2):y+(s//2)+1]\n",
        "    Zmin = np.min(window)\n",
        "    Zmed = np.median(window)\n",
        "    Zmax = np.max(window)\n",
        "\n",
        "    A1 = Zmed - Zmin\n",
        "    A2 = Zmed - Zmax\n",
        "\n",
        "    if A1 > 0 and A2 < 0:\n",
        "        return Lvl_B(window, Zmin, Zmed, Zmax)\n",
        "    else:\n",
        "        s += 2 \n",
        "        if s <= sMax:\n",
        "            return Lvl_A(mat,x,y,s,sMax)\n",
        "        else:\n",
        "             return Zmed\n",
        "\n",
        "#0@njit\n",
        "def Lvl_B(window, Zmin, Zmed, Zmax):\n",
        "    h,w = window.shape\n",
        "\n",
        "    Zxy = window[h//2,w//2]\n",
        "    B1 = Zxy - Zmin\n",
        "    B2 = Zxy - Zmax\n",
        "\n",
        "    if B1 > 0 and B2 < 0 :\n",
        "        return Zxy\n",
        "    else:\n",
        "        return Zmed\n",
        "for f in left_images:\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(f, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  s_and_p=sp_noise(f,0.08)\n",
        "  plt.title('Salt and Pepper Noise Image')\n",
        "  plt.imshow(s_and_p, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  filtered_img=AdaptiveMedianFilter(s_and_p)\n",
        "  plt.title('Image after adaptive median filter')\n",
        "  plt.imshow(filtered_img, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0sojRO0-gtN"
      },
      "source": [
        "# Adaptive noise filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tkGqSVs8-gtN",
        "outputId": "538a1d61-e506-4c61-db69-f6bb66ed2732"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# AMF params\n",
        "max_patch_size = 15\n",
        "\n",
        "def sp_noise(image,prob):\n",
        "    '''\n",
        "    Add salt and pepper noise to image\n",
        "    prob: Probability of the noise\n",
        "    '''\n",
        "    output = np.zeros(image.shape,np.uint8)\n",
        "    thres = 1 - prob \n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            rdn = random.random()\n",
        "            if rdn < prob:\n",
        "                output[i][j] = 0\n",
        "            elif rdn > thres:\n",
        "                output[i][j] = 255\n",
        "            else:\n",
        "                output[i][j] = image[i][j]\n",
        "    return output\n",
        "# Extract patch from image matrix\n",
        "def _extract_patch(matrix, x, y, patch_size=3):\n",
        "    height, width = matrix.shape\n",
        "    size = patch_size // 2\n",
        "\n",
        "    # initialize x index\n",
        "    if x - size >= 0:\n",
        "        x_begin = x - size\n",
        "    else:\n",
        "        x_begin = 0\n",
        "\n",
        "    if x + size < height:\n",
        "        x_end = x + size\n",
        "    else:\n",
        "        x_end = height - 1\n",
        "\n",
        "    # initialize y index\n",
        "    if y - size >= 0:\n",
        "        y_begin = y - size\n",
        "    else:\n",
        "        y_begin = 0\n",
        "\n",
        "    if y + size < width:\n",
        "        y_end = y + size\n",
        "    else:\n",
        "        y_end = width - 1\n",
        "\n",
        "    # loop inside patch\n",
        "    output = []\n",
        "    for i in range(x_begin, x_end+1):\n",
        "        for j in range(y_begin, y_end+1):\n",
        "            output.append(matrix[i][j])\n",
        "    return output\n",
        "\n",
        "\n",
        "# Adaptive median filter function\n",
        "def amf(matrix):\n",
        "\n",
        "    # prepare output\n",
        "    print(matrix.shape)\n",
        "    output = np.copy(matrix)\n",
        "    height, width = matrix.shape\n",
        "    vars=np.var(matrix)\n",
        "\n",
        "    for x in range(height):\n",
        "        for y in range(width):\n",
        "            patch_size = 3\n",
        "            patch = _extract_patch(matrix, x, y, patch_size)\n",
        "\n",
        "            varl=np.var(patch)\n",
        "            meanl=np.mean(patch)\n",
        "            # extract min, max and median value of patch\n",
        "            patch_min = np.min(patch)\n",
        "            patch_max = np.max(patch)\n",
        "            \n",
        "            temp=matrix[x][y]-((vars/varl)*(matrix[x][y]-meanl))\n",
        "\n",
        "            # check if pixel is corrupted\n",
        "            if patch_min < matrix[x][y] < patch_max:\n",
        "                output[x][y] = matrix[x][y]\n",
        "            else:\n",
        "                # check if median value is also corrupted\n",
        "                finish = False\n",
        "                while not finish:\n",
        "                    if 0 < temp < 255:\n",
        "                        output[x][y] = temp\n",
        "                        finish = True\n",
        "                    else:\n",
        "                        # calculate new patch\n",
        "                        patch_size = patch_size + 2\n",
        "                        if patch_size <= max_patch_size:\n",
        "                            patch = _extract_patch(matrix, x, y, patch_size)\n",
        "                            patch.sort()\n",
        "                            patch_median = patch[len(patch) // 2]\n",
        "                        else:\n",
        "                            finish = True\n",
        "\n",
        "    return output\n",
        "for f in left_images:\n",
        "  plt.title('Input Image')\n",
        "  plt.imshow(f, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  s_and_p=sp_noise(f,0.01)\n",
        "  plt.title('Noisy Image')\n",
        "  plt.imshow(s_and_p, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  new_img=amf(s_and_p)\n",
        "  plt.title('Image filtered using adaptive noise reduction')\n",
        "  plt.imshow(new_img, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHi66CRQMf6Q"
      },
      "source": [
        "## Abishek's Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8zEi3-CMiL5"
      },
      "outputs": [],
      "source": [
        "imgs = left_images\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3IUG3_IGHQi"
      },
      "outputs": [],
      "source": [
        "def arithmeticmean(img):\n",
        "    m, n = img.shape\n",
        "      \n",
        "    mask = np.ones([10, 10], dtype = int)\n",
        "    mask = mask / 100\n",
        "      \n",
        "    img_new = np.zeros([m, n])\n",
        "    \n",
        "    for i in range(1, m-1):\n",
        "        for j in range(1, n-1):\n",
        "            temp = img[i-1, j-1]*mask[0, 0]+img[i-1, j]*mask[0, 1]+img[i-1, j + 1]*mask[0, 2]+img[i, j-1]*mask[1, 0]+ img[i, j]*mask[1, 1]+img[i, j + 1]*mask[1, 2]+img[i + 1, j-1]*mask[2, 0]+img[i + 1, j]*mask[2, 1]+img[i + 1, j + 1]*mask[2, 2]\n",
        "            \n",
        "            img_new[i, j]= temp\n",
        "            \n",
        "    img_new = img_new.astype(np.uint8)\n",
        "    return img_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW9_-OURHdZH"
      },
      "outputs": [],
      "source": [
        "imgs = left_imgs\n",
        "salt_pepper_imgs = np.full_like(imgs,0)\n",
        "avg_cleaned_imgs = np.full_like(imgs,0)\n",
        "for i in range(4):\n",
        "  noisy = random_noise(imgs[i],mode='s&p',amount=0.3)\n",
        "\n",
        "  salt_pepper_imgs[i]=np.array(255*noisy, dtype = 'uint8') \n",
        "  avg_cleaned_imgs[i] = arithmeticmean(salt_pepper_imgs[i] + imgs[i])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OpmnhjUpaSd",
        "outputId": "f3890eab-64f1-4cec-fb75-812f129864b6"
      },
      "outputs": [],
      "source": [
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
        "                  # Therefore PSNR have no importance.\n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "PSNR(imgs[0,:,:],avg_cleaned_imgs[0,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9mNStCspwZz",
        "outputId": "1995939c-d016-436d-dcee-6c2ab3fd0152"
      },
      "outputs": [],
      "source": [
        "PSNR(imgs[0,:,:],salt_pepper_imgs[0,:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "uitDE7N-KnL8",
        "outputId": "cda0c325-0073-41de-a66d-97568a4cdca6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(salt_pepper_imgs[0],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(avg_cleaned_imgs[0],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(salt_pepper_imgs[1],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(avg_cleaned_imgs[1],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[2],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(salt_pepper_imgs[2],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(avg_cleaned_imgs[2],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(imgs[3],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(salt_pepper_imgs[3],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(avg_cleaned_imgs[3],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgqGhJS5OhGa"
      },
      "source": [
        "GEOMETRIC MEAN FILTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qslGMe8zPUFo"
      },
      "outputs": [],
      "source": [
        "def geometricmean(img,k):\n",
        "  m,n = img.shape\n",
        "  ksize = k\n",
        "  padsize = int((ksize-1)/2)\n",
        "  pad_img = cv2.copyMakeBorder(img, *[padsize]*4, cv2.BORDER_DEFAULT)\n",
        "  geomean1 = np.zeros_like(img)\n",
        "  for r in range(m):\n",
        "      for c in range(n):\n",
        "          geomean1[r, c] = np.prod(pad_img[r:r+ksize, c:c+ksize])**(1/(ksize**2))\n",
        "  geomean1 = np.uint8(geomean1)\n",
        "  return geomean1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5RXJXNNSiQt"
      },
      "outputs": [],
      "source": [
        "geo_imgs1 = np.full_like(imgs,0)\n",
        "geo_imgs2 = np.full_like(imgs,0)\n",
        "salt_pepper_imgs = np.full_like(imgs,0)\n",
        "\n",
        "for i in range(4):\n",
        "  noisy = random_noise(imgs[i],mode='s&p',amount=0.3)\n",
        "  salt_pepper_imgs[i]=np.array(255*noisy, dtype = 'uint8')\n",
        "  geo_imgs1[i] = geometricmean(salt_pepper_imgs[i],1)  \n",
        "  geo_imgs2[i] = geometricmean(salt_pepper_imgs[i],3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "YeZwOsNmS6_G",
        "outputId": "1dc20d51-22ef-4176-e91c-f4790bdd18b3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[0],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_imgs1[0],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_imgs2[0],cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[1],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[1],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_imgs1[1],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_imgs2[1],cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[2],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[2],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_imgs1[2],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_imgs2[2],cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(imgs[3],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_imgs[3],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_imgs1[3],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_imgs2[3],cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjwh_QpYxm4v"
      },
      "source": [
        "CONTRAHARMONIC FILTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj25l6NdxmSX"
      },
      "outputs": [],
      "source": [
        "def contraharmonic_mean(img, size, Q):\n",
        "    num = np.power(img, Q + 1)\n",
        "    denom = np.power(img, Q)\n",
        "    kernel = np.full(size, 1.0)\n",
        "    result = cv2.filter2D(num, -1, kernel) / cv2.filter2D(denom, -1, kernel)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwkRfkBByMbx",
        "outputId": "f40b852d-e618-408f-8903-0d27305d50dc"
      },
      "outputs": [],
      "source": [
        "salt_pepper_imgs = np.full_like(imgs,0)\n",
        "chm_cleaned_imgs0 = np.full_like(imgs,0)\n",
        "chm_cleaned_imgs1 = np.full_like(imgs,0)\n",
        "chm_cleaned_imgs2 = np.full_like(imgs,0)\n",
        "for i in range(4):\n",
        "  noisy = random_noise(imgs[i],mode='s&p',amount=0.3)\n",
        "  salt_pepper_imgs[i]=np.array(255*noisy, dtype = 'uint8')\n",
        "  chm_cleaned_imgs0[i]=contraharmonic_mean(salt_pepper_imgs[i],(3,3),-200.0)\n",
        "  chm_cleaned_imgs1[i]=contraharmonic_mean(salt_pepper_imgs[i],(3,3),2.0)\n",
        "  chm_cleaned_imgs2[i]=contraharmonic_mean(salt_pepper_imgs[i],(3,3),180.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "_NKWZFjIy0RK",
        "outputId": "7fc5afbe-7784-4322-cc78-69e788400c6e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,5,1)\n",
        "plt.imshow(imgs[0],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,2)\n",
        "plt.imshow(salt_pepper_imgs[0],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,3)\n",
        "plt.imshow(chm_cleaned_imgs0[0],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,4)\n",
        "plt.imshow(chm_cleaned_imgs1[0],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 2')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,5)\n",
        "plt.imshow(chm_cleaned_imgs2[0],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 3')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,5,1)\n",
        "plt.imshow(imgs[2],cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,2)\n",
        "plt.imshow(salt_pepper_imgs[2],cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,3)\n",
        "plt.imshow(chm_cleaned_imgs0[2],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,4)\n",
        "plt.imshow(chm_cleaned_imgs1[2],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 2')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,5)\n",
        "plt.imshow(chm_cleaned_imgs2[2],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 3')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfi97wAaKEXR"
      },
      "source": [
        "# COMPARISON OF ARITHMETIC,GEOMETRIC AND CONTRA-HARMONIC  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6hDhVpp6KWRx",
        "outputId": "d8263054-fff5-41f0-aad9-24b63694945d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(avg_cleaned_imgs[0],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(geo_imgs1[0],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(chm_cleaned_imgs0[0],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 1')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(avg_cleaned_imgs[2],cmap='gray')\n",
        "plt.title('Average filter')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(geo_imgs1[2],cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(chm_cleaned_imgs0[2],cmap='gray')\n",
        "plt.title('Contra-Harmonic filter 1')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0wCPrMAMeXT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_neighbors_matrix(filter_size, i, j, data):\n",
        "    mid_position = filter_size // 2\n",
        "    neighbors = []\n",
        "    for z in range(filter_size):\n",
        "        if i + z - mid_position < 0 or i + z - mid_position > len(data) - 1:\n",
        "            for c in range(filter_size):\n",
        "                neighbors.append(0)\n",
        "        elif j + z - mid_position < 0 or j + mid_position > len(data[0]) - 1:\n",
        "            neighbors.append(0)\n",
        "        else:\n",
        "            for k in range(filter_size):\n",
        "                neighbors.append(data[i + z - mid_position]\n",
        "                                 [j + k - mid_position])\n",
        "\n",
        "    return neighbors\n",
        "\n",
        "def get_harmonic_mean(matrix):\n",
        "    matrix= np.array(matrix)\n",
        "    float_matrix = matrix\n",
        "    counter = len(matrix)\n",
        "    if sum_value == 0:\n",
        "      sum_value = 1\n",
        "    else:\n",
        "      sum_value = np.sum(np.reciprocal(float_matrix))\n",
        "\n",
        "    result = counter / sum_value\n",
        "    return np.around(result, decimals=3)\n",
        "\n",
        "def apply_harmonic_mean(img, filter_size):\n",
        "    original = np.full_like(imgs,0)\n",
        "    obtained = np.full_like(imgs,0)\n",
        "    if len(img.shape) == 2:\n",
        "        for i in range(len(original)):\n",
        "            for j in range(len(original[0])):\n",
        "                neighbors = get_neighbors_matrix(\n",
        "                    filter_size, i, j, original)\n",
        "                obtained[i][j] = get_harmonic_mean(neighbors)\n",
        "    obtained\n",
        "    return obtained\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIdzKHVL193R",
        "outputId": "f3bed551-1fc5-4f67-c83c-fe5066a6b9a1"
      },
      "outputs": [],
      "source": [
        "salt_pepper_imgs[i,:,:].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZIAGkcz07TZ"
      },
      "outputs": [],
      "source": [
        "img = imgs[0,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "zcH_mOmM6epJ",
        "outputId": "79a9af40-7ab4-4263-f1d9-92e259f19c3f"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySb4YwuT7-_m",
        "outputId": "e66d4707-75bb-44de-baae-7f98cbb133e8"
      },
      "outputs": [],
      "source": [
        "filter_size = 9\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77Zb01t78FXA"
      },
      "outputs": [],
      "source": [
        "def get_neighbors_matrix(filter_size, i, j, data):\n",
        "        mid_position = filter_size // 2\n",
        "        neighbors = []\n",
        "        for z in range(filter_size):\n",
        "            if i + z - mid_position < 0 or i + z - mid_position > len(data) - 1:\n",
        "                for c in range(filter_size):\n",
        "                    neighbors.append(0)\n",
        "            elif j + z - mid_position < 0 or j + mid_position > len(data[0]) - 1:\n",
        "                neighbors.append(0)\n",
        "            else:\n",
        "                for k in range(filter_size):\n",
        "                    neighbors.append(data[i + z - mid_position]\n",
        "                                     [j + k - mid_position])\n",
        "                    \n",
        "        return neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekO4nxa89XMP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "def harmonic_mean_filter(image, kernel_size=2, boundary='fill', fillvalue=0):\n",
        "    \n",
        "    # Create an empty kernel array\n",
        "    kernel = np.zeros((kernel_size, kernel_size))\n",
        "    print(kernel)\n",
        "    # Iterate over the kernel array and compute the filtered value for each element\n",
        "    for i in range(kernel_size):\n",
        "        for j in range(kernel_size):\n",
        "            # Compute the harmonic mean of the pixel values in the kernel window\n",
        "            kernel[i, j] = 1 / np.mean([1/image[i + m, j + n] for m in range(-1, 2) for n in range(-1, 2)])\n",
        "    \n",
        "    # Perform convolution using the kernel and the input image\n",
        "    filtered_image = signal.convolve2d(image, kernel, boundary=boundary, fillvalue=fillvalue)\n",
        "    \n",
        "    return filtered_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "GkdxyNqXQU83",
        "outputId": "59bdfa3e-ac2a-49f6-91c2-63d79550b1f5"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(salt_pepper_imgs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BGGqsHXW_LRd",
        "outputId": "c8034fbc-2eb6-4a00-e2a7-0ea4d5e9b22b"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    cv2_imshow(harmonic_mean_filter(salt_pepper_imgs[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pYzQ0fklSCjt",
        "outputId": "59aa2821-8c3c-4e5f-9686-b8aa63707728"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "    cv2_imshow(harmonic_mean_filter(salt_pepper_imgs[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzZNPr_SQ5HF"
      },
      "source": [
        "<b> Depth sensing </b>\n",
        "\n",
        "Group 4\n",
        "  * Abishek M (CB.EN.U4CSE20601)â\n",
        "  * Shankara Narayana V (CB.EN.U4CSE20656)â\n",
        "  * Sneha Varsha M (CB.EN.U4CSE20659)â\n",
        "  * Syed Ashfaq Ahmed (CB.EN.U4CSE20665)â\n",
        "  * Tarun Ramaswamy (CB.EN.U4CSE20666)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORsD-kAlQz_c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings \n",
        "from PIL import Image\n",
        "import math\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcQbU1kcQ3w-",
        "outputId": "567eecef-882d-4460-836c-30e332d55a0c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Shankar0x/DepthSensingDatasets.git driving_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhtSeoi2Q4n2",
        "outputId": "405e5c66-598b-4b88-d022-d09167e41505"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Shankar0x/DepthSensingDatasets.git images\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kfMadr0Rins",
        "outputId": "61dc8ffd-7d0f-41bf-9088-b9e8f8b9bcbd"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "left_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/left.png').convert('L')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/left.png').convert('L')\n",
        "    data = np.asarray(image)\n",
        "    left_imgs[i-1] = data\n",
        "left_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkm7yMu5Rjue",
        "outputId": "461f6d58-a2c0-49ef-e38a-dfa1d55c7704"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "right_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/right.png').convert('L')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/right.png').convert('L')\n",
        "    data = np.asarray(image)\n",
        "    right_imgs[i-1] = data\n",
        "right_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM-r5n1fRkqc",
        "outputId": "04607bf0-d091-47a5-e006-943a5b5f66ad"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "right_disp_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/right_disp.png')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/right_disp.png')\n",
        "    data = np.asarray(image)\n",
        "    right_disp_imgs[i-1] = data\n",
        "right_disp_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUSjf1QsRlis",
        "outputId": "222dd07b-de1f-4947-faac-0ae41cf08c5a"
      },
      "outputs": [],
      "source": [
        "path = 'images/Reduced_dataset/0000'\n",
        "left_disp_imgs = np.zeros((30,860,1080))\n",
        "for i in range(1,30):\n",
        "    if i<=9:\n",
        "        image = Image.open(path+'0'+str(i)+'/left_disp.png')\n",
        "    else:\n",
        "        image = Image.open(path+str(i)+'/left_disp.png')\n",
        "    data = np.asarray(image)\n",
        "    left_disp_imgs[i-1] = data\n",
        "left_disp_imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf8XVA_LRmbl",
        "outputId": "f93deb37-9852-4991-ba5a-ada6a8894db4"
      },
      "outputs": [],
      "source": [
        "path = 'driving_images/DrivingStereo_dataset/'\n",
        "imgs = np.zeros((10,400,879))\n",
        "for i in range(1,10):\n",
        "        image = Image.open(path+'00'+str(i)+'.jpg').convert('L')\n",
        "        data = np.asarray(image)\n",
        "        imgs[i-1] = data\n",
        "imgs[9] = np.asarray(Image.open(path+'010.jpg').convert('L'))\n",
        "imgs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb95XqFaRoAc"
      },
      "source": [
        "### Datasets used\n",
        "``` \n",
        "        Indoor dataset --> left_imgs, right_imgs, left_disp_imgs, right_disp_imgs\n",
        "        Driving dataset --> imgs\n",
        "``` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OmFhI6z37f_"
      },
      "source": [
        "NOISE GENERATION: \n",
        "\n",
        "\n",
        "> Salt & Pepper, Gaussian, Salt, Pepper\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dj_Ctfz3-oS"
      },
      "outputs": [],
      "source": [
        "def noise_gen(img,typeofnoise):\n",
        "    row,col= img.shape\n",
        "    if typeofnoise == 'Gaussian':\n",
        "        gauss = np.random.normal(10,10,(row,col))\n",
        "        noisy = img + gauss\n",
        "    elif typeofnoise == 'SnP':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        pepper = 0.05\n",
        "        salt = 1-pepper\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn < pepper:\n",
        "                    noise[i][j]=0\n",
        "                elif rdn>salt:\n",
        "                    noise[i][j]=255\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    elif typeofnoise == 'Salt':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        salt = 0.6\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn>salt:\n",
        "                    noise[i][j]=255\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    elif typeofnoise == 'Pepper':\n",
        "        noise = np.zeros((row,col),dtype = np.float32)\n",
        "        pepper = 0.6\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                rdn = np.random.random()\n",
        "                if rdn < pepper:\n",
        "                    noise[i][j]=0\n",
        "                else:\n",
        "                    noise[i][j]=img[i][j]\n",
        "        noisy = img + noise\n",
        "    return noisy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTl4kgDd4EFg"
      },
      "source": [
        "ARITHMETIC MEAN FILTER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP5MXLyV4FwA"
      },
      "source": [
        "The Arithmetic mean filter is an simple smoothing filter. This uses Blurring effect to remove the noise from the image\n",
        "This works both with salt and pepper noise as well as Gaussian Noise "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgcKxdws4Hk4"
      },
      "outputs": [],
      "source": [
        "def arithmeticmean(img):\n",
        "    m, n = img.shape\n",
        "      \n",
        "    mask = np.ones([10, 10], dtype = int)\n",
        "    mask = mask / 100\n",
        "      \n",
        "    img_new = np.zeros([m, n])\n",
        "    \n",
        "    for i in range(1, m-1):\n",
        "        for j in range(1, n-1):\n",
        "            temp = img[i-1, j-1]*mask[0, 0]+img[i-1, j]*mask[0, 1]+img[i-1, j + 1]*mask[0, 2]+img[i, j-1]*mask[1, 0]+ img[i, j]*mask[1, 1]+img[i, j + 1]*mask[1, 2]+img[i + 1, j-1]*mask[2, 0]+img[i + 1, j]*mask[2, 1]+img[i + 1, j + 1]*mask[2, 2]\n",
        "            \n",
        "            img_new[i, j]= temp\n",
        "            \n",
        "    img_new = img_new.astype(np.uint8)\n",
        "    return img_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9ERDwIX4JQ0"
      },
      "outputs": [],
      "source": [
        "img0 = right_imgs[0]\n",
        "salt_pepper_img0 = noise_gen(img0, 'SnP')\n",
        "gaussian_img0 = noise_gen(img0,'Gaussian')\n",
        "avg_cleaned_img1 = arithmeticmean(salt_pepper_img0)\n",
        "avg_cleaned_img2 = arithmeticmean(gaussian_img0)\n",
        "\n",
        "img1 = right_imgs[1]\n",
        "salt_pepper_img1 = noise_gen(img1, 'SnP')\n",
        "gaussian_img1 = noise_gen(img1,'Gaussian')\n",
        "avg_cleaned_imgs1 = arithmeticmean(salt_pepper_img1)\n",
        "avg_cleaned_imgs2 = arithmeticmean(gaussian_img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "gTdJakp-4ZjN",
        "outputId": "864f7df3-26c9-4286-dc9b-812ca84694b7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,5,1)\n",
        "plt.imshow(img0,cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,2)\n",
        "plt.imshow(salt_pepper_img0,cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,3)\n",
        "plt.imshow(gaussian_img0,cmap='gray')\n",
        "plt.title('Gaussian noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,4)\n",
        "plt.imshow(avg_cleaned_img1,cmap='gray')\n",
        "plt.title('Mean filter for salt&pepper')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,5)\n",
        "plt.imshow(avg_cleaned_img2,cmap='gray')\n",
        "plt.title('Mean filter for Gaussian')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,5,1)\n",
        "plt.imshow(img1,cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,2)\n",
        "plt.imshow(salt_pepper_img1,cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,3)\n",
        "plt.imshow(gaussian_img1,cmap='gray')\n",
        "plt.title('Gaussian noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,4)\n",
        "plt.imshow(avg_cleaned_imgs1,cmap='gray')\n",
        "plt.title('Mean filter for salt&pepper')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,5,5)\n",
        "plt.imshow(avg_cleaned_imgs2,cmap='gray')\n",
        "plt.title('Mean filter for Gaussian')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxOfqUtv4bqP"
      },
      "source": [
        "As, there are less differences obervable to the bare eyes. We use measuring scale to see the difference in the noise reduction. The measuring scale used here is Peak Signal to Noise Ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qbbWHR64dYJ"
      },
      "outputs": [],
      "source": [
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):  \n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "9tZEdpcS4eiV",
        "outputId": "72c0734d-8128-47ff-b39f-1cc9bc7cec2d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "x = []\n",
        "x.append(PSNR(img0,avg_cleaned_img2))\n",
        "x.append(PSNR(img1,avg_cleaned_imgs2))\n",
        "\n",
        "y = []\n",
        "y.append(PSNR(img0,gaussian_img0))\n",
        "y.append(PSNR(img1,gaussian_img1))\n",
        "\n",
        "data = {'Gauss_Initial': y,'Arithmetic_result': x}  \n",
        "df1 = pd.DataFrame(data)\n",
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGCDuqGC4ugv"
      },
      "source": [
        "The above table denotes the Signal to noise ratio, this can be used to identify the change in noise.The PSNR ratio for Gaussian noise where the difference is more around ~8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lRXn_y14wwB"
      },
      "source": [
        "GEOMETRIC MEAN FILTER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUP40WMI4yhL"
      },
      "source": [
        "Geometric mean is a type of mean filter which can reduce the loss in image details. Geometric mean filter is used to denoise the salt&pepper noise more effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wku1_Mcc40OZ"
      },
      "outputs": [],
      "source": [
        "def geometricmean(img,k):\n",
        "  m,n = img.shape\n",
        "  ksize = k\n",
        "  padsize = int((ksize-1)/2)\n",
        "  pad_img = cv2.copyMakeBorder(img, *[padsize]*4, cv2.BORDER_DEFAULT)\n",
        "  geomean1 = np.zeros_like(img)\n",
        "  for r in range(m):\n",
        "      for c in range(n):\n",
        "          geomean1[r, c] = np.prod(pad_img[r:r+ksize, c:c+ksize])**(1/(ksize**2))\n",
        "  geomean1 = np.uint8(geomean1)\n",
        "  return geomean1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19zu2C7k4105"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "geo_imgs1 = geometricmean(salt_pepper_img0,1)  \n",
        "geo_imgs2 = geometricmean(salt_pepper_img0,3)\n",
        "\n",
        "geo_img1 = geometricmean(salt_pepper_img1,1)  \n",
        "geo_img2 = geometricmean(salt_pepper_img1,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "PmukJzWh47Bz",
        "outputId": "397e37b6-1704-440b-8f37-c94ab56ecad8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(img0,cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_img0,cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_imgs1,cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_imgs2,cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(30,5))\n",
        "\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(img1,cmap='gray')\n",
        "plt.title('Original image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(salt_pepper_img1,cmap='gray')\n",
        "plt.title('Salt and pepper noise')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(geo_img1,cmap='gray')\n",
        "plt.title('Geometric Filter 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(geo_img2,cmap='gray')\n",
        "plt.title('Geometric Filter 2')\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "vIdEOn9k49IJ",
        "outputId": "7e469463-4739-4bab-e2de-ed741a6f6d44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "x = []\n",
        "x.append(PSNR(img0,geo_img1))\n",
        "x.append(PSNR(img1,geo_imgs1))\n",
        "\n",
        "y = []\n",
        "y.append(PSNR(img0,gaussian_img0))\n",
        "y.append(PSNR(img1,gaussian_img1))\n",
        "\n",
        "data = {'Salt_Initial': y,'Geo_result': x}  \n",
        "df1 = pd.DataFrame(data)\n",
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UlNqanLGBTj"
      },
      "source": [
        "## EROSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTJinwvVGFJT"
      },
      "source": [
        "Erosion is a morphological image processing operation that erodes away the boundaries of white foreground pixels. It does this with 15 * 15 and 25 * 25 Structuring element in the given data set. The structuring elements can be some matrices which is less in size than the given image. The image which are eroded will be with objects of bigger pixel size.\n",
        "\n",
        "\n",
        "*   It diminishes the object area and erodes the boundary of the foreground object.\n",
        "*  It also removes some small white noises.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYTqTBCUGInb"
      },
      "outputs": [],
      "source": [
        "def erosion(img,img2,k,k1):\n",
        "  img1 = img\n",
        "  m,n = img.shape\n",
        "# Define the structuring element\n",
        "# k= 11,15,45 -Different sizes of the structuring element\n",
        "  fig, ax = plt.subplots(2,3,figsize=(20,12))\n",
        "  ax[0,0].title.set_text('Original Image')\n",
        "  ax[0,0].imshow(img1, cmap='gray')\n",
        "  ax[0,0].axis('off')\n",
        "\n",
        "  ax[1,0].title.set_text('Original Image')\n",
        "  ax[1,0].imshow(img2, cmap='gray')\n",
        "  ax[1,0].axis('off')\n",
        "\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgErode= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgErode[i,j]= np.min(product)\n",
        "\n",
        "  ax[0,1].title.set_text('Erosion Filtered k=15')\n",
        "  ax[0,1].imshow(imgErode, cmap='gray')\n",
        "  ax[0,1].axis('off')\n",
        "\n",
        " #new line\n",
        "  SE1= np.ones((k1,k1), dtype=np.uint8)\n",
        "  constant= (k1-1)//2\n",
        "\n",
        "  imgErode= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE1\n",
        "      imgErode[i,j]= np.min(product)\n",
        "\n",
        "  ax[0,2].title.set_text('Erosion Filtered k=25')\n",
        "  ax[0,2].imshow(imgErode, cmap='gray')\n",
        "  ax[0,2].axis('off')\n",
        "\n",
        "\n",
        "  #new line\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgErode1= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img2[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgErode1[i,j]= np.min(product)\n",
        "\n",
        "  ax[1,1].title.set_text('Erosion Filtered k=15')\n",
        "  ax[1,1].imshow(imgErode1,cmap='gray')\n",
        "  ax[1,1].axis('off')\n",
        "\n",
        "  #new line\n",
        "  SE1= np.ones((k1,k1), dtype=np.uint8)\n",
        "  constant= (k1-1)//2\n",
        "\n",
        "  imgErode1= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img2[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE1\n",
        "      imgErode1[i,j]= np.min(product)\n",
        "\n",
        "  ax[1,2].title.set_text('Erosion Filtered k=25')\n",
        "  ax[1,2].imshow(imgErode1,cmap='gray')\n",
        "  ax[1,2].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "IcRLa9zAGLRE",
        "outputId": "c98f192b-d309-469a-df87-104ebc06601a"
      },
      "outputs": [],
      "source": [
        "erosion(left_imgs[0],left_imgs[1],15,25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZeBXRmGMuD"
      },
      "source": [
        "## DILATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy-f-ZV9GOjV"
      },
      "source": [
        "Dilation is a morphological image processing operation that expands the boundaries of white foreground pixels.\n",
        "*   It increases the object area and reduces the boundary of the foreground object.\n",
        "\n",
        "*   It enhaces the white color and increases the features of image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z5ZOfOeGWxN"
      },
      "outputs": [],
      "source": [
        "def dilat(img,img2,k,k1):\n",
        "  img1 = img\n",
        "  m,n = img.shape\n",
        "# Define the structuring element\n",
        "# k= 11,15,45 -Different sizes of the structuring element\n",
        "  fig, ax = plt.subplots(2,3,figsize=(20,12))\n",
        "  ax[0,0].title.set_text('Original Image')\n",
        "  ax[0,0].imshow(img1, cmap='gray')\n",
        "  ax[0,0].axis('off')\n",
        "\n",
        "  ax[1,0].title.set_text('Original Image')\n",
        "  ax[1,0].imshow(img2, cmap='gray')\n",
        "  ax[1,0].axis('off')\n",
        "\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgdilat= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  #Erosion without using inbuilt cv2 function for morphology\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgdilat[i,j]= np.max(product)\n",
        "\n",
        "  ax[0,1].title.set_text('Dilation Filtered k=15')\n",
        "  ax[0,1].imshow(imgdilat, cmap='gray')\n",
        "  ax[0,1].axis('off')\n",
        "\n",
        " #new line\n",
        "  SE1= np.ones((k1,k1), dtype=np.uint8)\n",
        "  constant= (k1-1)//2\n",
        "\n",
        "  imgdilat= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  #Erosion without using inbuilt cv2 function for morphology\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE1\n",
        "      imgdilat[i,j]= np.max(product)\n",
        "\n",
        "  ax[0,2].title.set_text('Dilation Filtered k=25')\n",
        "  ax[0,2].imshow(imgdilat, cmap='gray')\n",
        "  ax[0,2].axis('off')\n",
        "\n",
        "\n",
        "  #new line\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgdilat1= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img2[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgdilat1[i,j]= np.max(product)\n",
        "\n",
        "  ax[1,1].title.set_text('Dilation Filtered k=15')\n",
        "  ax[1,1].imshow(imgdilat1,cmap='gray')\n",
        "  ax[1,1].axis('off')\n",
        "\n",
        "  #new line\n",
        "  SE1= np.ones((k1,k1), dtype=np.uint8)\n",
        "  constant= (k1-1)//2\n",
        "\n",
        "  imgdilat1= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img2[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE1\n",
        "      imgdilat1[i,j]= np.max(product)\n",
        "\n",
        "  ax[1,2].title.set_text('Dilation Filtered k=25')\n",
        "  ax[1,2].imshow(imgdilat1,cmap='gray')\n",
        "  ax[1,2].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "XMF3pckoGRXV",
        "outputId": "4bbcc0e4-332f-4679-dbf1-3253f39031d3"
      },
      "outputs": [],
      "source": [
        "dilat(left_imgs[0],left_imgs[1],15,25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDtdU9-xGY7e"
      },
      "source": [
        "OPENING AND CLOSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BBx7mMkGcmW"
      },
      "source": [
        "The Closing is a process in which first dilation operation is performed and then erosion operation is performed.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The Opening is a process in which first erosion operation is performed and then dilation operation is performed.\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfOMYnmMGiCI"
      },
      "outputs": [],
      "source": [
        "def erosion(img,k):\n",
        "  img1 = img\n",
        "  m,n = img.shape\n",
        "\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgErode= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgErode[i,j]= np.min(product)\n",
        "\n",
        "  return imgErode\n",
        "\n",
        "def dilat(img,k):\n",
        "  img1 = img\n",
        "  m,n = img.shape\n",
        "\n",
        "  SE= np.ones((k,k), dtype=np.uint8)\n",
        "  constant= (k-1)//2\n",
        "\n",
        "  imgdilat= np.zeros((m,n), dtype=np.uint8)\n",
        "\n",
        "  for i in range(constant, m-constant):\n",
        "    for j in range(constant,n-constant):\n",
        "      temp= img1[i-constant:i+constant+1, j-constant:j+constant+1]\n",
        "      product= temp*SE\n",
        "      imgdilat[i,j]= np.max(product)\n",
        "\n",
        "  return imgdilat\n",
        "\n",
        "\n",
        "Dilated = dilat(left_imgs[0],15)\n",
        "Dilated1 = dilat(left_imgs[1],15)\n",
        "\n",
        "open = dilat(erosion(left_imgs[0],15),15) \n",
        "closed = erosion(dilat(left_imgs[0],15),15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7xJzdpJGjhX"
      },
      "outputs": [],
      "source": [
        "erode = erosion(left_imgs[0],15)\n",
        "erode1 = erosion(left_imgs[1],15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0A7xvW8GkmQ"
      },
      "outputs": [],
      "source": [
        "open1 = dilat(erosion(left_imgs[1],15),15)\n",
        "closed1 = erosion(dilat(left_imgs[1],15),15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "yJH1NoPnGlmA",
        "outputId": "5c8c0d88-93c0-4209-9cf4-60eb9a8a255e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,4,figsize=(30,10))\n",
        "\n",
        "ax[0,0].title.set_text('Eroded Image 1')\n",
        "ax[0,0].imshow(erode, cmap='gray')\n",
        "ax[0,0].axis('off')\n",
        "\n",
        "ax[1,0].title.set_text('Eroded Image 2')\n",
        "ax[1,0].imshow(erode1, cmap='gray')\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "ax[0,1].title.set_text('Dilated Image 1')\n",
        "ax[0,1].imshow(Dilated, cmap='gray')\n",
        "ax[0,1].axis('off')\n",
        "\n",
        "ax[1,1].title.set_text('Dilated Image 2')\n",
        "ax[1,1].imshow(Dilated1, cmap='gray')\n",
        "ax[1,1].axis('off')\n",
        "\n",
        "ax[0,2].title.set_text('Opened Image 1')\n",
        "ax[0,2].imshow(open, cmap='gray')\n",
        "ax[0,2].axis('off')\n",
        "\n",
        "ax[1,2].title.set_text('Opened Image 2')\n",
        "ax[1,2].imshow(open1, cmap='gray')\n",
        "ax[1,2].axis('off')\n",
        "\n",
        "ax[0,3].title.set_text('Closed Image 1')\n",
        "ax[0,3].imshow(closed, cmap='gray')\n",
        "ax[0,3].axis('off')\n",
        "\n",
        "ax[1,3].title.set_text('Closed Image 2')\n",
        "ax[1,3].imshow(closed1, cmap='gray')\n",
        "ax[1,3].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqmDNSB6GnOH"
      },
      "source": [
        "Boundary detection using Dilation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CWgAknPGpHg"
      },
      "source": [
        "Boundary extraction is one of the applications of morphological transformations.\n",
        "This is a simple process in which morphological process is used by using the Dilation. \n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "The Process consists of finding the difference between the input image and the dilated image. The boundary will be black in colour and foreground will be white in colour "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yHqe5IoGquR"
      },
      "outputs": [],
      "source": [
        "def boundary(img):\n",
        "  ext_bound = img - erode\n",
        "  return ext_bound\n",
        "\n",
        "def boundary1(img):\n",
        "  ext_bound = img - erode1\n",
        "  return ext_bound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT8HPpwEGs9A"
      },
      "outputs": [],
      "source": [
        "b1=boundary(left_imgs[0])\n",
        "b2=boundary1(left_imgs[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "bWWBJQ9lGuSd",
        "outputId": "d95d3d3f-c548-4de5-fc5c-d3db05dfbd61"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(2,3,figsize=(20,10))\n",
        "\n",
        "ax[0,0].title.set_text('Orignal Image 1')\n",
        "ax[0,0].imshow(left_imgs[0], cmap='gray')\n",
        "ax[0,0].axis('off')\n",
        "\n",
        "ax[1,0].title.set_text('Original Image 2')\n",
        "ax[1,0].imshow(left_imgs[1], cmap='gray')\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "ax[0,1].title.set_text('Dilated Image Mask')\n",
        "ax[0,1].imshow(Dilated, cmap='gray')\n",
        "ax[0,1].axis('off')\n",
        "\n",
        "ax[1,1].title.set_text('Dilated Image Mask')\n",
        "ax[1,1].imshow(Dilated1, cmap='gray')\n",
        "ax[1,1].axis('off')\n",
        "\n",
        "ax[0,2].title.set_text('Image 1 Boundary')\n",
        "ax[0,2].imshow(b1, cmap='gray')\n",
        "ax[0,2].axis('off')\n",
        "\n",
        "ax[1,2].title.set_text('Image 2 Boundary')\n",
        "ax[1,2].imshow(b2, cmap='gray')\n",
        "ax[1,2].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Cb4D8MRpkc"
      },
      "source": [
        "Otsu's Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "hc2t1ooPRrre",
        "outputId": "7ccb09dc-dbad-4b20-95a1-286ded004891"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_img = imgs[0]\n",
        "plt.imshow(test_img,cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYb79d6-Rs0V"
      },
      "source": [
        "### Algorithm\n",
        "<ol>\n",
        "<li> Plot the histogram \n",
        "<li> The image passed must be filtered and no noise must be present. Since this was taken care by previous preprocessing steps, the histogram is sure to be binarized \n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "<li> Using the above formula the histogram is plotted on a range of values from 0-255 on the X-axis and the count of each pixels in the Y-axis\n",
        "\n",
        "<li> The following metrics are to be calculated:\n",
        "\n",
        "![image.png](attachment:image-2.png)\n",
        "<ol>\n",
        "    <li> Weights\n",
        "    <li> Variance \n",
        "    <li> Mean\n",
        "</ol>\n",
        "\n",
        "<li> Within class variance\n",
        "\n",
        "![image.png](attachment:image-3.png)\n",
        "\n",
        "<li> Between class variance \n",
        "\n",
        "![image.png](attachment:image-4.png)\n",
        "<li> Using within class variance the possible thresholding values are added to the dictionary\n",
        "<li> Finally using the get_optimal_threshold method the best threshold is chosen from the dictionary. That chosen threshold is applied as the global threshold on the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTp371p_R0hF"
      },
      "outputs": [],
      "source": [
        "class otsu:\n",
        "\n",
        "    def __init__(self, img):\n",
        "        self.img = img\n",
        "        self.threshold_values = {}\n",
        "        self.h = [1]\n",
        "\n",
        "    def Hist(self):\n",
        "        row, col = self.img.shape \n",
        "        y = np.zeros(256)\n",
        "        for i in range(0,row):\n",
        "            for j in range(0,col):\n",
        "                y[self.img[i,j]] += 1\n",
        "        return y\n",
        "\n",
        "    def countPixel(self):\n",
        "        self.h = self.Hist()\n",
        "        cnt = 0\n",
        "        for i in range(0, len(self.h)):\n",
        "            if self.h[i]>0:\n",
        "                cnt += self.h[i]\n",
        "        return cnt\n",
        "\n",
        "    def weight(self, s, e):\n",
        "        w = 0\n",
        "        for i in range(s, e):\n",
        "            w += self.h[i]\n",
        "        return w\n",
        "\n",
        "    def mean(self, s, e):\n",
        "        m = 0\n",
        "        w = self.weight(s, e)\n",
        "        for i in range(s, e):\n",
        "            m += self.h[i] * i\n",
        "        return m/float(w)\n",
        "\n",
        "    def variance(self, s, e):\n",
        "        v = 0\n",
        "        m = self.mean(s, e)\n",
        "        w = self.weight(s, e)\n",
        "        for i in range(s, e):\n",
        "            v += ((i - m) **2) * self.h[i]\n",
        "        v /= w\n",
        "        return v\n",
        "    \n",
        "    def threshold(self):\n",
        "        cnt = self.countPixel()\n",
        "        for i in range(1, len(self.h)):\n",
        "            vb = self.variance(0, i)\n",
        "            wb = self.weight(0, i) / float(cnt)\n",
        "            mb = self.mean(0, i)\n",
        "            \n",
        "            vf = self.variance(i, len(self.h))\n",
        "            wf = self.weight(i, len(self.h)) / float(cnt)\n",
        "            mf = self.mean(i, len(self.h))\n",
        "            \n",
        "            V2w = wb * (vb) + wf * (vf)\n",
        "            V2b = wb * wf * (mb - mf)**2\n",
        "            \n",
        "            if not math.isnan(V2w):\n",
        "                self.threshold_values[i] = V2w\n",
        "    \n",
        "    def get_optimal_threshold(self):\n",
        "        min_V2w = min(self.threshold_values.values())\n",
        "        optimal_threshold = [k for k, v in self.threshold_values.items() if v == min_V2w]\n",
        "        return optimal_threshold[0]\n",
        "\n",
        "def otsu_thresholding(image):\n",
        "    img = image.astype('int8')\n",
        "    ot = otsu(img)\n",
        "    x = np.arange(0,256)\n",
        "    h = ot.Hist()\n",
        "    ot.threshold()\n",
        "    op_thres = ot.get_optimal_threshold()\n",
        "\n",
        "    plt.title(f\"Optimal threshold {op_thres}\")\n",
        "    plt.bar(x, h, color='b', width=5, align='center', alpha=0.25)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2,figsize=(20,9))\n",
        "\n",
        "    ax[0].title.set_text('Original Image')\n",
        "    ax[0].imshow(image,cmap='gray')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].title.set_text('After Otsu Thresholding')\n",
        "    ax[1].imshow(image>op_thres,cmap='gray');\n",
        "    ax[1].axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkrygPA4R3UO"
      },
      "source": [
        "Outdoor Images Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "eAcx3vCXR5q3",
        "outputId": "3ee9c0c7-9dcc-4f59-847f-2bc7d2d23704"
      },
      "outputs": [],
      "source": [
        "# Randomly picking 4 outdoor dataset images\n",
        "import random\n",
        "res = random.sample(range(0, imgs.shape[0]), 4)\n",
        "otsu_thresholding(imgs[res[0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "aRS4nZWnR6wI",
        "outputId": "a15c11a6-185c-455f-f9d5-311258ba15c8"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(imgs[res[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "GD_byD75R7tg",
        "outputId": "416056aa-d932-491a-e828-e5d5b8812d6f"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(imgs[res[2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "TmPMHUU7R81i",
        "outputId": "71c25fbb-9dd6-4e90-9b4f-b75a909ff2e1"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(imgs[res[3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl051iB8R-K_"
      },
      "source": [
        "<b> Indoor images dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "UvDx_SzKR_SI",
        "outputId": "4f20f2b1-876a-4c63-cf12-0864e0d9925d"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, left_imgs.shape[0]), 2)\n",
        "otsu_thresholding(left_imgs[res[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "yKQrkVHsSARx",
        "outputId": "a9e3e481-f0b6-48ba-c154-410cc19f0007"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(left_imgs[res[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "QpzOOMwvSBi5",
        "outputId": "83a6b3b7-affd-43a9-dbe0-ae38b7882f0b"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, right_imgs.shape[0]), 2)\n",
        "otsu_thresholding(right_imgs[res[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "cM_kzlWlSCpU",
        "outputId": "04643784-00d7-498d-cd39-734ba9e4e174"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(right_imgs[res[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX9ZfI6BSEFR"
      },
      "source": [
        "#### Using smoothing techniques to improve global threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veNnoie8SFW4"
      },
      "source": [
        "<b> Outdoor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "zRQN-cZQSHTq",
        "outputId": "f163124c-5931-4ead-9b33-8ac5d2baaeaa"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "res = random.sample(range(0, imgs.shape[0]), 1)\n",
        "fig, ax = plt.subplots(1,2,figsize=(20,9))\n",
        "\n",
        "ax[0].title.set_text('Original Image')\n",
        "ax[0].imshow(imgs[res[0]],cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "test_img_smooth = cv2.GaussianBlur(imgs[res[0]], (7,7),0)\n",
        "\n",
        "ax[1].title.set_text('Smooth image')\n",
        "ax[1].imshow(test_img_smooth,cmap='gray')\n",
        "ax[1].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lucM5hTqSIhx"
      },
      "source": [
        "Thresholding the Original Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "PSu2-F63SKwM",
        "outputId": "0250d099-159d-48b5-fc16-08ed401984b4"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(imgs[res[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mqy5tgpSL7B"
      },
      "source": [
        "<b> Thresholding smoothened version of original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "1mcjhjl2SM1Z",
        "outputId": "b2869ca2-faf8-4905-f63a-8a108f6fc057"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(test_img_smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHgld3DjSOLq"
      },
      "source": [
        "<b> Indoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "wqiHqVIZSPVc",
        "outputId": "86fb42fe-d804-4f99-f791-0652b37e17c6"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, left_imgs.shape[0]), 1)\n",
        "fig, ax = plt.subplots(1,2,figsize=(20,9))\n",
        "\n",
        "ax[0].title.set_text('Original Image')\n",
        "ax[0].imshow(left_imgs[res[0]],cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "test_img_smooth = cv2.GaussianBlur(left_imgs[res[0]], (7,7),0)\n",
        "\n",
        "ax[1].title.set_text('Smooth image')\n",
        "ax[1].imshow(test_img_smooth,cmap='gray')\n",
        "ax[1].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCPwXFRQSQe6"
      },
      "source": [
        "<b> Thresholding original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "UMKVwLRWSRha",
        "outputId": "77e40a00-ff93-48b6-e9b7-f38a18438369"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(left_imgs[res[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l81mWA0KSTzi"
      },
      "source": [
        "<b> Thresholding smoothened version of the original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "kfzrEDYNSVDk",
        "outputId": "c10451f0-9ba1-4773-8c61-41eabe7c569c"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(test_img_smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp-xOVbISWjk"
      },
      "source": [
        "#### Using edges to improve global threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77qy6s5Sasl"
      },
      "source": [
        "<b> Outdoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D-o7ACU8Sblw",
        "outputId": "e5f17bf6-7b0e-4b93-d362-550bf04629d8"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, imgs.shape[0]), 1)\n",
        "fig, ax = plt.subplots(1,3,figsize=(20,9))\n",
        "\n",
        "ax[0].title.set_text('Original Image')\n",
        "ax[0].imshow(imgs[res[0]],cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "test_img_smooth = cv2.GaussianBlur(imgs[res[0]], (7,7),0)\n",
        "laplacian = cv2.Laplacian(test_img_smooth,cv2.CV_64F)\n",
        "\n",
        "ax[1].title.set_text('Laplacian Image')\n",
        "ax[1].imshow(laplacian,cmap='gray')\n",
        "ax[1].axis('off')\n",
        "\n",
        "test_edge_enhanced = test_img_smooth-laplacian\n",
        "\n",
        "ax[2].title.set_text('Edge enhanced Image')\n",
        "ax[2].imshow(test_edge_enhanced, cmap='gray')\n",
        "ax[2].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5GyDfnuSdCW"
      },
      "source": [
        "<b> Thresholding original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "Jfk1FFvJSeCF",
        "outputId": "b18dff6b-e03c-4b42-c284-2d81abfb6fda"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(imgs[res[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyvQMZJMSfWq"
      },
      "source": [
        "<b> Thresholding edge enhanced image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "ikPJjuIISgTR",
        "outputId": "d5930077-edad-4c54-e59f-4514efdf8d38"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(test_edge_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ncjPFIrShiB"
      },
      "source": [
        "<b> Indoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "1fU4PsYUSich",
        "outputId": "ab0b3faa-9161-4da0-b213-bc87c4b815ce"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, left_imgs.shape[0]), 1)\n",
        "fig, ax = plt.subplots(1,3,figsize=(20,9))\n",
        "\n",
        "ax[0].title.set_text('Original Image')\n",
        "ax[0].imshow(left_imgs[res[0]],cmap='gray')\n",
        "ax[0].axis('off')\n",
        "\n",
        "test_img_smooth = cv2.GaussianBlur(left_imgs[res[0]], (7,7),0)\n",
        "laplacian = cv2.Laplacian(test_img_smooth,cv2.CV_64F)\n",
        "\n",
        "ax[1].title.set_text('Laplacian Image')\n",
        "ax[1].imshow(laplacian,cmap='gray')\n",
        "ax[1].axis('off')\n",
        "\n",
        "test_edge_enhanced = test_img_smooth-laplacian\n",
        "\n",
        "ax[2].title.set_text('Edge enhanced Image')\n",
        "ax[2].imshow(test_edge_enhanced, cmap='gray')\n",
        "ax[2].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glzvaEqWSj-u"
      },
      "source": [
        "<b> Thresholding original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "tP0VkPe1SlFr",
        "outputId": "35a040b7-05cf-491b-97b8-26547ebcef6c"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(left_imgs[res[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRoI2JbWSnA1"
      },
      "source": [
        "<b> Thresholding edge enhanced image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "1CwBg-wrSoIu",
        "outputId": "db48befb-2c1c-4fa6-b43c-5f13638d8693"
      },
      "outputs": [],
      "source": [
        "otsu_thresholding(test_edge_enhanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28GYbVYsSpXq"
      },
      "source": [
        "#### Multiple threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tdgnaT7Sqmw"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, imgs.shape[0]), 1)\n",
        "img = imgs[res[0]]\n",
        "a = 0\n",
        "b = 255\n",
        "n = 4 # number of thresholds (better choose even value)\n",
        "k = 0.7 # free variable to take any positive value\n",
        "T = [] # list which will contain 'n' thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBZQVpZLSrdS",
        "outputId": "bd3c1673-3eda-4de4-f581-a7333289aa2b"
      },
      "outputs": [],
      "source": [
        "def multiThresh(img, a, b):\n",
        "    if a>b:\n",
        "        s=-1\n",
        "        m=-1\n",
        "        return m,s\n",
        "\n",
        "    img = np.array(img)\n",
        "    t1 = (img>=a)\n",
        "    t2 = (img<=b)\n",
        "    X = np.multiply(t1,t2)\n",
        "    Y = np.multiply(img,X)\n",
        "    s = np.sum(X)\n",
        "    m = np.sum(Y)/s\n",
        "    return m,s\n",
        "\n",
        "for i in range(int(n/2-1)):\n",
        "    img = np.array(img)\n",
        "    t1 = (img>=a)\n",
        "    t2 = (img<=b)\n",
        "    X = np.multiply(t1,t2)\n",
        "    Y = np.multiply(img,X)\n",
        "    mu = np.sum(Y)/np.sum(X)\n",
        "\n",
        "    Z = Y - mu\n",
        "    Z = np.multiply(Z,X)\n",
        "    W = np.multiply(Z,Z)\n",
        "    sigma = math.sqrt(np.sum(W)/np.sum(X))\n",
        "\n",
        "    T1 = mu - k*sigma\n",
        "    T2 = mu + k*sigma\n",
        "\n",
        "    x, y = multiThresh(img, a, T1)\n",
        "    w, z = multiThresh(img, T2, b)\n",
        "\n",
        "    T.append(x)\n",
        "    T.append(w)\n",
        "\n",
        "    a = T1+1\n",
        "    b = T2-1\n",
        "    k = k*(i+1)\n",
        "\n",
        "T1 = mu\n",
        "T2 = mu+1\n",
        "x, y = multiThresh(img, a, T1)\n",
        "w, z = multiThresh(img, T2, b)    \n",
        "T.append(x)\n",
        "T.append(w)\n",
        "T.sort()\n",
        "print(T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZpfaX33StOK"
      },
      "outputs": [],
      "source": [
        "def print_multi_otsu():\n",
        "    image = img\n",
        "\n",
        "    # Applying multi-Otsu threshold for the default value, generating\n",
        "    # three classes.\n",
        "    thresholds =T\n",
        "\n",
        "    # Using the threshold values, we generate the three regions.\n",
        "    regions = np.digitize(image, bins=thresholds)\n",
        "    \n",
        "    plt.hist(image.ravel(), bins=255)\n",
        "    plt.title('Histogram')\n",
        "    for thresh in thresholds:\n",
        "        plt.axvline(thresh, color='r')\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(20,9))\n",
        "\n",
        "    # Plotting the histogram and the two thresholds obtained from\n",
        "    # multi-Otsu.\n",
        "    \n",
        "\n",
        "    # Plotting the original image.\n",
        "    ax[0].imshow(image, cmap='gray')\n",
        "    ax[0].set_title('Original')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Plotting the Multi Otsu result.\n",
        "    ax[1].imshow(regions, cmap='jet')\n",
        "    ax[1].set_title('Multi-Otsu result')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.subplots_adjust()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHNA73rvSumw"
      },
      "source": [
        "<b> Outdoor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "Ddkh1r_HSvpP",
        "outputId": "b051cc03-7662-42b9-9ed7-8f2097521a61"
      },
      "outputs": [],
      "source": [
        "print_multi_otsu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU6LIvmpSw9A"
      },
      "source": [
        "<b> Indoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvXHNGvkSx4w"
      },
      "outputs": [],
      "source": [
        "res = random.sample(range(0, left_imgs.shape[0]), 1)\n",
        "img = left_imgs[res[0]]\n",
        "a = 0\n",
        "b = 255\n",
        "n = 2 # number of thresholds (better choose even value)\n",
        "k = 0.7 # free variable to take any positive value\n",
        "T = [] # list which will contain 'n' thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcqqEa7dSy2A",
        "outputId": "8b446f87-e780-4277-a39f-fd68b45d7b8d"
      },
      "outputs": [],
      "source": [
        "def multiThresh(img, a, b):\n",
        "    if a>b:\n",
        "        s=-1\n",
        "        m=-1\n",
        "        return m,s\n",
        "\n",
        "    img = np.array(img)\n",
        "    t1 = (img>=a)\n",
        "    t2 = (img<=b)\n",
        "    X = np.multiply(t1,t2)\n",
        "    Y = np.multiply(img,X)\n",
        "    s = np.sum(X)\n",
        "    m = np.sum(Y)/s\n",
        "    return m,s\n",
        "\n",
        "for i in range(int(n/2-1)):\n",
        "    img = np.array(img)\n",
        "    t1 = (img>=a)\n",
        "    t2 = (img<=b)\n",
        "    X = np.multiply(t1,t2)\n",
        "    Y = np.multiply(img,X)\n",
        "    mu = np.sum(Y)/np.sum(X)\n",
        "\n",
        "    Z = Y - mu\n",
        "    Z = np.multiply(Z,X)\n",
        "    W = np.multiply(Z,Z)\n",
        "    sigma = math.sqrt(np.sum(W)/np.sum(X))\n",
        "\n",
        "    T1 = mu - k*sigma\n",
        "    T2 = mu + k*sigma\n",
        "\n",
        "    x, y = multiThresh(img, a, T1)\n",
        "    w, z = multiThresh(img, T2, b)\n",
        "\n",
        "    T.append(x)\n",
        "    T.append(w)\n",
        "\n",
        "    a = T1+1\n",
        "    b = T2-1\n",
        "    k = k*(i+1)\n",
        "\n",
        "T1 = mu\n",
        "T2 = mu+1\n",
        "x, y = multiThresh(img, a, T1)\n",
        "w, z = multiThresh(img, T2, b)    \n",
        "T.append(x)\n",
        "T.append(w)\n",
        "T.sort()\n",
        "print(T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "Ywv4-DVKSzzR",
        "outputId": "22c739b5-3c94-42ce-a1df-2d2378711c10"
      },
      "outputs": [],
      "source": [
        "print_multi_otsu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi-1jU2hS1ZI"
      },
      "source": [
        "#### Variable thresholding using moving average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9w97mbPS2gQ"
      },
      "outputs": [],
      "source": [
        "class variable_thresholding:\n",
        "    def __init__(self, img):\n",
        "        self.img = img\n",
        "    def thresholdIntegral(self, inputMat,s,T = 0.15):\n",
        "        outputMat=np.zeros(inputMat.shape)\n",
        "        nRows = inputMat.shape[0]\n",
        "        nCols = inputMat.shape[1]\n",
        "        S = int(max(nRows, nCols) / 8)\n",
        "\n",
        "        s2 = int(S / 4)\n",
        "\n",
        "        for i in range(nRows):\n",
        "            y1 = i - s2\n",
        "            y2 = i + s2\n",
        "\n",
        "            if (y1 < 0) :\n",
        "                y1 = 0\n",
        "            if (y2 >= nRows):\n",
        "                y2 = nRows - 1\n",
        "\n",
        "            for j in range(nCols):\n",
        "                x1 = j - s2\n",
        "                x2 = j + s2\n",
        "\n",
        "                if (x1 < 0) :\n",
        "                    x1 = 0\n",
        "                if (x2 >= nCols):\n",
        "                    x2 = nCols - 1\n",
        "                count = (x2 - x1)*(y2 - y1)\n",
        "\n",
        "                sum=s[y2][x2]-s[y2][x1]-s[y1][x2]+s[y1][x1]\n",
        "\n",
        "                if ((int)(inputMat[i][j] * count) < (int)(sum*(1.0 - T))):\n",
        "                    outputMat[i][j] = 255\n",
        "        return outputMat\n",
        "\n",
        "\n",
        "\n",
        "    def local_thresholding(self):\n",
        "        otsu_thresholding(self.img)\n",
        "        ratio=1\n",
        "        roii = cv2.integral(self.img)\n",
        "        thresh = self.thresholdIntegral(self.img, roii)\n",
        "        fig,ax = plt.subplots(1,2,figsize=(20,9))\n",
        "        ax[0].title.set_text(\"Original image\")\n",
        "        ax[0].imshow(self.img,cmap='gray')\n",
        "        ax[0].axis('off')\n",
        "\n",
        "        ax[1].title.set_text(\"Local thresholding\")\n",
        "        ax[1].imshow(thresh,cmap='gray')\n",
        "        ax[1].axis('off')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATdsnYOuS4Bh"
      },
      "source": [
        "<b> Outdoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "Y6jE6aClS4_R",
        "outputId": "f820c88c-9a8b-4f24-98e3-657b62001da0"
      },
      "outputs": [],
      "source": [
        "vt = variable_thresholding(imgs[2])\n",
        "vt.local_thresholding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "v9GgfFUmS6NE",
        "outputId": "6e667209-14ed-4b4c-ea99-793ab1e33b3d"
      },
      "outputs": [],
      "source": [
        "vt2 = variable_thresholding(imgs[9])\n",
        "vt2.local_thresholding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL3QYZXdS7WM"
      },
      "source": [
        "<b> Indoor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IaEo_JQZS8Zq",
        "outputId": "631db2c4-ff83-4b82-e024-aa8727069f53"
      },
      "outputs": [],
      "source": [
        "vt2 = variable_thresholding(left_imgs[9])\n",
        "vt2.local_thresholding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mrE6JOmZS9kp",
        "outputId": "0cf50f4b-bc04-470a-9623-d88a519bedf1"
      },
      "outputs": [],
      "source": [
        "vt2 = variable_thresholding(right_imgs[13])\n",
        "vt2.local_thresholding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vIfa9jQpqLn"
      },
      "source": [
        "<b> Canny Edge Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "rtz6WkQtpubt",
        "outputId": "38258fa2-fd58-40ed-83d6-e6135cf58496"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(left_imgs[3],cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAboZFuPpwWd"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "img = np.uint8(left_imgs[3])\n",
        "blurred = cv2.GaussianBlur(img, (5,5), 0)\n",
        "edge = cv.Canny(img, 50, 150)\n",
        "edge1 = cv.Canny(blurred, 50, 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "tdSCHdccpyYC",
        "outputId": "503c4896-af77-4580-946c-c33af02edd76"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(edge,cmap='gray')\n",
        "#plt.imshow(edge1,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "MOysWFRxpz6G",
        "outputId": "cc2cd043-1f25-4b69-fa1f-3646f87e00a1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "#plt.imshow(edge,cmap='gray')\n",
        "plt.imshow(edge1,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "LTdOJX0vp1-6",
        "outputId": "e0b95987-731f-43b9-8a50-8023b05079a4"
      },
      "outputs": [],
      "source": [
        "kernel = np.array([[0, -1, 0],\n",
        "                   [-1, 5,-1],\n",
        "                   [0, -1, 0]])\n",
        "image_sharp = cv2.filter2D(src=left_imgs[3], ddepth=-1, kernel=kernel)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image_sharp,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "jVhLTsDhp3wm",
        "outputId": "47bda993-4857-4e5d-ebb3-36efc76a071d"
      },
      "outputs": [],
      "source": [
        "image_sharp = np.uint8(left_imgs[3])\n",
        "edge2 = cv.Canny(image_sharp, 50, 150)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(edge2,cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oM8Fl-Bp7KQ"
      },
      "source": [
        "Canny Edge Detector from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIxsFnT8U7UM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYz5fSoTU7UQ"
      },
      "outputs": [],
      "source": [
        "def sHalf(T, sigma):\n",
        "    temp = -np.log(T) * 2 * (sigma ** 2)\n",
        "    return np.round(np.sqrt(temp))\n",
        "\n",
        "def calculate_filter_size(T, sigma):\n",
        "    return 2*sHalf(T, sigma) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vap9BHPTU7UR"
      },
      "outputs": [],
      "source": [
        "def MaskGeneration(T, sigma):\n",
        "    N = calculate_filter_size(T, sigma)\n",
        "    shalf = sHalf(T, sigma)\n",
        "    y, x = np.meshgrid(range(-int(shalf), int(shalf) + 1), range(-int(shalf), int(shalf) + 1))\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjqmifPIU7UR"
      },
      "outputs": [],
      "source": [
        "def Gaussian(x,y, sigma):\n",
        "    temp = ((x ** 2) + (y ** 2)) / (2 * (sigma ** 2))\n",
        "    return (np.exp(-temp))\n",
        "\n",
        "def calculate_gradient_X(x,y, sigma):\n",
        "    temp = (x ** 2 + y ** 2) / (2 * sigma ** 2)\n",
        "    return -((x * np.exp(-temp)) / sigma ** 2)\n",
        "\n",
        "def calculate_gradient_Y(x,y, sigma):\n",
        "    temp = (x ** 2 + y ** 2) / (2 * sigma ** 2)\n",
        "    return -((y * np.exp(-temp)) / sigma ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YST5NnXuU7US"
      },
      "outputs": [],
      "source": [
        "def pad(img, kernel):\n",
        "    r, c = img.shape\n",
        "    kr, kc = kernel.shape\n",
        "    padded = np.zeros((r + kr,c + kc), dtype=img.dtype)\n",
        "    insert = int((kr)//2)\n",
        "    padded[insert: insert + r, insert: insert + c] = img\n",
        "    return padded\n",
        "            \n",
        "def smooth(img, kernel=None):\n",
        "    if kernel is None:\n",
        "        mask = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
        "    else:\n",
        "        mask = kernel\n",
        "    i, j = mask.shape\n",
        "    output = np.zeros((img.shape[0], img.shape[1]))           \n",
        "    image_padded = pad(img, mask)\n",
        "    for x in range(img.shape[0]):    \n",
        "        for y in range(img.shape[1]):\n",
        "            output[x, y] = (mask * image_padded[x:x+i, y:y+j]).sum() / mask.sum()  \n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt3LWKmfU7US"
      },
      "outputs": [],
      "source": [
        "def Create_Gx(fx, fy):\n",
        "    gx = calculate_gradient_X(fx, fy, sigma)\n",
        "    gx = (gx * 255)\n",
        "    return np.around(gx)\n",
        "\n",
        "def Create_Gy(fx, fy):    \n",
        "    gy = calculate_gradient_Y(fx, fy, sigma)\n",
        "    gy = (gy * 255)\n",
        "    return np.around(gy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogEAuuv6U7UT"
      },
      "outputs": [],
      "source": [
        "def ApplyMask(image, kernel):\n",
        "    i, j = kernel.shape\n",
        "    kernel = np.flipud(np.fliplr(kernel))    \n",
        "    output = np.zeros_like(image)           \n",
        "    image_padded = pad(image, kernel)\n",
        "    for x in range(image.shape[0]):    \n",
        "        for y in range(image.shape[1]):\n",
        "            output[x, y] = (kernel * image_padded[x:x+i, y:y+j]).sum()        \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKI_H_Y9U7UT"
      },
      "outputs": [],
      "source": [
        "def Gradient_Magnitude(fx, fy):\n",
        "    mag = np.zeros((fx.shape[0], fx.shape[1]))\n",
        "    mag = np.sqrt((fx ** 2) + (fy ** 2))\n",
        "    mag = mag * 100 / mag.max()\n",
        "    return np.around(mag)\n",
        "\n",
        "def Gradient_Direction(fx, fy):\n",
        "    g_dir = np.zeros((fx.shape[0], fx.shape[1]))\n",
        "    g_dir = np.rad2deg(np.arctan2(fy, fx)) + 180\n",
        "    return g_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlvbn9C-U7UU"
      },
      "outputs": [],
      "source": [
        "def Digitize_angle(Angle):\n",
        "    quantized = np.zeros((Angle.shape[0], Angle.shape[1]))\n",
        "    for i in range(Angle.shape[0]):\n",
        "        for j in range(Angle.shape[1]):\n",
        "            if 0 <= Angle[i, j] <= 22.5 or 157.5 <= Angle[i, j] <= 202.5 or 337.5 < Angle[i, j] < 360:\n",
        "                quantized[i, j] = 0\n",
        "            elif 22.5 <= Angle[i, j] <= 67.5 or 202.5 <= Angle[i, j] <= 247.5:\n",
        "                quantized[i, j] = 1\n",
        "            elif 67.5 <= Angle[i, j] <= 122.5 or 247.5 <= Angle[i, j] <= 292.5:\n",
        "                quantized[i, j] = 2\n",
        "            elif 112.5 <= Angle[i, j] <= 157.5 or 292.5 <= Angle[i, j] <= 337.5:\n",
        "                quantized[i, j] = 3\n",
        "    return quantized\n",
        "    \n",
        "def Non_Max_Supp(qn, magni, D):\n",
        "    M = np.zeros(qn.shape)\n",
        "    a, b = np.shape(qn)\n",
        "    for i in range(a-1):\n",
        "        for j in range(b-1):\n",
        "            if qn[i,j] == 0:\n",
        "                if  magni[i,j-1]< magni[i,j] or magni[i,j] > magni[i,j+1]:\n",
        "                    M[i,j] = D[i,j]\n",
        "                else:\n",
        "                    M[i,j] = 0\n",
        "            if qn[i,j]==1:\n",
        "                if  magni[i-1,j+1]<= magni[i,j] or magni[i,j] >= magni[i+1,j-1]:\n",
        "                    M[i,j] = D[i,j]\n",
        "                else:\n",
        "                    M[i,j] = 0       \n",
        "            if qn[i,j] == 2:\n",
        "                if  magni[i-1,j]<= magni[i,j] or magni[i,j] >= magni[i+1,j]:\n",
        "                    M[i,j] = D[i,j]\n",
        "                else:\n",
        "                    M[i,j] = 0\n",
        "            if qn[i,j] == 3:\n",
        "                if  magni[i-1,j-1]<= magni[i,j] or magni[i,j] >= magni[i+1,j+1]:\n",
        "                    M[i,j] = D[i,j]\n",
        "                else:\n",
        "                    M[i,j] = 0\n",
        "    return M\n",
        "\n",
        "def color(quant, mag):\n",
        "    color = np.zeros((mag.shape[0], mag.shape[1], 3), np.uint8)\n",
        "    a, b = np.shape(mag)\n",
        "    for i in range(a-1):\n",
        "        for j in range(b-1):\n",
        "            if quant[i,j] == 0:\n",
        "                if mag[i,j] != 0:\n",
        "                    color[i,j,0] = 255\n",
        "                else:\n",
        "                    color[i,j,0] = 0\n",
        "            if quant[i,j] == 1:\n",
        "                if mag[i,j] != 0:\n",
        "                    color[i,j,1] = 255\n",
        "                else:\n",
        "                    color[i,j,1] = 0\n",
        "            if quant[i,j] == 2:\n",
        "                if mag[i,j] != 0:\n",
        "                    color[i,j,2] = 255\n",
        "                else:\n",
        "                    color[i,j,2] = 0\n",
        "            if quant[i,j] == 3:\n",
        "                if mag[i,j] != 0:\n",
        "                    color[i,j,0] = 255\n",
        "                    color[i,j,1] = 255\n",
        "                    \n",
        "                else:\n",
        "                    color[i,j,0] = 0\n",
        "                    color[i,j,1] = 0\n",
        "    return color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2JUxPF0U7UV"
      },
      "outputs": [],
      "source": [
        "def _double_thresholding(g_suppressed, low_threshold, high_threshold):\n",
        "    g_thresholded = np.zeros(g_suppressed.shape)\n",
        "    for i in range(0, g_suppressed.shape[0]):\t\t# loop over pixels\n",
        "        for j in range(0, g_suppressed.shape[1]):\n",
        "            if g_suppressed[i,j] < low_threshold:\t# lower than low threshold\n",
        "                g_thresholded[i,j] = 0\n",
        "            elif g_suppressed[i,j] >= low_threshold and g_suppressed[i,j] < high_threshold: \t# between thresholds\n",
        "                g_thresholded[i,j] = 128\n",
        "            else:\t\t\t\t\t        # higher than high threshold\n",
        "                g_thresholded[i,j] = 255\n",
        "    return g_thresholded\n",
        "\n",
        "def _hysteresis(g_thresholded):\n",
        "    g_strong = np.zeros(g_thresholded.shape)\n",
        "    for i in range(0, g_thresholded.shape[0]):\t\t# loop over pixels\n",
        "        for j in range(0, g_thresholded.shape[1]):\n",
        "            val = g_thresholded[i,j]\n",
        "            if val == 128:\t\t\t# check if weak edge connected to strong\n",
        "                if g_thresholded[i-1,j] == 255 or g_thresholded[i+1,j] == 255 or g_thresholded[i-1,j-1] == 255 or g_thresholded[i+1,j-1] == 255 or g_thresholded[i-1,j+1] == 255 or g_thresholded[i+1,j+1] == 255 or g_thresholded[i,j-1] == 255 or g_thresholded[i,j+1] == 255:\n",
        "                    g_strong[i,j] = 255\t\t# replace weak edge as strong\n",
        "            elif val == 255:\n",
        "                g_strong[i,j] = 255\t\t# strong edge remains as strong edge\n",
        "    return g_strong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQES4Lm5U7UV"
      },
      "source": [
        "# Step 1 Specify sigma and T value Also calculate Gradient masks\n",
        "Here you will give the values of sigma and T(0-1). This will create the size of filter automatically. We generate gradient masks in x and y directions i.e. Gx and Gy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPhnBRk9U7UX"
      },
      "outputs": [],
      "source": [
        "sigma = 0.5\n",
        "T = 0.3\n",
        "x, y = MaskGeneration(T, sigma)\n",
        "gauss = Gaussian(x, y, sigma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYP-k52qU7UX"
      },
      "outputs": [],
      "source": [
        "gx = -Create_Gx(x, y)\n",
        "gy = -Create_Gy(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcPwrAbtU7UX"
      },
      "source": [
        "# Step 2 Reading and converting image into grayscale\n",
        "Here we convert the image into grayscale image for easy processing and finding edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5E94x0afBuw",
        "outputId": "b67f37fe-79d5-45df-8dae-4e4f9b8dcf60"
      },
      "outputs": [],
      "source": [
        "right_imgs[8].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mqfpgh5EU7UY",
        "outputId": "9ad778d5-89b2-408d-c7f2-8d3d08770561",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "gray = right_imgs[8]\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(gray, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R49M8XLpU7UY"
      },
      "source": [
        "## Smoothing\n",
        "Here we smooth the image to reduce the intensity in the pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "F4Nq7LnNU7UY",
        "outputId": "62a822cd-a5d9-4804-ecdc-33ab2f521c38",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "smooth_img = smooth(gray,gauss)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(smooth_img, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXqPLy0rU7UZ"
      },
      "source": [
        "# Step 3 Applying the Gradient masks\n",
        "In this step we apply the gradient x and y masks on the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7LgSwkabbOw",
        "outputId": "02a985d9-8c65-4f82-c0c4-3cecc67f3e7d"
      },
      "outputs": [],
      "source": [
        "gx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "B-Y07KOdU7UZ",
        "outputId": "385e5cbd-1425-4a8f-9b4f-1800671cffc6"
      },
      "outputs": [],
      "source": [
        "fx = ApplyMask(smooth_img, gx)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(fx, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Yt6rDf6mU7UZ",
        "outputId": "ce93c1fd-7e80-400e-aa91-fac5fbc2667c"
      },
      "outputs": [],
      "source": [
        "fy = ApplyMask(smooth_img, gy)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(fy, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naeLeQxxU7UZ"
      },
      "source": [
        "# Step 4 Gradient magnitude\n",
        "In this step we calculate the gradient magnitude at every pixel location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "JDi1RWHVU7UZ",
        "outputId": "ec105d97-7722-44ff-c11a-d86eefe845f7"
      },
      "outputs": [],
      "source": [
        "mag = Gradient_Magnitude(fx, fy)\n",
        "mag = mag.astype(int)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(mag, cmap='gray')\n",
        "print('max', mag.max())\n",
        "print('min', mag.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYC80AvtU7Ua"
      },
      "source": [
        "# STEP 5 Gradient Direction\n",
        "In this step we find direction of gradient at each pixel of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "bSAFo_gMU7Ua",
        "outputId": "73306cc0-a205-47b9-cc9b-2d4a812ad621",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "Angle = Gradient_Direction(fx, fy)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(Angle, cmap='gray')\n",
        "print('max', Angle.max())\n",
        "print('min', Angle.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKH46iZoU7Ua"
      },
      "source": [
        "# Step 6 Quantization of angles and Non-Max Suppression\n",
        "In this step we quantize our angles into 4 groups 0, 1, 2, 3. Then we apply non-maximum suppression on it to make the edges thin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ZWfcJRpEU7Ua",
        "outputId": "3c894b9a-8a9c-4dad-c9c6-c5ea4c9f71af"
      },
      "outputs": [],
      "source": [
        "quantized = Digitize_angle(Angle)\n",
        "nms = Non_Max_Supp(quantized, Angle, mag)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(nms, cmap='gray')\n",
        "print('max', nms.max())\n",
        "print('min', nms.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_4eeQcnU7Ua"
      },
      "source": [
        "### Colorized Image for visualiztion of angles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "xOlCesVSU7Ua",
        "outputId": "6731965c-97b7-402a-8a49-09e2b7521a83"
      },
      "outputs": [],
      "source": [
        "colorized = color(quantized, mag)\n",
        "plt.figure(figsize = (7,7))\n",
        "plt.imshow(colorized)\n",
        "cv2.imwrite('color.jpg',colorized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_13XzQJU7Ub"
      },
      "source": [
        "# Step 7 Double Threshold and Hysteresis\n",
        "In this step we apply double threshold Tl and Th to our non-maximum suppressed images. After that we apply Hysteresis algorithm to get resultant edges of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "ye2ZHvwnU7Ub",
        "outputId": "8a1e11e3-2c0c-4c70-9f83-646ddc249006"
      },
      "outputs": [],
      "source": [
        "threshold = _double_thresholding(nms,3,8)\n",
        "cv2.imwrite('double_thresholded.jpg', threshold )\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(threshold, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "vTqs4LvvU7Ub",
        "outputId": "7e987acb-9043-4040-989f-68e4ef3c0dc1"
      },
      "outputs": [],
      "source": [
        "hys = _hysteresis(threshold)\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(hys, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uuD-uukhv-L"
      },
      "source": [
        "### Hough Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "-iSLwLucZSYp",
        "outputId": "27394ac8-53a8-40f9-9d79-c9f688a44cf9"
      },
      "outputs": [],
      "source": [
        "smooth_img = cv2.GaussianBlur(left_imgs[20], (3,3), 0)\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(smooth_img, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "8HS8VBK3b_vc",
        "outputId": "bae613d7-ca7a-4935-d500-a830bd03adce"
      },
      "outputs": [],
      "source": [
        "smooth_img1 = np.uint8(smooth_img)\n",
        "edge2 = cv.Canny(smooth_img1, 50, 150)\n",
        "minLineLength = 10\n",
        "maxLineGap = 10\n",
        "lines = cv2.HoughLinesP(edge2,1,np.pi/180,50,minLineLength,maxLineGap)\n",
        "for line in lines:\n",
        "   for x1,y1,x2,y2 in line:\n",
        "      cv2.line(smooth_img1,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(smooth_img1,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "3cNaWPXue7ot",
        "outputId": "5c2065f2-8afa-43a1-aae6-6fa1d8b2f772"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(edge2,cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUeFVc72mo9M"
      },
      "source": [
        "Hough transform from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "3jR1XXBqmq-e",
        "outputId": "4c8072fc-f9d3-4585-94ac-c59c8ff7894d"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# The Hough Transform is a popular algorithm for detecting any shape that can\n",
        "# be represented in a parametric mathmatical form in binary images. This\n",
        "# usually means that images need to be thresholded or filtered prior to running\n",
        "# the Hough Transform.\n",
        "\n",
        "# read in shapes image and convert to grayscale\n",
        "shapes = left_imgs[20]\n",
        "# blur image (this will help clean up noise for Canny Edge Detection)\n",
        "# see Chapter 2.0 for Guassian Blur or check OpenCV documentation\n",
        "shapes_blurred = cv2.GaussianBlur(shapes,(3,3),0)\n",
        "shapes_blurred1 = np.uint8(shapes_blurred)\n",
        "# find Canny Edges and show resulting image\n",
        "canny_edges = cv2.Canny(shapes_blurred1, 50, 150)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(canny_edges,cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "Nu8q8QPsokQ9",
        "outputId": "97b9b408-7f5d-4d8f-db81-3243b3ba1da6"
      },
      "outputs": [],
      "source": [
        "\n",
        "########################################### HOUGH LINES FROM SCRATCH USING NUMPY\n",
        "# Step 1: The Hough transform needs a binary edges images.  For this particular\n",
        "# python file, I used the openCV built in Class Canny to create this edge image\n",
        "# from the original shapes.png file.\n",
        "\n",
        "# This is the function that will build the Hough Accumulator for the given image\n",
        "def hough_lines_acc(img, rho_resolution=1, theta_resolution=1):\n",
        "    ''' A function for creating a Hough Accumulator for lines in an image. '''\n",
        "    height, width = img.shape # we need heigth and width to calculate the diag\n",
        "    img_diagonal = np.ceil(np.sqrt(height**2 + width**2)) # a**2 + b**2 = c**2\n",
        "    rhos = np.arange(-img_diagonal, img_diagonal + 1, rho_resolution)\n",
        "    thetas = np.deg2rad(np.arange(-90, 90, theta_resolution))\n",
        "\n",
        "    # create the empty Hough Accumulator with dimensions equal to the size of\n",
        "    # rhos and thetas\n",
        "    H = np.zeros((len(rhos), len(thetas)), dtype=np.uint64)\n",
        "    y_idxs, x_idxs = np.nonzero(img) # find all edge (nonzero) pixel indexes\n",
        "\n",
        "    for i in range(len(x_idxs)): # cycle through edge points\n",
        "        x = x_idxs[i]\n",
        "        y = y_idxs[i]\n",
        "\n",
        "        for j in range(len(thetas)): # cycle through thetas and calc rho\n",
        "            rho = int((x * np.cos(thetas[j]) +\n",
        "                       y * np.sin(thetas[j])) + img_diagonal)\n",
        "            H[rho, j] += 1\n",
        "\n",
        "    return H, rhos, thetas\n",
        "\n",
        "\n",
        "# This is a simple peaks function that just finds the indicies of the number\n",
        "# of maximum values equal to num_peaks.  You have to be careful here though, if\n",
        "# there's any noise in the image it will like create a 'pocket' of local maxima\n",
        "# values.  This function ignores this and in turn has the tendancy to return\n",
        "# multiple lines along an actual line in the image.\n",
        "def hough_simple_peaks(H, num_peaks):\n",
        "    ''' A function that returns the number of indicies = num_peaks of the\n",
        "        accumulator array H that correspond to local maxima. '''\n",
        "    indices =  np.argpartition(H.flatten(), -2)[-num_peaks:]\n",
        "    return np.vstack(np.unravel_index(indices, H.shape)).T\n",
        "\n",
        "\n",
        "# This more advance Hough peaks funciton has threshold and nhood_size arguments\n",
        "# threshold will threshold the peak values to be above this value if supplied,\n",
        "# where as nhood_size will surpress the surrounding pixels centered around\n",
        "# the local maximum after that value has been assigned as a peak.  This will\n",
        "# force the algorithm to look eslwhere after it's already selected a point from\n",
        "# a 'pocket' of local maxima.\n",
        "def hough_peaks(H, num_peaks, threshold=0, nhood_size=3):\n",
        "    ''' A function that returns the indicies of the accumulator array H that\n",
        "        correspond to a local maxima.  If threshold is active all values less\n",
        "        than this value will be ignored, if neighborhood_size is greater than\n",
        "        (1, 1) this number of indicies around the maximum will be surpessed. '''\n",
        "    # loop through number of peaks to identify\n",
        "    indicies = []\n",
        "    H1 = np.copy(H)\n",
        "    for i in range(num_peaks):\n",
        "        idx = np.argmax(H1) # find argmax in flattened array\n",
        "        H1_idx = np.unravel_index(idx, H1.shape) # remap to shape of H\n",
        "        indicies.append(H1_idx)\n",
        "\n",
        "        # surpess indicies in neighborhood\n",
        "        idx_y, idx_x = H1_idx # first separate x, y indexes from argmax(H)\n",
        "        # if idx_x is too close to the edges choose appropriate values\n",
        "        if (idx_x - (nhood_size/2)) < 0: \n",
        "          min_x = 0\n",
        "        else: \n",
        "          min_x = int(idx_x - (nhood_size/2))\n",
        "        if ((idx_x + (nhood_size/2) + 1) > H.shape[1]): \n",
        "          max_x = H.shape[1]\n",
        "        else: \n",
        "          max_x = int(idx_x + (nhood_size/2) + 1)\n",
        "\n",
        "        # if idx_y is too close to the edges choose appropriate values\n",
        "        if (idx_y - (nhood_size/2)) < 0: \n",
        "          min_y = 0\n",
        "        else: \n",
        "          min_y = int(idx_y - (nhood_size/2))\n",
        "        if ((idx_y + (nhood_size/2) + 1) > H.shape[0]): \n",
        "          max_y = H.shape[0]\n",
        "        else: \n",
        "          max_y = int(idx_y + (nhood_size/2) + 1)\n",
        "\n",
        "        # bound each index by the neighborhood size and set all values to 0\n",
        "        for x in range(min_x, max_x):\n",
        "            for y in range(min_y, max_y):\n",
        "                # remove neighborhoods in H1\n",
        "                H1[y, x] = 0\n",
        "\n",
        "                # highlight peaks in original H\n",
        "                if (x == min_x or x == (max_x - 1)):\n",
        "                    H[y, x] = 255\n",
        "                if (y == min_y or y == (max_y - 1)):\n",
        "                    H[y, x] = 255\n",
        "\n",
        "    # return the indicies and the original Hough space with selected points\n",
        "    return indicies, H\n",
        "\n",
        "# drawing the lines from the Hough Accumulatorlines using OpevCV cv2.line\n",
        "def hough_lines_draw(img, indicies, rhos, thetas):\n",
        "    ''' A function that takes indicies a rhos table and thetas table and draws\n",
        "        lines on the input images that correspond to these values. '''\n",
        "    for i in range(len(indicies)):\n",
        "        # reverse engineer lines from rhos and thetas\n",
        "        rho = rhos[indicies[i][0]]\n",
        "        theta = thetas[indicies[i][1]]\n",
        "        a = np.cos(theta)\n",
        "        b = np.sin(theta)\n",
        "        x0 = a*rho\n",
        "        y0 = b*rho\n",
        "        # these are then scaled so that the lines go off the edges of the image\n",
        "        x1 = int(x0 + 1000*(-b))\n",
        "        y1 = int(y0 + 1000*(a))\n",
        "        x2 = int(x0 - 1000*(-b))\n",
        "        y2 = int(y0 - 1000*(a))\n",
        "\n",
        "        cv2.line(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "\n",
        "# run hough_lines_accumulator on the shapes canny_edges image\n",
        "H, rhos, thetas = hough_lines_acc(canny_edges)\n",
        "indicies, H = hough_peaks(H, 3, nhood_size=11) # find peaks\n",
        "hough_lines_draw(shapes, indicies, rhos, thetas)\n",
        "plt.figure(figsize=(10,10))\n",
        "# Show image with manual Hough Transform Lines\n",
        "plt.imshow(shapes,cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxKi2s9JA64Z"
      },
      "source": [
        "### Sobel and Prewitt edge detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "yzKtRra4SGcX",
        "outputId": "5c8923b3-cdf5-4a90-d2de-1b306c1bb834"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "gray = right_imgs[20]\n",
        "img_gaussian = np.uint8(cv2.GaussianBlur(gray,(3,3),0))\n",
        "\n",
        "#canny\n",
        "img_canny = cv2.Canny(img_gaussian,50,150)\n",
        "\n",
        "#sobel\n",
        "img_sobely = cv2.Sobel(img_gaussian,cv2.CV_8U,1,0,ksize=5)\n",
        "img_sobelx = cv2.Sobel(img_gaussian,cv2.CV_8U,0,1,ksize=5)\n",
        "img_sobel = img_sobelx + img_sobely\n",
        "\n",
        "\n",
        "#prewitt\n",
        "kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
        "kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "img_prewittx = cv2.filter2D(img_gaussian, -1, kernelx)\n",
        "img_prewitty = cv2.filter2D(img_gaussian, -1, kernely)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(2, 4,figsize=(20,8))\n",
        "\n",
        "ax[0, 0].imshow(gray,cmap='gray')\n",
        "ax[0,0].title.set_text('Original image')\n",
        "ax[0,0].axis('off')\n",
        "ax[1, 0].imshow(img_canny,cmap='gray')\n",
        "ax[1, 0].title.set_text('Canny Edge Detector')\n",
        "ax[1, 0].axis('off')\n",
        "ax[0, 1].imshow(img_sobelx,cmap='gray')\n",
        "ax[0, 1].title.set_text('Sobel - X')\n",
        "ax[0, 1].axis('off')\n",
        "ax[1, 1].imshow(img_prewittx,cmap='gray')\n",
        "ax[1, 1].title.set_text('Prewitt - X')\n",
        "ax[1, 1].axis('off')\n",
        "ax[0,2].imshow(img_sobely,cmap='gray')\n",
        "ax[0,2].title.set_text('Sobel - Y')\n",
        "ax[0,2].axis('off')\n",
        "ax[1,2].imshow(img_prewitty,cmap='gray')\n",
        "ax[1,2].title.set_text('Prewitt - Y')\n",
        "ax[1,2].axis('off')\n",
        "ax[0,3].imshow(img_sobel,cmap='gray')\n",
        "ax[0,3].title.set_text('Final Sobel')\n",
        "ax[0,3].axis('off')\n",
        "ax[1,3].imshow(img_prewittx + img_prewitty,cmap='gray')\n",
        "ax[1,3].title.set_text('Final Prewitt')\n",
        "ax[1,3].axis('off')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s03XLrfaTR9"
      },
      "source": [
        "### Contour detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "F47amcXPWspl",
        "outputId": "c51e216b-7e83-4511-b86d-06986ab9f79b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "image = left_imgs[10]\n",
        "blurred = np.uint8(cv2.GaussianBlur(image, (5, 5), 0))\n",
        "edged = cv2.Canny(blurred, 50, 150)\n",
        "fig,ax = plt.subplots(1,2,figsize=(20,10))\n",
        "ax[0].imshow(image,cmap='gray')\n",
        "ax[0].title.set_text(\"Original image\")\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(edged,cmap='gray')\n",
        "ax[1].title.set_text(\"Edged Image\")\n",
        "ax[1].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "EFd0QezrcEnQ",
        "outputId": "3b6cb788-6907-4418-a590-b2aa3bd0749b"
      },
      "outputs": [],
      "source": [
        "# find the contours in the edged image\n",
        "contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "image_copy = image.copy()\n",
        "# draw the contours on a copy of the original image\n",
        "cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 2)\n",
        "print(len(contours), \"objects were found in this image.\")\n",
        "fig,ax = plt.subplots(1,2,figsize=(20,10))\n",
        "ax[0].imshow(edged,cmap='gray')\n",
        "ax[0].title.set_text(\"Edged image\")\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(image_copy,cmap='gray')\n",
        "ax[1].title.set_text(\"Contours\")\n",
        "ax[1].axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "0MXk85sZclLG",
        "outputId": "ece90fe2-b6d0-490f-9f05-8d93f266dd7f"
      },
      "outputs": [],
      "source": [
        "# define a (3, 3) structuring element\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "\n",
        "# apply the dilation operation to the edged image\n",
        "dilate = cv2.dilate(edged, kernel, iterations=1)\n",
        "\n",
        "# find the contours in the dilated image\n",
        "contours, _ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "image_copy = image.copy()\n",
        "# draw the contours on a copy of the original image\n",
        "cv2.drawContours(image_copy, contours, -1, (0, 255, 0), 2)\n",
        "print(len(contours), \"objects were found in this image.\")\n",
        "fig,ax = plt.subplots(1,2,figsize=(20,10))\n",
        "ax[0].imshow(dilate,cmap='gray')\n",
        "ax[0].title.set_text(\"Dilated image\")\n",
        "ax[0].axis('off')\n",
        "ax[1].imshow(image_copy,cmap='gray')\n",
        "ax[1].title.set_text(\"Contours\")\n",
        "ax[1].axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxfkowhJHTo_"
      },
      "source": [
        "<b> Marr Hildreth Edge Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9UKQufdHWeG",
        "outputId": "80e11ed5-1a25-4cf6-b7d8-458cf5d95e5d"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2 as cv\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def edgesMarrHildreth(img, sigma):\n",
        "    \"\"\"\n",
        "            finds the edges using MarrHildreth edge detection method...\n",
        "            :param im : input image\n",
        "            :param sigma : sigma is the std-deviation and refers to the spread of gaussian\n",
        "            :return:\n",
        "            a binary edge image...\n",
        "    \"\"\"\n",
        "    size = int(2*(np.ceil(3*sigma))+1)\n",
        "\n",
        "    x, y = np.meshgrid(np.arange(-size/2+1, size/2+1),\n",
        "                       np.arange(-size/2+1, size/2+1))\n",
        "\n",
        "    normal = 1 / (2.0 * np.pi * sigma**2)\n",
        "\n",
        "    kernel = ((x**2 + y**2 - (2.0*sigma**2)) / sigma**4) * \\\n",
        "        np.exp(-(x**2+y**2) / (2.0*sigma**2)) / normal  # LoG filter\n",
        "\n",
        "    kern_size = kernel.shape[0]\n",
        "    log = np.zeros_like(img, dtype=float)\n",
        "\n",
        "    # applying filter\n",
        "    for i in range(img.shape[0]-(kern_size-1)):\n",
        "        for j in range(img.shape[1]-(kern_size-1)):\n",
        "            window = img[i:i+kern_size, j:j+kern_size] * kernel\n",
        "            log[i, j] = np.sum(window)\n",
        "\n",
        "    log = log.astype(np.int64, copy=False)\n",
        "\n",
        "    zero_crossing = np.zeros_like(log)\n",
        "\n",
        "    # computing zero crossing\n",
        "    for i in range(log.shape[0]-(kern_size-1)):\n",
        "        for j in range(log.shape[1]-(kern_size-1)):\n",
        "            if log[i][j] == 0:\n",
        "                if (log[i][j-1] < 0 and log[i][j+1] > 0) or (log[i][j-1] < 0 and log[i][j+1] < 0) or (log[i-1][j] < 0 and log[i+1][j] > 0) or (log[i-1][j] > 0 and log[i+1][j] < 0):\n",
        "                    zero_crossing[i][j] = 255\n",
        "            if log[i][j] < 0:\n",
        "                if (log[i][j-1] > 0) or (log[i][j+1] > 0) or (log[i-1][j] > 0) or (log[i+1][j] > 0):\n",
        "                    zero_crossing[i][j] = 255\n",
        "\n",
        "    # plotting images\n",
        "    # fig = plt.figure()\n",
        "    # a = fig.add_subplot(1, 2, 1)\n",
        "    # imgplot = plt.imshow(log, cmap='gray')\n",
        "    # a.set_title('Laplacian of Gaussian')\n",
        "    # a = fig.add_subplot(1, 2, 2)\n",
        "    # imgplot = plt.imshow(zero_crossing, cmap='gray')\n",
        "    # string = 'Zero Crossing sigma = '\n",
        "    # string += (str(sigma))\n",
        "    # a.set_title(string)\n",
        "    # plt.show()\n",
        "\n",
        "    return log, zero_crossing\n",
        "\n",
        "\n",
        "def main():\n",
        "    # oparser = argparse.ArgumentParser(description=\"Marr-Hildreth Edge detector\")\n",
        "    # oparser.add_argument(\"--input\", dest=\"input_image\", required=True,\n",
        "    #                      help=\"Path containing the image\")\n",
        "    # oparser.add_argument(\"--output\", dest=\"output_image\", required=True,\n",
        "    #                      help=\"Path containing the image\")\n",
        "    # oparser.add_argument(\"--sigma\", dest=\"sigma\", default=3, required=False,\n",
        "    #                      help=\"Sigma threshold\", type=int)\n",
        "    # options = oparser.parse_args()\n",
        "\n",
        "    # img = io.imread(options.input_image)\n",
        "    # img = color.rgb2gray(img)\n",
        "\n",
        "    # log, zero_crossing = edgesMarrHildreth(img, options.sigma)\n",
        "\n",
        "    # io.imsave(f'{options.output_image}_{options.sigma}_log.jpg', log)\n",
        "    # io.imsave(f'{options.output_image}_{options.sigma}_zero_crossing.jpg', zero_crossing)\n",
        "    while(1):\n",
        "      imgs=left_imgs[0]\n",
        "      log,zero_crossing=edgesMarrHildreth(imgs, 3)\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.title('Input Image')\n",
        "      plt.imshow(imgs, cmap='gray')\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.title('Laplacian of Gaussian')\n",
        "      plt.imshow(log, cmap='gray')\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.title('Marr Hildreth with zero crossing')\n",
        "      plt.imshow(zero_crossing, cmap='gray')\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "      return 0\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbDjZFGZHcpg"
      },
      "source": [
        "<b> Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p-QHd-AtHeJo",
        "outputId": "9f9ef148-1e88-4730-a5d3-abbce4273ddd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "\n",
        "def clust_gray(image,k=5,iters=3): # expects img in grayscale\n",
        "    # image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    img=image.copy()\n",
        "    h,w=img.shape\n",
        "    orig=image.copy()\n",
        "    Klusters=np.random.randint(0,255,size=k)\n",
        "    print('init clusters', Klusters)\n",
        "    for it in range(iters):\n",
        "        img=image.copy()\n",
        "        for i in range(h):\n",
        "            for j in range(w):\n",
        "                pnt=img[i][j]\n",
        "                diff=np.abs(Klusters-pnt)\n",
        "                c=np.argmin(diff)\n",
        "                img[i][j]=Klusters[c]\n",
        "        loss=0\n",
        "        l=[]\n",
        "        for i in range(k):\n",
        "            Ys,Xs=np.where(img==Klusters[i])\n",
        "            kth_points=orig[Ys,Xs]\n",
        "            l.append(np.sum(Klusters[i]-kth_points))\n",
        "            Klusters[i]=np.mean(kth_points)\n",
        "        loss=sum(l)    \n",
        "        print('Cluster centroids at iteration-{}'.format(it+1), Klusters)\n",
        "        print('loss at iteration-{}'.format(it+1),loss)\n",
        "    return img\n",
        "if __name__ == '__main__':\n",
        "  im = left_imgs[0]\n",
        "  clusters=clust_gray(im,k=3)\n",
        "  cv2_imshow(im)\n",
        "  cv2_imshow(clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_0LCHBigpkZ"
      },
      "source": [
        "<b> Water Shed Segmentation </b>\n",
        "\n",
        "In geographical sense : An array where water accumulates. It is a land area that channels / drains rain and snow to \n",
        "creeks, streams, etc. Watershed can be segmented as topographical maps with boundaries (more lowers the altitude of the land, more water it accumulates). I.E, the gray scale images can be considered to have valleys and peaks, based on the intensity. There is also a threshold that seggregates between the two. The brightness determines the high (peak) and low (valley) in this algorithm.\n",
        "\n",
        "It works by filling values (i.e local minima), with pixels belonging to the same predefined label. High intensity denotes peaks and hills, while low intensity denotes valley. We fill every local isloated minima and mark it as a different segment. We also create a boundary / barrier between two isolated valleys.\n",
        "\n",
        "The algorithm is useful for segmenting images into background and forground for certain images where other algorithms fail, for example when the forground has several objects of same / similar intensity, other algorithms will determine that all said objects will be merged to one, while the watershed algorithm prevents this.\n",
        "\n",
        "However, it fails when RGB image is used (primarily because if objects are not clearly differentiable when we do the thresholding of image). Also, noise can heavily corrupt / bias the result, for which denoising is required as a preprocessing step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ0Z2o4TLEzw"
      },
      "source": [
        "Main use case of this algorithm : Segment individual objects when heavily clustered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4sejm-YLS5c"
      },
      "source": [
        "![](https://miro.medium.com/max/828/1*uuk-mzJygthxB6krOObZyw.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3wUggAELBXc"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaIa5VNwhXOZ",
        "outputId": "4d62b206-9029-4939-a8c7-e45aa401bd1c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Shankar0x/DepthSensingDatasets.git images\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEu7pTWXgpkb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rcltIcHhf5D"
      },
      "outputs": [],
      "source": [
        "path = 'images/DrivingStereo_dataset/004.jpg'\n",
        "image = cv2.imread(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "DyyIyqh8gpkc",
        "outputId": "b201cb1c-1d6f-4da3-d7ed-cf458c1d8fa8"
      },
      "outputs": [],
      "source": [
        "color_image = image.copy()\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print('source image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN3lGJH6gpkd"
      },
      "source": [
        "Performing threshold based segmentation\n",
        "\n",
        "The black regions can be considered as 'surely' background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPTwDazrLmTc"
      },
      "outputs": [],
      "source": [
        "def threshold(image, t, inv=False):\n",
        "  m, n = image.shape\n",
        "  result = np.zeros((m, n))\n",
        "  print(m, n)\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      #print(image[i,j,0])\n",
        "      if image[i, j] > t:\n",
        "        if inv:\n",
        "          result[i, j] = 0\n",
        "        else:\n",
        "          result[i, j] = 255\n",
        "      else:\n",
        "          if inv:\n",
        "            result[i, j] = 255\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "50l0_bxygpkd",
        "outputId": "3753159c-dd7a-4155-af8e-6b48f5a52206"
      },
      "outputs": [],
      "source": [
        "threshold_image = threshold(image, 120, True)\n",
        "\n",
        "print('source image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('threshold segmented image [SURE BACKGROUND]')\n",
        "plt.imshow(threshold_image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AaefZT8ON6r"
      },
      "source": [
        "Sure Background : Result obtained from thresholding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJJ1hP3gpkd"
      },
      "source": [
        "Noise Removal using morphological opening, and dilation to make pixels around boundaries thinner (to now surely what is background), and to also remove small holes within an object.\n",
        "\n",
        "Then, use dilation to increase object boundaries. This way we can be sure of what is *definitely* the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ZUhZaK1egpkd",
        "outputId": "73d00d02-6064-44fc-ae0b-b629ca7da810"
      },
      "outputs": [],
      "source": [
        "threshold_image = cv2.threshold(image, 120, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "opening = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=1)\n",
        "print('mophological opening')\n",
        "plt.imshow(opening, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "dilation = cv2.dilate(opening, np.ones((3, 3), dtype=np.uint8), iterations=2)\n",
        "print('dilation')\n",
        "plt.imshow(dilation, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9W993n2OiP-"
      },
      "source": [
        "Sure Foreground"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiG1sNjHgpke"
      },
      "source": [
        "Distance Transform : As pixels get further away from a bunch of 0's, the intensity increnases. Essentially, the edges are darker, while the center of object is bright.\n",
        "\n",
        "This is used as small objects tend to get washed away while performing erosion. Can be seen as an alternative to using erosion to determine what componenets are ****'surely' forground**** in this case.\n",
        "\n",
        "The distance indicates the minimum distance to the closes background (to the region of 0's in the thresholded image).\n",
        "\n",
        "Unknown region is just the difference between surely foreground and surely background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPQxlu9fObXe"
      },
      "source": [
        "![](https://miro.medium.com/max/786/1*N2souynjEJN6jk9GszwRaA.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECGECLLmSeer"
      },
      "source": [
        "Relevant Research Paper on Distance Transform with implementation: https://cs.brown.edu/people/pfelzens/papers/dt-final.pdf\n",
        "\n",
        "![](![image.png](data:image/png;base64,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))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhqPmYWfQ46E"
      },
      "outputs": [],
      "source": [
        "# Distance transform for a 1-dimensional vector using city block distance\n",
        "def distance_transform_1d(v, n, inf=1e20):\n",
        "    f = v\n",
        "    d = np.zeros(n, dtype=np.float64)\n",
        "    v = np.zeros(n, dtype=int)\n",
        "    z = np.zeros(n+1, dtype=np.float64)\n",
        "    \n",
        "    # Locations of boundaries between parabolas\n",
        "    z[0] = -inf\n",
        "    z[1] = inf\n",
        "    \n",
        "    k = 0       # Index of rightmost parabola in lower envelope\n",
        "    for q in range(n)[1:]:\n",
        "        s = ((f[q]+ q*q) - (f[v[k]] + v[k]*v[k]))/(2*q-2*v[k])\n",
        "        while s<= z[k]:\n",
        "            k -= 1\n",
        "            s  = ((f[q]+q*q)-(f[v[k]]+v[k]*v[k]))/(2*q-2*v[k])\n",
        "        k +=1\n",
        "        v[k] = q\n",
        "        z[k] = s\n",
        "        z[k+1] = inf\n",
        "\n",
        "    k=0\n",
        "    for q in range(n):\n",
        "        while (z[k+1] < q):\n",
        "            k +=1\n",
        "        d[q] = (q-v[k])*(q-v[k]) + f[v[k]]\n",
        "    \n",
        "    return d\n",
        "\n",
        "# Distance transform for a 2D image using city block distance\n",
        "def dt_img(image):\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    # Columns\n",
        "    for x in range(width):\n",
        "        f = image[:,x]\n",
        "        image[:,x] = distance_transform_1d(f, height)\n",
        "    # Rows\n",
        "    for y in range(height):\n",
        "        f = image[y,:]\n",
        "        d = distance_transform_1d(f, width)\n",
        "        image[y,:] = d\n",
        "    return image\n",
        "\n",
        "# Distance transform for 2D binary image\n",
        "def distance_transform_binary(image, inf=1e20, on=0):\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    out = np.ones([height, width], dtype=np.float64)*inf # Multiply by infinity \n",
        "    out[image==on]=0\n",
        "    out = dt_img(out)\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "R4EdrsEOR6Q-",
        "outputId": "17da400f-9bb3-4ec2-b7f3-9dd20ae7d323"
      },
      "outputs": [],
      "source": [
        "plt.imshow(distance_transform_binary(dilation.copy()), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "um44ndQEgpke",
        "outputId": "45b1dcbb-5579-4ca2-dc2a-9477bc5d1f6d"
      },
      "outputs": [],
      "source": [
        "dilation = cv2.dilate(opening, np.ones((3, 3), dtype=np.uint8), iterations=2)\n",
        "dist_transform = cv2.distanceTransform(dilation, cv2.DIST_L2, 5)\n",
        "forground = cv2.threshold(dist_transform, 0.2*dist_transform.max(), 255, 0)[1]\n",
        "print('Distance transform')\n",
        "plt.imshow(dist_transform, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('forground points (sure)')\n",
        "plt.imshow(forground, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Not sure if forground or background\n",
        "print('unknown')\n",
        "unknown_region = cv2.subtract(dilation, np.uint8(forground))\n",
        "plt.imshow(unknown_region, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl_Id8_Bgpke"
      },
      "source": [
        "Find connected componenets and get markers for each connected component"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "8Z-51haPgpkf",
        "outputId": "eb2ee58e-286a-488d-d7fb-32aa2544d2e5"
      },
      "outputs": [],
      "source": [
        "markers = cv2.connectedComponents(np.uint8(forground))[1]\n",
        "\n",
        "# Plus one so background is not 0, but 1\n",
        "markers=markers+1\n",
        "\n",
        "# Mark unknown region (not sure if forground or background) with 0's\n",
        "markers[unknown_region==255] = 0\n",
        "\n",
        "print('markers')\n",
        "plt.imshow(markers, cmap='jet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ATMz6jgpkf"
      },
      "source": [
        "Using the final watershed algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "_MlfPFkVgpkf",
        "outputId": "61161356-6fb6-4db2-8dc8-7205b47d3e23"
      },
      "outputs": [],
      "source": [
        "watershed_res = cv2.watershed(color_image, markers)\n",
        "\n",
        "# Make boundaries (marked with -1 as background)\n",
        "color_image_marked = color_image.copy()\n",
        "\n",
        "color_image_marked[markers==-1] = [255, 0, 0]\n",
        "\n",
        "print('markers')\n",
        "plt.imshow(markers)\n",
        "plt.show()\n",
        "\n",
        "print('watershed res')\n",
        "plt.imshow(color_image_marked)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2LOyaTbyL"
      },
      "source": [
        "Scenarios where Water Shed Segmentation is Useful ð°\n",
        "\n",
        "<Foreground is clearly distinct from background, with excessive clustering and no overlapping of foreground and bckground> \n",
        "\n",
        "![](https://docs.opencv.org/3.4/water_coins.jpg)\n",
        "![](https://docs.opencv.org/3.4/water_result.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hER8Bbwp6qUH"
      },
      "source": [
        "Morphological Gradient Operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrsK9IjI6wBn"
      },
      "source": [
        "A simple morphological image processing technique used to find the borders / outline of images.\n",
        "\n",
        "Consist of two steps : \n",
        "\n",
        "(i) Perform erosion to shrink the image based on structuring element. \\\n",
        "(ii)  Subtract eroded image from the dilated  image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "ND9rBx_n60lh",
        "outputId": "0f48aa6d-ffdf-4beb-b976-339f398a7cd1"
      },
      "outputs": [],
      "source": [
        "print('original image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "eroded = cv2.erode(image, np.ones((3,3), dtype=np.uint8))\n",
        "dilate = cv2.dilate(image, np.ones((3,3), dtype=np.uint8))\n",
        "\n",
        "print('eroded image')\n",
        "plt.imshow(eroded, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('dilate image')\n",
        "plt.imshow(dilate, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('gradient res')\n",
        "plt.imshow(dilate-eroded, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKDiVrBD9sFV"
      },
      "source": [
        "Morphological Top Hat Operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z6zRoZQ9vqI"
      },
      "source": [
        "A simple morphological image processing technique used to extract the small and fine details from an image.\n",
        "\n",
        "It consist of two steps : \n",
        "\n",
        "(i) Obtain the 'opening' of the image. \\\n",
        "(ii) Subtract the opening of image from the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "BkN1WZzg9zXG",
        "outputId": "11a30089-e684-43ef-f4b1-fa832fb36596"
      },
      "outputs": [],
      "source": [
        "print('original image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "eroded = cv2.erode(image, np.ones((3,3), dtype=np.uint8))\n",
        "opening = cv2.dilate(eroded, np.ones((3,3), dtype=np.uint8))\n",
        "\n",
        "print('eroded image')\n",
        "plt.imshow(eroded, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('image opening')\n",
        "plt.imshow(opening, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('top hat res')\n",
        "plt.imshow(image-opening, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1JtKJA6SSUM"
      },
      "source": [
        "<b> Color Spaces Segmentation </b>\n",
        "\n",
        "Given an RGB image, we first convert the color space to HSV (Hue Saturation Value). The reason for this is : \n",
        "\n",
        "(i) Hue : Gives only color information (based on degrees, where red falls between 0 to 60, yellow falls between 61 to 120, etc).\n",
        "\n",
        "(ii) Value : The darkness / brightness of the color.\n",
        "\n",
        "(iii) Saturation : The amount of gray in the image. If this value is 0%, it produces a faded effect and produces more white. On the other hand, if the value is 100%, we get the primary color itself.\n",
        "\n",
        "If we are able to retrieve the Hue value alone from a given HSV image, we can segment the objects based on just the color information, disregarding the shade / brightness of the *same* color present in several objects over the scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "HAstNqXQSWQE",
        "outputId": "2138b2c7-c30c-4dfa-ddb6-cda0aa06294e"
      },
      "outputs": [],
      "source": [
        "image = color_image.copy()\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "print('RGB image')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "print('HSV image')\n",
        "plt.imshow(hsv_image, cmap='hsv')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGmTR57UUtQW"
      },
      "outputs": [],
      "source": [
        "def in_range(image, lower_hsv, upper_hsv):\n",
        "  result = np.zeros(image.shape[0:2], dtype=np.uint8)\n",
        "\n",
        "  for i in range(image.shape[0]):\n",
        "    for j in range(image.shape[1]):\n",
        "      if ((image[i,j,0] >= lower_hsv[0] and image[i, j, 0] <= upper_hsv[0]) and (image[i,j,1] >= lower_hsv[1] and image[i, j, 1] <= upper_hsv[1]) and (image[i,j,2] >= lower_hsv[2] and image[i, j, 2] <= upper_hsv[2])):\n",
        "        result[i, j] = 255\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7jqyK-4uSfBW",
        "outputId": "c4a8c0dd-53d7-4355-c5e5-6ae96c570172"
      },
      "outputs": [],
      "source": [
        "upper_saturation = 255\n",
        "upper_value = 255\n",
        "\n",
        "lower_saturation = 0\n",
        "lower_value = 0\n",
        "\n",
        "ranges_names = ['red', 'orange', 'yellow', 'green', 'green - light blue / cyan', 'dark blue', 'purple', 'red']\n",
        "\n",
        "hue_ranges =   [[0,10],[10,21],[21,35],    [35,72],  [72,90],      [90,130],   [140,170], [170,180]]\n",
        "\n",
        "for i in range(len(hue_ranges)):\n",
        "    lower_hue = hue_ranges[i][0]\n",
        "    upper_hue = hue_ranges[i][1]\n",
        "    \n",
        "    # Color range in HSV color space\n",
        "    upper_hsv = np.array([upper_hue, upper_saturation, upper_value])\n",
        "    lower_hsv = np.array([lower_hue, lower_saturation, lower_value])\n",
        "\n",
        "    mask = in_range(hsv_image, lower_hsv, upper_hsv)\n",
        "    hsv_segmentation_res = cv2.bitwise_and(hsv_image, hsv_image, mask=mask)\n",
        "    hsv_segmentation_blurred = cv2.blur(hsv_segmentation_res, (3,3))\n",
        "\n",
        "    print(ranges_names[i], '\\n', 'mask -> hsv res blurred -> original image')\n",
        "\n",
        "    plt.figure(figsize=(100,100))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(cv2.cvtColor(hsv_segmentation_blurred, cv2.COLOR_HSV2RGB), cmap='hsv')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9rentHiZteF"
      },
      "source": [
        "For verification, performing HSV segmentation using a HSV color map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qsqa8uCEZxj7",
        "outputId": "cb91e54d-7c37-4c57-d38f-c1a854ab78e4"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('images/Infographics/hsv_colormap.png')\n",
        "print(image)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "print('source image')\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7stxGqH5Z4NO",
        "outputId": "fd41743e-c917-451b-9c17-16a99d5ab431"
      },
      "outputs": [],
      "source": [
        "upper_saturation = 255\n",
        "upper_value = 255\n",
        "\n",
        "lower_saturation = 0\n",
        "lower_value = 0\n",
        "\n",
        "ranges_names = ['red', 'orange', 'yellow', 'green', 'green - light blue / cyan', 'dark blue', 'purple', 'red']\n",
        "\n",
        "hue_ranges =   [[0,10],[10,21],[21,35],    [35,72],  [72,90],      [90,130],   [140,170], [170,180]]\n",
        "\n",
        "for i in range(len(hue_ranges)):\n",
        "    lower_hue = hue_ranges[i][0]\n",
        "    upper_hue = hue_ranges[i][1]\n",
        "    \n",
        "    # Color range in HSV color space\n",
        "    upper_hsv = np.array([upper_hue, upper_saturation, upper_value])\n",
        "    lower_hsv = np.array([lower_hue, lower_saturation, lower_value])\n",
        "\n",
        "    mask = in_range(hsv_image, lower_hsv, upper_hsv)\n",
        "    hsv_segmentation_res = cv2.bitwise_and(hsv_image, hsv_image, mask=mask)\n",
        "    hsv_segmentation_blurred = cv2.blur(hsv_segmentation_res, (3,3))\n",
        "\n",
        "    print(ranges_names[i], '\\n', 'mask -> hsv res blurred -> original image')\n",
        "\n",
        "    plt.figure(figsize=(100,100))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(1,4,2)\n",
        "    plt.imshow(cv2.cvtColor(hsv_segmentation_blurred, cv2.COLOR_HSV2RGB), cmap='hsv')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NXyVPZ0a5P2"
      },
      "source": [
        "Depth / Disparity Map Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9pN4uyga8N-"
      },
      "source": [
        "When we take a photo on a camera, we 'convert' the scene's world coordinate, into the view / camera coordinate frame, where the camera is at the center, looking down on either the +z or -z axis. Then, we apply the projection matrix and perspective divide to go from the view space onto pixel space.\n",
        "\n",
        "Our goal is the estimate the relative objects in the image, given camera calibaration parameters and a pair of stereo (i.e left and right images).\n",
        "Essentially, we try to estimate the world coordinates of different pixels in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkLzr11va9lf"
      },
      "source": [
        "**Stereo Vision System** : It consist of two cameras located at a known distance from each other, at the time the pictures of the scene are taken. Often, they have a difference in thier horizontal displacement, which is the basis for depth estimation. We need to calibrate the cameras so as to accurately determine the correspondence between pixels in the left and right stereo images. This often involved a template / pattern matching algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "F1KOjYbva-5L",
        "outputId": "12ddc2c2-a7d0-4799-d593-aa893c4b9d6d"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cv2.imread('images/Infographics/disparity_exp.png'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y9OSTEqbBtu"
      },
      "source": [
        "**Camera Calibration and Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouuVhkB4bDJF"
      },
      "source": [
        "View matrix : Defined using the position and orientation of the camera with respect to the world coordinate frame. The view matrix translates and rotates the scene such that the camera is placed at the origin of the view space, looking down at the z axis (+ve or -ve)\n",
        "\n",
        "**This is referred to the external parameters of the camera**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZFpo10sbEms"
      },
      "source": [
        "Projection Matrix : Maps point from the view space to the projection plane, where the distance between the camera's optical center and the projection / imaging plance is the focal length of the camera, *f*. **These are referred to as internal paramters of camera (such as focal length)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsi8GyHdbFuF"
      },
      "source": [
        "Suppose we had a point in the view space, V(xv, yv, zv) and its corresponding point in the image plane, IP(x, y). The relationship between both are given by : \n",
        "\n",
        "x = *f* * xv / zv\n",
        "\n",
        "y = *f* * yv / zv\n",
        "\n",
        "However, the image sensor has pixels, and the image place's pixel need not have a 1-1 relation with the image sensor pixels.\n",
        "\n",
        "We can approximate image pixels and the image sensor pixels using the following logic:\n",
        "\n",
        "If dx and dy are the pixel densities in a millimeter range around a pixel (i.e it has the dimentions px/mm), then the pixel coordinates in the imaging plane is given by, \n",
        "\n",
        "u(sensor) = dx*x = dx * *f* * xv / zv\n",
        "\n",
        "v(sensor) = dy*y = dy * *f* * yv / zv\n",
        "\n",
        "Also, the origin for the image lies in one corner of the sensor, given by ox and oy. So, finally, the pixel coordinates (u, v) of the sensor w.r.t the view coordinate space pixel coordinates is given by : \n",
        "\n",
        "(u, v) = (dx * *f* * xv / zv + ox, dy * *f* * yv / zv + oy).\n",
        "\n",
        "It is to be noted that the intrinsic parameters of the camera, that represent the cameras internal geometry is represented by (fx, fy, ox, oy), where fx and fy are the result of (dx * f, dy * f)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3uawe-RbJH2"
      },
      "source": [
        "Suppose we had a point in the view space, V(xv, yv, zv) and its corresponding point in the image plane, IP(x, y). The relationship between both are given by : \n",
        "\n",
        "x = *f* * xv / zv\n",
        "\n",
        "y = *f* * yv / zv\n",
        "\n",
        "However, the image sensor has pixels, and the image place's pixel need not have a 1-1 relation with the image sensor pixels.\n",
        "\n",
        "We can approximate image pixels and the image sensor pixels using the following logic:\n",
        "\n",
        "If dx and dy are the pixel densities in a millimeter range around a pixel (i.e it has the dimentions px/mm), then the pixel coordinates in the imaging plane is given by, \n",
        "\n",
        "u(sensor) = dx*x = dx * *f* * xv / zv\n",
        "\n",
        "v(sensor) = dy*y = dy * *f* * yv / zv\n",
        "\n",
        "Also, the origin for the image lies in one corner of the sensor, given by ox and oy. So, finally, the pixel coordinates (u, v) of the sensor w.r.t the view coordinate space pixel coordinates is given by : \n",
        "\n",
        "(u, v) = (dx * *f* * xv / zv + ox, dy * *f* * yv / zv + oy).\n",
        "\n",
        "It is to be noted that the intrinsic parameters of the camera, that represent the cameras internal geometry is represented by (fx, fy, ox, oy), where fx and fy are the result of (dx * f, dy * f)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "dK1U0q4qbKq4",
        "outputId": "edaf49ff-805f-4eb1-e4f8-a7f7217d54bf"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cv2.imread('images/Infographics/world_view_projection.png'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk3vNdvUbQeN"
      },
      "source": [
        "We can represent the above non linear transformation (i.e because of division of xv / yv by zv), by the use of homogeneous coordinates.\n",
        "\n",
        "The **projection matrix** to go from [xc, yc, zc] to [u, v] and vice versa is : \n",
        "\n",
        "[u, v, 1] =  [u', v', w'] = [zc u', zc v', zc] = [fx * xc + ox * zc, fy * yc + oy * zc, zc]\n",
        "\n",
        "=> \n",
        "\n",
        "[fx 0 ox 0] * [xc yc zc 1]^T \\\n",
        "[0 fy 0y 0]  \\\n",
        "[0 0 0 0 ] \n",
        "\n",
        "It can be observed that the projection matrix is made up of a scaling matrix (scale coordinates to fx, fy) and a translation matrix (translated by ox, oy, which are the center points of the imaging plane system).\n",
        "\n",
        "Also, the upper 3x3 matrix is the camera calibration matrix, **K**. The projection matrix is therefore **M** = [**K**|0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWPXNXNsbSUY"
      },
      "source": [
        "**World Coordinate frame -> View Coordinate Frame**\n",
        "\n",
        "There are two transformation involved.\n",
        "1. Translation of the scene so the camera is placed at origin.\n",
        "2. Rotation of scene so camera looks towards the z axis.\n",
        "\n",
        "The Position and Orientation of the camera in the world coordinate frame represents the camera's extrinsic parameters.\n",
        "If matrix **R** is the rotation matrix and vector **T** is the translation vector, we can represent the view matrix as : \n",
        "\n",
        "(xv, yv, zv, 1v) = \n",
        "\n",
        "                  [r11, r12, r13, tx]  * [xw, yw, zw, 1]\n",
        "                  [r21, r22, r23, ty] \n",
        "                  [r31, r32, r33, tz]  \n",
        "                  [0    0    0     1]\n",
        "\n",
        "Therefore, the extrinsic matrix is given by : \n",
        "\n",
        "Mext = \\\n",
        "       [r3x3 t] \\\n",
        "       [01x3 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEDcuHHPbVLA"
      },
      "source": [
        "The complete transformation of a given world coordinate to image plane / pixel coordinate is there fore given by : \n",
        "\n",
        "pixelCoord = Mintrinsic * Mextrinsic * worldCoord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcpP4SuybWiQ"
      },
      "source": [
        "**Disparity Generation / Calculation Using Template Matching**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "EtxuVmVAbYdJ",
        "outputId": "9ecf0e66-e267-441b-b6f6-153bfa01b487"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cv2.imread('images/Infographics/disparity_generation.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFgngYzobbFh"
      },
      "source": [
        "Since the displacement in y is 0, we can have a moving window in the scanline (i.e x axis, going from left to right).\n",
        "We will use the Sum of absolute differences metric to determine the values of ul and ur in the above explanatory image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7LBlTAAbcAw"
      },
      "outputs": [],
      "source": [
        "k_left, k_right = None, None\n",
        "t_left, t_right= None, None\n",
        "\n",
        "def parse_calibration_data(filename):\n",
        "    global t_left, t_right, k_left, k_right\n",
        "    parsed_fields = {}\n",
        "\n",
        "    f = open(filename, \"r\")\n",
        "    for l in f:\n",
        "        kv = l.split(':')\n",
        "        k, v = kv\n",
        "        parsed_fields[k] = v.strip()\n",
        "\n",
        "    scale_width_left, scale_height_left = np.fromstring(parsed_fields['S_rect_101'], sep=\" \").reshape(2)\n",
        "    scale_width_right, scale_height_right = np.fromstring(parsed_fields['S_rect_103'], sep=\" \").reshape(2)\n",
        "\n",
        "    projection_left = np.fromstring(parsed_fields['P_rect_101'], sep=\" \").reshape(3, 4)\n",
        "    projection_right = np.fromstring(parsed_fields['P_rect_103'], sep=\" \").reshape(3, 4)\n",
        "\n",
        "    translation  = np.fromstring(parsed_fields['T_103'], sep=\" \").reshape(3)\n",
        "\n",
        "    baseline = np.linalg.norm(translation)\n",
        "    \n",
        "    print(\"Translation : \\n\", translation)\n",
        "    print(\"Projection Left : \\n\", projection_left)\n",
        "    print(\"Projection Right : \\n\", projection_right)\n",
        "    fx, fy = projection_left[0,0], projection_left[1, 1]\n",
        "\n",
        "    return baseline, fx, fy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEgzg8TWcLQ1"
      },
      "outputs": [],
      "source": [
        "right_projection_matrix = np.array([2.002991e+03, 0.000000e+00, 9.053329e+02, 0.000000e+00, 0.000000e+00, 2.002991e+03, 3.885141e+02, 0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00, 0.000000e+00,\n",
        "]).reshape(3, 4)\n",
        "r_camera_matrix, r_rot_matrix, r_trans_vect, r_rot_matrix_x, r_rot_matrix_y, r_rot_matrix_z, r_euler_angles = cv2.decomposeProjectionMatrix(right_projection_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyEZbTPNcMBg"
      },
      "outputs": [],
      "source": [
        "# Perspective Divide on translation vector (4D vector -> 3D vector)\n",
        "r_trans_vect_3d = r_trans_vect / r_trans_vect[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umuZofAmcNgP"
      },
      "outputs": [],
      "source": [
        "left_projection_matrix = np.array([2.002991e+03, 0.000000e+00, 9.053329e+02, -1.091469e+03, 0.000000e+00, 2.002991e+03, 3.885141e+02, 0.000000e+00, 0.000000e+00, 0.000000e+00, 1.000000e+00, 0.000000e+00]).reshape(3, 4)\n",
        "l_camera_matrix, l_rot_matrix, l_trans_vect, l_rot_matrix_x, l_rot_matrix_y, l_rot_matrix_z, l_euler_angles = cv2.decomposeProjectionMatrix(left_projection_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNtylbrKcOV_"
      },
      "outputs": [],
      "source": [
        "# Perspective Divide on translation vector (4D vector -> 3D vector)\n",
        "l_trans_vect_3d = l_trans_vect / l_trans_vect[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmE6QtmscPDH",
        "outputId": "be9ba765-d8b1-4dd9-f9b5-8a073f33d36a"
      },
      "outputs": [],
      "source": [
        "print(\"Left Translation Vector \\n\", l_trans_vect_3d)\n",
        "print(\"\\n Right Translation Vector \\n\", r_trans_vect_3d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAntpInQcPzA",
        "outputId": "8d9f997c-ecae-4f3a-f164-bb75e9b80a79"
      },
      "outputs": [],
      "source": [
        "# Print the projection matrices.\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "print(\"Left Projection Matrix \\n\", left_projection_matrix)\n",
        "print(\"\\n Right Projection Matrix \\n\", right_projection_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN74HuxtcQpf",
        "outputId": "a9ec16ce-94de-443b-fd6e-a782e966993d"
      },
      "outputs": [],
      "source": [
        "translation = r_trans_vect - l_trans_vect\n",
        "print(\"Translation : \\n\", translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6CR5aYFcRmP"
      },
      "outputs": [],
      "source": [
        "left = cv2.imread('images/DrivingStereo_dataset/Stereo/left.jpg', 0)\n",
        "right = cv2.imread('images/DrivingStereo_dataset/Stereo/right.jpg', 0)\n",
        "\n",
        "#left = cv2.resize(left,None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_LINEAR)\n",
        "#right  = cv2.resize(right,None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_LINEAR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "06daIch1cXGo",
        "outputId": "06d2bc47-9749-4d93-91b1-aa85e10f5ec8"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.imshow(left, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(right, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbRsbNG1cX6x"
      },
      "outputs": [],
      "source": [
        "\n",
        "m_left = cv2.resize(left,None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_LINEAR)\n",
        "m_right  = cv2.resize(right,None, fx = 0.75, fy = 0.75, interpolation = cv2.INTER_LINEAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcYLdkXcYlh"
      },
      "source": [
        "<b> Template Matching of a region in left image to the right image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "9DWagZ7qca9B",
        "outputId": "2b858c8f-4e1c-4713-c817-da67457f0db3"
      },
      "outputs": [],
      "source": [
        "# Using a 3x3 pattern from the right image for said action.\n",
        "# Metric used : sum of absoulte difference\n",
        "\n",
        "pattern_top_left = (150, 50)\n",
        "match_pattern_kernel_size = 5\n",
        "\n",
        "pattern = np.zeros((match_pattern_kernel_size, match_pattern_kernel_size))\n",
        "\n",
        "for i in range(0,match_pattern_kernel_size):\n",
        "    for j in range(0, match_pattern_kernel_size):\n",
        "        pattern[i][j] = m_left[pattern_top_left[0] + i, pattern_top_left[1] + j]\n",
        " \n",
        "marked_left = cv2.rectangle(m_left, pattern_top_left, (pattern_top_left[0]+match_pattern_kernel_size, pattern_top_left[1]+match_pattern_kernel_size), 255)\n",
        "plt.imshow(marked_left, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "template_matched_top_left = []\n",
        "minimum_sad = 1000000000\n",
        "\n",
        "for i in range(0, m_right.shape[0]-match_pattern_kernel_size):\n",
        "    j = pattern_top_left[1]\n",
        "\n",
        "    sad = 0\n",
        "    for x in range(0, match_pattern_kernel_size):\n",
        "        for y in range(0, match_pattern_kernel_size):\n",
        "            sad = sad + np.abs(m_right[i + x][j + y] - pattern[x][y])\n",
        "            minimum_sad = np.minimum(minimum_sad, sad)\n",
        "            if (minimum_sad == 0):\n",
        "                template_matched_top_left.append([i,j])\n",
        "                break\n",
        "\n",
        "template_matched_top_left = template_matched_top_left[0]\n",
        "print('Template matched (minimum SAD) : ', minimum_sad)\n",
        "print('Template matched coordinate : ', template_matched_top_left)\n",
        "print('Pattern coordinate in left image : ', pattern_top_left)\n",
        "marked_right = cv2.rectangle(m_right, template_matched_top_left, (template_matched_top_left[0]+match_pattern_kernel_size, template_matched_top_left[1]+match_pattern_kernel_size), 255)\n",
        "plt.imshow(marked_right, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(100,100))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(marked_left, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(marked_right, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print('The disparity value of ul - ur is : ', pattern_top_left[0] - template_matched_top_left[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVIX6CvBccLJ"
      },
      "source": [
        "Calculate and show disparity map for a range of block sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mnI66MKicd6q",
        "outputId": "1ce02c22-dc03-433e-9188-89899d9b681c"
      },
      "outputs": [],
      "source": [
        "blockSizes = [5,7,11,13,15,17,21]\n",
        "disparity_images = []\n",
        "closed_disparity_images = []\n",
        "\n",
        "# Blur images using gaussian blur\n",
        "smooth_left = cv2.GaussianBlur(left, (3,3), 1.5)\n",
        "smooth_right = cv2.GaussianBlur(right, (3,3), 1.5)\n",
        "\n",
        "print(smooth_left.shape, smooth_right.shape)\n",
        "kernel = np.array([[1, 1, 1],\n",
        "                    [1, 1, 1],\n",
        "                    [1, 1, 1]], np.uint8)\n",
        "\n",
        "\n",
        "pattern_match_window_size = 9\n",
        "\n",
        "for b in blockSizes:\n",
        "    stereo = cv2.StereoSGBM_create(numDisparities= 16*6,minDisparity = 0, P1 = 8 * 1 * b ** 2,\n",
        "                                        P2 = 32 * 1 * b ** 2, blockSize=b,mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n",
        "\n",
        "    disparity = stereo.compute(smooth_left, smooth_right).astype(np.float32)/16.0\n",
        "\n",
        "    # Disparity map values must be normalized for visualization\n",
        "    # Using min - max scaling to range [0, 1], and then upscaling values to rnage [0, 255]\n",
        "    min_value  = disparity.min()\n",
        "    max_value = disparity.max()\n",
        "\n",
        "    #disparity = np.uint8(255 * (disparity - min_value) / (max_value - min_value))\n",
        "    disparity_images.append(disparity)\n",
        "    erosion = cv2.erode(disparity, kernel, iterations=i+3)\n",
        "    dilation = cv2.dilate(erosion, kernel, iterations=i+3)\n",
        "\n",
        "    closed_disparity_images.append((cv2.morphologyEx(disparity, cv2.MORPH_DILATE,kernel)))\n",
        "\n",
        "for i in range(len(disparity_images)):\n",
        "    print('block size : ', blockSizes[i])\n",
        "    plt.figure(figsize=(100,100))\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.imshow(disparity_images[i])\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,4,2)\n",
        "\n",
        "    plt.imshow(closed_disparity_images[i], cmap='hsv')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.imshow(left)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmrYTBNdcfPj"
      },
      "source": [
        "For Generation of Depth map, you have to do : \n",
        "\n",
        "z = fb / (xl - xr) = fb / d.\n",
        "\n",
        "Here, fb is the focal length (obtainable from the camera matrix. \\\n",
        "b is the baseline values corresponding from the translation vectors t. \\\n",
        "d is the disparity map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uuuU3N5gcgkh",
        "outputId": "edee50d7-6946-456e-bc32-569653d58f8e"
      },
      "outputs": [],
      "source": [
        "#finding depth from the eroded depth images.\n",
        "depth_maps = []\n",
        "depth_map_closed_disparity = []\n",
        "\n",
        "i = 0\n",
        "for disp in closed_disparity_images:\n",
        "\t\n",
        "\tf = l_camera_matrix[0,0]\n",
        "\tb = r_trans_vect_3d[1] - l_trans_vect_3d[1]\n",
        "\n",
        "\tdisp[disp == 0] = 0.1\n",
        "\tdisp[disp == -1] = 0.9\n",
        "\n",
        "\tdepth_map = np.ones(disp.shape, dtype=np.float32)\n",
        "\tdepth_map[:] = (f * b) / disp\n",
        "\t\n",
        "\tdepth_map_closed_disparity.append(depth_map)\n",
        "\t\n",
        "\tplt.figure(figsize=(100,100))\n",
        "\tplt.subplot(1,4,1)\n",
        "\tplt.imshow(closed_disparity_images[i])\n",
        "\tplt.axis('off')\n",
        "\tplt.subplot(1,4,2)\n",
        "\tplt.imshow(depth_map, cmap='flag')\n",
        "\tplt.axis('off')\n",
        "\tplt.subplot(1,4,3)\n",
        "\tplt.imshow(left)\n",
        "\tplt.axis('off')\n",
        "\tplt.show()\n",
        "\ti += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8gzAxp5EgVs"
      },
      "source": [
        "<b> Hit Or Miss Transform </b>\n",
        "\n",
        "\n",
        "Used in finding a given configuration / pattern in a binary image . Uses basic morphological image processing as a basis (i.e erosion and diliation).\n",
        "\n",
        "This transform find those pixels whose neighbourhood matchines the shape of a first structuring element B1 while *not* matching the shape of a second structuring element B2 simultaneously.\n",
        "\n",
        "That is, A (*) B = (A (-) B1 ) ^ (A' (-) B2) \\\n",
        "where, A is the source image and B is the structural element, \\\n",
        "(*) is the hit or miss transform, \\\n",
        "(-) is the erosion operation, \\\n",
        "X' is the complement of X, \\\n",
        "^ is the intersection operator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "xF-CdPn-FAHU",
        "outputId": "aca3dab8-19c9-424c-be92-8de5842c696a"
      },
      "outputs": [],
      "source": [
        "image = closed_disparity_images[0].copy()\n",
        "print(image.shape)\n",
        "print('source image')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "threshold_image =  cv2.threshold(image, 50, 255, cv2.THRESH_BINARY)[1]\n",
        "print('thresholded image')\n",
        "plt.imshow(threshold_image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(threshold_image.max())\n",
        "threshold_image_complement = cv2.threshold(image, 50, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "print('threshold image complement')\n",
        "plt.imshow(threshold_image_complement, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(threshold_image.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0l0uLxiFQ0l",
        "outputId": "ffcb4147-4522-45a0-98f0-1fe0b9ab857b"
      },
      "outputs": [],
      "source": [
        "# Setup structuring element : for detection the bike rider in this scenario.\n",
        "# While b1 (here, se_b1) is just a rectangle on ones, se_b2 (b2) has a column of 1's in the middle.\n",
        "# This is to ensure that the detected object does *not* have missing 1's in the middle (this is not entirely required for this usecase, but present here to show the \n",
        "# flexibility the hit or miss transform gives us).\n",
        "se_b1 = np.ones((160, 80), dtype=np.uint8)\n",
        "se_b2 = np.zeros(se_b1.shape, dtype=np.uint8)\n",
        "for i in range(se_b1.shape[0]):\n",
        "  se_b2[i, se_b1.shape[1]//2] = 1\n",
        "\n",
        "se_b2 = se_b2.astype(np.uint8)\n",
        "\n",
        "print('circle se b1\\n', se_b1)\n",
        "print('shape : ', se_b1.shape)\n",
        "print('circle se b2\\n', se_b2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "u-_sIwF5FUjD",
        "outputId": "3700148a-fc90-40cf-85ac-564e4279f896"
      },
      "outputs": [],
      "source": [
        "# Step 1 : A erroded by B1.\n",
        "a_eroded_b1 = cv2.erode(threshold_image, se_b1)\n",
        "\n",
        "# Step 2 : Ac eroded by B2.\n",
        "ac_eroded_b2 = cv2.erode(threshold_image_complement, se_b2)\n",
        "\n",
        "ac_eroded_b2 = cv2.threshold(ac_eroded_b2, 1, 1, type=cv2.THRESH_BINARY_INV)[1]\n",
        "\n",
        "print(a_eroded_b1.min(), ac_eroded_b2.min())\n",
        "hitormiss_result = cv2.bitwise_and(a_eroded_b1, ac_eroded_b2)\n",
        "\n",
        "print('a eroded by b1')\n",
        "plt.imshow(a_eroded_b1, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('ac eroded by b2 ')\n",
        "plt.imshow(ac_eroded_b2, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print('hit or miss result')\n",
        "plt.imshow(hitormiss_result, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzxFX7v6HWUg"
      },
      "source": [
        "The single white line gives us the position of the matched object, which in this case is the driver."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "vscode": {
      "interpreter": {
        "hash": "8831fef4892bf96e6d13c9ddc5ee4273910b298099b1cbdd26dedb68e9e22eee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
